#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
%\usetheme{Warsaw}
\usetheme{Boadilla}
% or ...

%\usecolortheme{orchis}
%\setbeamertemplate{footline}[frame number]{}
\usefonttheme[onlymath]{serif}

%\setbeamercovered{transparent}
% or whatever (possibly just delete it)
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "biolinum" "default"
\font_typewriter "default" "default"
\font_math "libertine-ntxm" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Brief Review on Large Language Models
\end_layout

\begin_layout Author
Mo Zhou
\begin_inset Newline newline
\end_inset

Johns Hopkins University
\end_layout

\begin_layout Date
Sept.
 13 2023
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quotation
Simple algorithms that scale well are the core of deep learning.
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
flushright
\end_layout

\end_inset

— Kaiming He
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Masked Autoencoders Are Scalable Vision Learners, 2111.06377
\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

Quoted from Section 6 
\begin_inset Quotes eld
\end_inset

Discussion and Conclusion
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Table of Contents
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
tableofcontents[sections={1}]{}
\end_layout

\end_inset


\end_layout

\begin_layout Column
5cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
tableofcontents[sections={2}]{}
\end_layout

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Section
Natural Langauge Processing
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\bar under
Part I: Natural Language Processing
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quote
A portion of this part is borrowed from CS224N (Stanford).
\end_layout

\begin_layout Quote
NLP = Natural Language Understanding + Generation.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
NLP: Lexical Tokenization
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
The task of splitting a text into meaningful segments, called tokens.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted3.png
	special width=0.6\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout AlertBlock
There is no standard way of tokenization.
 Modern models still use different tokenizers – some are simple and native,
 while some use intricated ones.
 
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] SpaCy Linguistic Features: https://spacy.io/usage/linguistic-features
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Processing
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
A couple of foundamental aspects.
\end_layout

\begin_layout Itemize
Part-of-speech-tagging (Language Parsing)
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted1.png
	special width=1.0\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
[1] SpaCy Linguistic Features: https://spacy.io/usage/linguistic-features
\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Processing
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Dependency Tree Parsing (Language Parsing)
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted2.png
	special width=1.0\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] SpaCy Linguistic Features: https://spacy.io/usage/linguistic-features
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Processing
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Understanding tasks requires a stronger language representation.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
GLUE/SuperGLUE Benchmarks (understanding)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
https://gluebenchmark.com/tasks
\end_layout

\begin_layout Itemize
https://super.gluebenchmark.com/tasks
\end_layout

\end_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Example: Semantic Textual Similarity Benchmark (STS-B)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
(1) The bird is bathing in the sink.
\end_layout

\begin_layout Itemize
(2) Birdie is washing itself in the water basin.
\end_layout

\begin_layout Standard
Measure 
\series bold
semantic similarity
\series default
 between two sentences.
\end_layout

\begin_layout Standard
Evaluation is 
\series bold
Pearson correlation
\series default
 w.r.t.
 human.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Word Vectors
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Word Vectors: Words Represented by Context
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
How to represent the meaning of a single word?
\end_layout

\begin_layout Itemize
Before the introduction of word2vec, people use 
\series bold
WordNet
\series default
.
\begin_inset Newline newline
\end_inset

(ImageNet/ILSVRC class identifiers use WordNet.)
\end_layout

\begin_layout Itemize
WordNet representation (one-hot vector) does not encode similarity.
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

A word's meaning is given by the words that frequently appear close-by.
\begin_inset Quotes erd
\end_inset

 (statistical NLP)
\end_layout

\begin_layout Itemize
We use the many contexts of 
\begin_inset Formula $w$
\end_inset

 to build up the representation of 
\begin_inset Formula $w$
\end_inset

.
\end_layout

\begin_layout Itemize
Used as input tokens for RNN/LSTM/GRU for a long while.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Word2Vec
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Use similarity between word 
\begin_inset Formula $c$
\end_inset

 and context 
\begin_inset Formula $o$
\end_inset

 to calculate 
\begin_inset Formula $P(o|c)$
\end_inset

, then adjust word vectors to maximize it.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted4.png
	special width=0.6\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Likelyhood -> NLL objective function
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $L(\theta)=\prod_{t=1}^{T}\prod_{j\in\text{"window"}}P(w_{t+j}|w_{t};\theta)\quad\Rightarrow\quad J(\theta)=-\frac{1}{T}\log L(\theta)$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
We use two vectors per word 
\begin_inset Formula $w$
\end_inset

 — 
\begin_inset Formula $v_{w}$
\end_inset

 for center word; 
\begin_inset Formula $u_{w}$
\end_inset

 for context word.
 For a center word 
\begin_inset Formula $c$
\end_inset

 and context word 
\begin_inset Formula $o$
\end_inset

,
\begin_inset Formula 
\[
P(o|c)=\frac{\exp(u_{o}^{T}v_{c})}{\sum_{w\in V}\exp(u_{w}^{T}v_{c})}
\]

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] Efficient Estimation of Word Representations in Vector Space, 1301.3781
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Word2vec: extensions and further work
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\begin_inset Quotes eld
\end_inset

Learning from context
\begin_inset Quotes erd
\end_inset

 -> computer vision?
\end_layout

\begin_layout Itemize
The previously shown method is the skip-gram (SG) variant – predicting context
 words given center word.
\end_layout

\begin_layout Itemize
We can also use the continuous bag of words (CBoW) variant – predicting
 center word given context words.
 
\end_layout

\begin_layout Itemize
Negative sampling (a true pair + several 
\begin_inset Quotes eld
\end_inset

noise
\begin_inset Quotes erd
\end_inset

 pairs) can be used for less computational overhead in normalization term.
\end_layout

\begin_layout Itemize
SoTA word representations for a long period of time
\begin_inset Newline newline
\end_inset


\bar under
GloVe: Global Vectors for Word Representation, EMNLP2014
\begin_inset Newline newline
\end_inset

ELMo: Extending a Parser to Distant Domains Using a Few Dozen Partially
 Annotated Examples, ACL2018
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Language Modeling
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Language Modeling
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Language Modeling
\series default
 is the task of predicting what word comes next.
 i.e., 
\begin_inset Formula 
\[
P(x_{t+1}|x_{t},\ldots,x_{2},x_{1})
\]

\end_inset


\end_layout

\begin_layout Itemize
Can also assign a probability to a piece of text (chain rule)
\begin_inset Formula 
\[
P(x_{1},\ldots,x_{T})=\prod_{t=1}^{T}P(x_{t}|x_{t-1},\ldots,x_{1})
\]

\end_inset


\end_layout

\begin_layout Itemize
Flexible enough (chain rule) to deal with issues like
\begin_inset Formula 
\[
P(y_{1},\ldots,y_{M}|x_{1},\ldots,x_{T})=\prod_{m=1}^{M}P(y_{m}|x_{1},\ldots,x_{T},y_{1},\ldots,y_{m-1})
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Alex Graves, Supervised Sequence Labelling with Recurrent Neural Networks
 (Book)
\end_layout

\begin_layout Frame
[2] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
N-Gram Language Models
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Pretty old.
 But good to know.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
n-gram examples
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
unigrams: “the”, “students”, “opened”, ”their”
\end_layout

\begin_layout Itemize
bigrams: “the students”, “students opened”, “opened their”
\end_layout

\begin_layout Itemize
trigrams: “the students opened”, “students opened their”
\end_layout

\begin_layout Itemize
four-grams: “the students opened their”
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame
The we can use Markov model, using the assumption that 
\begin_inset Formula $x_{t+1}$
\end_inset

 only depends on the preceding 
\begin_inset Formula $n-1$
\end_inset

 words.
\begin_inset Formula 
\[
P(x_{t+1}|x_{t},\ldots,x_{1})=P(x_{t+1}|x_{t},\ldots,x_{t-n+2})=\frac{P(x_{t+1},x_{t},\ldots,x_{t-n+2})}{P(x_{t},\ldots,x_{t-n+2})}
\]

\end_inset


\end_layout

\begin_layout Frame
Such model can be statically approximated by counting on an corpus.
\end_layout

\begin_layout Frame
Then you can generate language from it in the auto-regressive manner.
\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Recurrent Neural Network
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Neural Language Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
They have became the past since the introduction of transformers – 
\series bold
but they incubated attention
\series default
.
\end_layout

\begin_layout Itemize
Markov model
\begin_inset Newline newline
\end_inset

A larger window will greatly increase model size, and introduce sparsity
 issue.
\end_layout

\begin_layout Itemize
Fixed-window neural language model
\begin_inset Newline newline
\end_inset

MLP for predicting 
\begin_inset Formula $x_{t+1}$
\end_inset

 based on the previous window.
\begin_inset Newline newline
\end_inset

No longer need to store all n-grams.
\begin_inset Newline newline
\end_inset

But fixed window is still too small.
\end_layout

\begin_layout Itemize
We need a neural architecture that can process variable length input.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Y.
 Bengio, A Neural Probabilistic Language Model (2000/2003)
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Recurrent Neural Network
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Core idea: apply the same weights 
\begin_inset Formula $W$
\end_inset

 repeatedly across the whole sequence.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted5.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] A.
 Graves, Generating Sequences With Recurrent Neural Networks
\end_layout

\begin_layout Frame
[2] Alex Graves, Supervised Sequence Labelling with Recurrent Neural Networks
 (Book)
\end_layout

\begin_layout Frame
[3] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Simple RNN Language Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Can process any-length input.
 Trained using cross-entropy loss.
\begin_inset Newline newline
\end_inset

But slow since input tokens are not processed in parallel, and difficult
 to access information for long range.
 Also suffers from vanishing gradient and exploding gradient issue (grad
 clipping) issue.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted6.png
	special width=0.6\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Frame
[2] On the difficulty of training recurrent neural networks, 1211.5063
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Long-Short Term Memory (LSTM)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Forget gate, input gate, and output gate.
 Cell state and hidden state.
 Dominant between 2013-2015.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted7.png
	special width=0.8\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-0.5cm}
\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Alleviated long-term dependency issue.
 But what about even longer distance dependency?
\end_layout

\begin_layout Itemize
LSTM is much slower than RNN.
 The input sequence is not processed in parallel.
\end_layout

\begin_layout Itemize
People removed several gates from the model and then it becomes Gated Recurrent
 Unit (GRU).
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Frame
[2] Improved Semantic Representations From Tree-Structured Long Short-Term
 Memory Networks, ACL2015
\end_layout

\begin_layout Frame
[3] Very Deep Convolutional Networks for Text Classification, 1606.01781
\end_layout

\begin_layout Frame
[4] Convolutional Neural Networks for Sentence Classification.
 EMNLP 2014
\end_layout

\begin_layout Frame
[5] Parsing Natural Scenes and Natural Language with Recursive Neural Networks,
 ICML2011
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Sequence To Sequence
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Neural Machine Translation (NMT)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
The sequence-to-sequence (seq2seq) model is an example of conditional language
 model.
 The first commercially successful NLP deep learning domain.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted8.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Frame
[2] Y.
 Bengio, Neural Machine Translation by Jointly Learning to Align and Translate,
 1409.0473
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Information Bottleneck & Attention
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Sequence-to-sequence with attention mechanism.
 Core Idea: on each decoder step, use direct connection to the encoder to
 focus on a particular part of the source sequence.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted9.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Y.
 Bengio, Neural Machine Translation by Jointly Learning to Align and Translate,
 1409.0473
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Attention Is All You Need (NMT)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Transformer: eschewing recurrence and instead relying entirely on an attention
 mechanism.
 Solved many previously existing issues, e.g., parallelism, interaction distance.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted10.png
	special width=0.4\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Attention Is All You Need, 1706.03762
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Sequence + Multi-Modality
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Sequence + Multimodal
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Retrieval (image<>text)
\begin_inset Newline newline
\end_inset

Early models: Visual Semantic Embedding (Frome 2013)
\begin_inset Newline newline
\end_inset

Contrastive models: CLIP (Radford 2021), ALIGN (Jia 2021), 
\end_layout

\begin_layout Itemize
Captioning (image->text)
\begin_inset Newline newline
\end_inset

Early models: Show and tell (Vinyals 2015)
\end_layout

\begin_layout Itemize
Generation(text->image)
\begin_inset Newline newline
\end_inset

Early models: GAN (Goodfellow 2014)
\end_layout

\begin_layout Itemize
VQA (image+text->text)
\end_layout

\begin_layout Itemize
Multimodal CLS (image+text->label)
\end_layout

\begin_layout Itemize
Vision Sequence?
\begin_inset Newline newline
\end_inset

ViT, SwinT, etc.
\end_layout

\begin_layout Itemize
V+L Foundation Models:
\begin_inset Newline newline
\end_inset

Visual BERT models, ViLT (Kim 2021), Flamingo (Alayrac 2022), BLIP-2 (Junnan
 2023) ......
\end_layout

\begin_layout Itemize
...
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
[1] https://web.stanford.edu/class/cs224n/slides/Multimodal-Deep-Learning-CS224n-K
iela.pdf
\end_layout

\begin_layout Subsection
Pre-training Paradigm
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Only Word Embeddings is Pretrained
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
The past tense (before 2017): Start with pretrained word emb, then learn
 to incorporate context in LSTM/Transformer on 
\series bold
specific task
\series default
.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted11.png
	special width=0.4\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Example
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Consider I 
\series bold
record
\series default
 the 
\series bold
record
\series default
: the two instances of record mean different things.
\end_layout

\begin_layout ExampleBlock
-> See ELMo
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining in Modern NLP
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle

\series bold
All parameters are initialized via pretraining
\series default
 — hiding parts of the input from the model, and train the model to reconstruct
 those parts.
 Does not require datasets for specific task.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted12.png
	special width=0.35\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
This practice leads to exceptionally strong:
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
representations of language
\end_layout

\begin_layout Itemize
parameter initializations
\end_layout

\begin_layout Itemize
probability distributions
\end_layout

\begin_layout Standard
Even if the pre-training task is simply next word prediction [1].
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Quoc V.
 Le, Semi-supervised Sequence Learning, 1511.01432
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Feasible Pretraining Task Depends on Architecture
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
We don't know which architecture is the best.
\end_layout

\begin_layout Itemize

\series bold
Encoder-Only
\series default
 Architecture
\begin_inset Newline newline
\end_inset

Can obtain bidirectional context – but accessing future means it is infeasible
 for language modeling.
\end_layout

\begin_layout Itemize

\series bold
Encoder-Decoder
\series default
 Architecture
\begin_inset Newline newline
\end_inset

What is the best way to pretrain them?
\end_layout

\begin_layout Itemize

\series bold
Decoder-Only
\series default
 Architecture
\begin_inset Newline newline
\end_inset

Suitable for LMs.
 Nice for generation.
 Cannot condition on future words.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Encoder-Only Pretraining
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining for Encoder-Only Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
It has got bi-directional context (can condition on the future), so cannot
 do language modeling.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted13.png
	special width=0.5\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Reconstructing masked input: Masked LM
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Stanford University is located in __________, California.
\end_layout

\begin_layout ExampleBlock
I put ___ fork down on the table.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Bidirectional Encoder Representations from Transformers, 2018
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Masked LM — BERT
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Bidirectional Encoder Representations from Transformers, 2018
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-0.3cm}
\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted14.png
	special width=0.9\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\backslash
vspace{-0.9cm}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Task #1: Masked LM
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Randomly replace 15% of all WordPiece tokens.
\end_layout

\begin_deeper
\begin_layout Enumerate
80%: w/ [MASK] token
\end_layout

\begin_layout Enumerate
10%: w/ random token
\end_layout

\begin_layout Enumerate
with itself 10% of the time
\end_layout

\end_deeper
\begin_layout Itemize
Then predict the masked word.
\end_layout

\end_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Task #2: Next Sentence Pred
\end_layout

\end_inset


\end_layout

\begin_layout Block
Bert pretraining input is a pair of sentence
\end_layout

\begin_deeper
\begin_layout Itemize
Sentence B is the next sentence of A 50% of the time
\end_layout

\begin_layout Itemize
Sentence B is not next sentence of A 50% of the time
\end_layout

\end_deeper
\begin_layout Block
Beneficial for some downstream tasks like QA and NLI.
\end_layout

\begin_layout Block
Demonstrated not necessary by later works.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
More on BERT
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Model Size
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
BERT-base: 12 layers, 768-dim hidden states, 12 attention heads, 110 million
 params.
\end_layout

\begin_layout Itemize
BERT-large: 24 layers, 1024-dim hidden states, 16 attention heads, 340 million
 params.
\end_layout

\begin_layout Itemize
PyTorch-ResNet50-ILSVRC: 25.6M params
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Issues
\end_layout

\end_inset


\end_layout

\begin_layout Block
Does not naturally lead to autoregressive methods.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Extensions
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
RoBERTa: mainly just train BERT for longer and remove next sentence prediction.
\begin_inset Newline newline
\end_inset


\bar under
More compute, more data can improve pretraining even when not changing the
 underlying Transformer encoder.
\end_layout

\begin_layout Itemize
SpanBERT: masking contiguous spans of words makes pretraining task harder.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] RoBERTa: A Robustly Optimized BERT Pretraining Approach, 1907.11692
\end_layout

\begin_layout Frame
[2] SpanBERT: Improving Pre-training by Representing and Predicting Spans,
 1907.10529
\end_layout

\begin_layout Subsection
Encoder-Decoder Pretraining
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining for Encoder-Decoder Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
We can do something like language modeling, but a prefix of every input
 is provided to encoder and is not predicted.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted15.png
	special width=0.36\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\begin_inset Formula 
\begin{align*}
h_{1,}\ldots,h_{T} & ={\color{blue}\text{Encoder}}(w_{1},\ldots,w_{T})\\
h_{T+1},\ldots,h_{2T} & =\text{{\color{red}Decoder}}(w_{T+1},\ldots,w_{2T};h_{1},\ldots,h_{T})
\end{align*}

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The encoder portion benefits from bidirectional context.
\end_layout

\begin_layout Itemize
The decoder portion trains the whole model through language modeling.
 (triangular attn mask)
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text
 Transformer, 1910.10683
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Text-to-Text w/ Span-Corruption Pretraining
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text
 Transformer, 1910.10683
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted16.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hrulefill
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\size small
Every task considered is cast as feeding (task-specific) text prefix and
 input, and then generating some target text (teacher-forcing objective).
\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted17.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
More on T5
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
T5 Can be finetuned to answer a wide range of questions, retrieving knowledge
 from its parameters.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Model Size
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\backslash
small
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Small
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Base
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Large
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#Params
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60M
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
220M
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
770M
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Flan-T5: Scaling Instruction-Finetuned Language Models, 2210.11416
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset CommandInset label
LatexCommand label
name "page:flan-t5"

\end_inset


\end_layout

\begin_layout Block

\size footnotesize
Instruction/chain-of-thought finetuning, while scaling number of tasks and
 model size.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Block
\begin_inset Graphics
	filename pasted18.png
	special width=0.7\linewidth

\end_inset


\end_layout

\begin_layout Block

\end_layout

\end_deeper
\begin_layout Subsection
Decoder-Only Pretraining
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining for Decoder-Only Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
All the biggest pretrained models are Decoders.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Pre-training
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Graphics
	filename pasted19.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Block
\begin_inset Formula 
\begin{align*}
h_{1},\ldots,h_{T} & =\text{Decoder}(w_{1},\ldots,w_{T})\\
w_{t} & \sim Ah_{t-1}+b
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Fine-tuning
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Graphics
	filename pasted20.png
	special width=\linewidth

\end_inset


\begin_inset Formula 
\begin{align*}
h_{1},\ldots,h_{T} & =\text{Decoder}(w_{1},\ldots,w_{T})\\
y & \sim Ah_{T}+b
\end{align*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-1: Generative Pretrained Transformer
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Improving Language Understanding by Generative Pre-Training, 2018
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: generative pre-training and discriminative fine-tuning.
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Transformer Decoder w/ 12 layers.
 117M params.
 Trained on BooksCorpus (> 7k books).
 Contains long spans of contiguous text (long distance dependency learning).
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Unsupervised Pretraining
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_layout Block
Given an unsup corpus of tokens 
\begin_inset Formula 
\[
U=\{u_{1},\ldots,u_{n}\}
\]

\end_inset


\end_layout

\begin_layout Block
Standard LM for maximizing likelihood
\begin_inset Formula 
\[
L_{1}(U)=\sum_{i}\log P(u_{i}|u_{i-k},\ldots,u_{i-1};\Theta)
\]

\end_inset

the 
\begin_inset Formula $k$
\end_inset

 is context window size.
\end_layout

\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Supervised Fine-tuning
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_layout Block
Dataset 
\begin_inset Formula $C$
\end_inset

 where 
\begin_inset Formula $x_{1},\ldots,x_{m}$
\end_inset

 has label 
\begin_inset Formula $y$
\end_inset

.
\end_layout

\begin_layout Block
Last block activation 
\begin_inset Formula $h_{m}^{l}$
\end_inset

 for prediction
\begin_inset Formula 
\begin{align*}
P(y|x_{1},\ldots,x_{m}) & =\text{softmax}(h_{m}^{l}W_{y})
\end{align*}

\end_inset


\begin_inset Formula 
\[
L_{2}(C)=\sum_{(x,y)}\log P(y|x_{1},\ldots,x_{m})
\]

\end_inset


\end_layout

\begin_layout Block
Pretraining as regularization
\begin_inset Formula 
\[
L_{3}(C)=L_{2}(C)+\lambda\times L_{1}(C)
\]

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-1 :: Architecture
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Generative model can learn good representation for discriminative task.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted21.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-2
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Language Models are Unsupervised Multitask Learners, 2019
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: w/ Larger dataset, LM begins to learn sup tasks w/o sup label.
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
GPT-2 is a (117M, 345M, 762M, 1.5B) decoder model, almost same as GPT architectur
e.
\end_layout

\begin_layout Itemize
Building LMs which learn to perform tasks from their naturally occuring
 demonstrations.
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Pre-training
\end_layout

\end_inset


\end_layout

\begin_layout Block
Same as GPT-1.
\end_layout

\begin_layout Block
Although there should be something hidden in details.
\end_layout

\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Fine-tuning
\end_layout

\end_inset


\end_layout

\begin_layout Block
Same as GPT-1.
\end_layout

\begin_layout Block
Although there should be something hidden in details.
\end_layout

\end_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Limitations
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Tends to 
\begin_inset Quotes eld
\end_inset

stray off topic
\begin_inset Quotes erd
\end_inset

 when generating long text.
\end_layout

\begin_layout ExampleBlock
Can become repetitive or nonsensical when generating long text.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Language Models are Few-Shot Learners, 2005.14165
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: Very large LM 
\begin_inset Quotes eld
\end_inset

learns
\begin_inset Quotes erd
\end_inset

 without gradient within contexts
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
GPT-3 is 175B model (800GB disk), using the same arch as GPT-2, evaluated
 without fine-tuning.
\end_layout

\begin_layout ExampleBlock
Apart from sampling from LM's distribution, and fine-tuning them and take
 their distributions, very large LMs enables in-context learning (as well
 as prompt engineering).
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted23.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted24.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3 :: In-Context Learning (Inference)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
No gradient update at all.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
4cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted25.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
4cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted26.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
4cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted27.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3 :: Model Size Scaling Law
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Larger model -> requires larger batch size but smaller learning rate.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted22.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted28.png
	special width=0.8\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3.5
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: ChatGPT (2022) is fine-tuned version of GPT-3.5
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
No much technical details are disclosed from OpenAI.
\end_layout

\begin_layout Itemize
(Chat) gpt-3.5-turbo
\end_layout

\begin_layout Itemize
(Text completion) text-davinci-003
\end_layout

\begin_layout Itemize
(Text completion) text-davinci-002
\end_layout

\begin_layout Standard
FYI: text-davinci-001 migbt be InstructGPT-3, not included in GPT-3.5.
\end_layout

\end_deeper
\begin_layout Frame
InstructGPT will be covered later.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
[1] https://en.wikipedia.org/wiki/GPT-3#GPT-3.5
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-4
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
GPT-4 Technical Report, 2303.08774
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: larger scale; multi-modality extension; human-level
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
Did not present much useful information other than showing off.
\end_layout

\end_deeper
\begin_layout Itemize

\size small
GPT-4 is a Transformerbased model pre-trained to predict the next token
 in a document.
\end_layout

\begin_layout Itemize

\size small
The post-training alignment process results in improved performance on measures
 of factuality and adherence to desired behavior.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted36.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Figure source: https://arxiv.org/pdf/2303.18223.pdf
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Why does next-word prediction work?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Taken from Jensen Huang and Ilya's Talk: https://lifearchitect.ai/ilya/
\end_layout

\begin_layout Quotation

\size small
So, I’d like to take a small detour and to give an analogy that will hopefully
 clarify why more accurate prediction of the next word leads to more understandi
ng, real understanding.
 Let’s consider an example.
 
\bar under
Say you read a detective novel.
 It’s like complicated plot, a storyline, different characters, lots of
 events, mysteries like clues, it’s unclear.
 Then, let’s say that at the last page of the book, the detective has gathered
 all the clues, gathered all the people
\bar default
 and saying, “okay, I’m going to reveal the identity of whoever committed
 the crime and that person’s name is”.
 
\bar under
Predict that word.

\bar default
 Predict that word, exactly.
 My goodness.
 Right? Yeah, right.
 Now, there are many different words.
 But predicting those words better and better and better, the understanding
 of the text keeps on increasing.
 GPT-4 predicts the next word better.
\end_layout

\begin_layout Quotation
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
flushright
\end_layout

\end_inset

– Ilya
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Natural Langauge Genration
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Generation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Previous discussion only covers a small part of generation.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Plot Generation
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Graphics
	filename pasted29.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Visual Description
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Graphics
	filename pasted30.png
	special width=0.6\linewidth

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Outline-Conditioned Generation with Dynamic Plot State Tracking, EMNLP20
\end_layout

\begin_layout Frame
[2] A Hierarchical Approach for Generating Descriptive Image Paragraphs,
 CVPR17
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Categorization of NLG Tasks
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
One way of formalizing categorization this is by 
\series bold
entropy
\series default
.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted31.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Open-ended generation
\begin_inset Newline newline
\end_inset

the output distribution still has high freedom
\end_layout

\begin_layout Itemize
Non-open-ended generation
\begin_inset Newline newline
\end_inset

the input mostly determines the output generation.
\end_layout

\begin_layout Itemize
The two types of tasks require different 
\series bold
decoding
\series default
 and/or 
\series bold
training
\series default
 approaches.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Autoregressive Generation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
GPT Family is auto-regressive.
 Note, non-autoregressive LM models do exist.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Model 
\begin_inset Formula $f(\cdot),$
\end_inset

Vocab 
\begin_inset Formula $V$
\end_inset

, Score 
\begin_inset Formula $S=f(\{y_{<t}\},\theta\}\in R^{V}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Formula 
\begin{align*}
P(y_{t}=w|\{y_{<t}\}) & =\frac{\exp(S_{w})}{\sum_{w'\in V}\exp(S_{w'})}\\
\hat{y}_{t} & \leftarrow P(y_{t}|y_{1},\ldots y_{t-1})\\
\hat{y}_{t+1} & \leftarrow P(y_{t+1}|y_{1},\ldots,y_{t-1},\hat{y}_{t})\\
\hat{y}_{t+2} & \leftarrow P(y_{t+2}|y_{1},\ldots,y_{t-1},\hat{y}_{t},\hat{y}_{t+1})\\
\ldots & \ldots\\
\mathcal{L} & =-\sum_{t=1}^{T}\log P(y_{t}^{*}|\{y_{<t}^{*}\})
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
For non-open-ended tasks (e.g., NMT), we typically use encoder-decoder model,
 where the autoregressive model serves as the decoder, and the bidirectional
 encoder deals with the inputs.
\end_layout

\begin_layout Itemize
For open-ended tasks (e.g., story generation), autoregressive generation is
 often the only component.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decoding Algorithms
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Decoding algorithm defines a function to select to token from the distribution.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Decoding algorithm 
\begin_inset Formula $g(\cdot)$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Formula 
\[
\hat{y}_{t}=g\big\{ P(y_{t}|\{y_{<t}\})\big\}
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Greedy Decoding
\series default
: highest probability for the next token at each step.
\begin_inset Formula 
\[
\hat{y}_{t}=\arg\max_{w\in V}P(y_{t}=w|\{y_{<t}\})
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Beam Search
\series default
: find strings that maximizes the log-prob, with wider exploration of candidates.
 Frequently used in tasks like NMT.
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Issue
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
Good for low-entropy tasks like MT and summarization.
\end_layout

\begin_layout Standard
Bad for open-ended generation – most likely going repetitive.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decoding :: Random Sampling
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Sample a token from the token distribution
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Formula 
\[
\hat{y}_{t}\sim P(y_{t}=w|\{y_{<t}\})
\]

\end_inset


\end_layout

\begin_layout Itemize
Vanilla sampling may fall into the long-tail of the distribution (the long
 tail has a considerable mass), where many tokens are really wrong.
\end_layout

\begin_layout Itemize
Top-k sampling.
 Only sampling within the top-k (e.g., 50) tokens.
\end_layout

\begin_deeper
\begin_layout Itemize
Larger 
\begin_inset Formula $k$
\end_inset

 leads to more diverse but risky outputs.
\end_layout

\begin_layout Itemize
Smaller 
\begin_inset Formula $k$
\end_inset

 leads to safe but generic outputs.
\end_layout

\begin_layout Itemize
Not adaptive to the distribution shape,either too small or too large.
\end_layout

\end_deeper
\begin_layout Itemize
Top-
\begin_inset Formula $p$
\end_inset

 (nucleus) sampling.
 Sampling from the tokens in top-
\begin_inset Formula $p$
\end_inset

 cumulative probability mass.
\end_layout

\begin_layout Itemize
Other decoding algorithms...
 (re-ranking; will cover it later)
\end_layout

\begin_layout Itemize
Scaling randomness through 
\series bold
Temperature
\series default
 (See Hinton distillation)
\begin_inset Formula 
\[
P(y_{t}=w|\ldots)=\frac{\exp(S_{w}/\tau)}{\sum_{w'\in V}\exp(S_{w'}/\tau)}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] The Curious Case of Neural Text Degeneration, ICLR20
\end_layout

\begin_layout Frame
[2] G.
 Hinton, Distilling the Knowledge in a Neural Network, NIPSw2014
\end_layout

\begin_layout Section
Large Language Models
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\bar under
Part II: Large Language Models
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quote
Is scaling up everything the ultimate answer towards intelligence?
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
[1] A Survey of Large Language Models, 2303.18223
\end_layout

\end_deeper
\begin_layout Frame
[2] A Comprehensive Survey on Pretrained Foundation Models: A History from
 BERT to ChatGPT
\end_layout

\begin_layout Frame
[3] Towards AGI in comuter vision: lessons learned from gpt and large language
 models
\end_layout

\begin_layout Frame
[4] Next Steps for Human-Centered Generative AI: A Technical Perspective
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Scaling Law
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Why Larger and Larger?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Observation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
The performance improves somewhat predictably as one scales up either the
 amount of compute or the size of the network.
\end_layout

\end_deeper
\begin_layout Quotation
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\end_layout

\end_inset


\end_layout

\begin_layout Quotation

\size small
\bar under
Kaplan Scaling Law:
\bar default
 larger models are significantly more sample-efficient, such as optimally
 compute-efficient training involves training very large models on a relatively
 modest amount of data and stopping significantly before convergence.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Scaling Law [1/2]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Scaling can largely improve the model capacity of LLMs, and show emergent
 properties.
\end_layout

\begin_layout Standard

\size footnotesize
Power law between model performance and model size (
\begin_inset Formula $N$
\end_inset

), dataset size (
\begin_inset Formula $D$
\end_inset

), and amount of compute (
\begin_inset Formula $C$
\end_inset

).
\begin_inset Newline newline
\end_inset

These notations are constants: 
\begin_inset Formula $N_{c}$
\end_inset

, 
\begin_inset Formula $D_{c}$
\end_inset

, 
\begin_inset Formula $C_{c}$
\end_inset

, 
\begin_inset Formula $\alpha_{N}$
\end_inset

, 
\begin_inset Formula $\alpha_{D}$
\end_inset

, 
\begin_inset Formula $\alpha_{C}$
\end_inset

 to be found through curve fitting.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Kaplan Scaling Law (OpenAI)
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Graphics
	filename pasted38.png
	special width=\linewidth

\end_inset


\begin_inset Formula 
\[
L(N)\approx\Big[\frac{N_{c}}{N}\Big]^{\alpha_{N}}\quad L(D)\approx\Big[\frac{D_{c}}{D}\Big]^{\alpha_{D}}\quad L(C)\approx\Big[\frac{C_{c}}{C}\Big]^{\alpha_{C}}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] (Kaplan Scaling Law) Scaling Laws for Neural Language Models, 2001.08361
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Scaling Law [2/2]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Given a fixed FLOPs budget, how should one trade-off model size and the
 number of training tokens?
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Chinchilla Scaling Law (DeepMind)
\end_layout

\end_inset


\end_layout

\begin_layout Block

\size footnotesize
Minimizing pretraining loss 
\begin_inset Formula $L$
\end_inset

 under the constraint FLOPs
\begin_inset Formula $(N,D)=C$
\end_inset

 for optimal allocation of 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $D$
\end_inset

:
\size default

\begin_inset Formula 
\[
N_{\text{opt}}(C),D_{\text{opt}}(C)=\underset{N,D\text{ s.t. FLOPs}(N,D)=C}{\text{argmin}}L(N,D)
\]

\end_inset

With many analysis, they propose the following functional form to fit:
\begin_inset Formula 
\[
\hat{L}(N,D)\triangleq E+\frac{A}{N^{\alpha}}+\frac{B}{D^{\beta}}\qquad\text{const.}(A,B,E,\alpha,\beta)
\]

\end_inset

After estimating the coefficients using L-BFGS on the Huber loss, they obtain
\begin_inset Formula 
\[
N_{\text{opt}}(C)=G\big[\frac{C}{6}\big]^{a}\quad D_{\text{opt}}(C)=G^{-1}\big[\frac{C}{6}\big]^{b}\quad\text{where }G=\big(\frac{\alpha A}{\beta B})^{\frac{1}{\alpha+\beta}},a=\frac{\beta}{\alpha+\beta},b=\frac{\alpha}{\alpha+\beta}
\]

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
But emergent properties cannot be predicted through scaling law.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
[1] Chinchilla: Training Compute-Optimal Large Language Models, 2203.15556
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Fine-Tuning & Alignment
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHP :: 1706.03741 [1/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
This is the original RLHF (OpenAI, DeepMind) paper referred by InstructGPT.
\series bold

\begin_inset Newline newline
\end_inset

It uses the contrastive idea, learning from pairwise relations.
\end_layout

\begin_layout Standard
Sequential decision problem without a well-specified reward function.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted42.png
	special width=0.6\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
This can effectively solve some RL problems with less than 1% of agent interacti
on with the environment.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHP :: Explained [2/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Reinforcement Learning from Human Preferences, 1706.03741
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Problem Setting
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
At timestep 
\begin_inset Formula $t$
\end_inset

, the agent receives observation 
\begin_inset Formula $o_{t}\in\mathcal{O}$
\end_inset

 from enrivonment, and then sends action 
\begin_inset Formula $a_{t}\in\mathcal{A}$
\end_inset

.
\end_layout

\begin_layout Itemize
Note, there is no reward 
\begin_inset Formula $r_{t}\in\mathcal{R}$
\end_inset

 like traditional RL setting.
\end_layout

\begin_layout Itemize
Instead, we assume there is a human observer expressing preferences between
 trajectory segments.
\end_layout

\begin_layout Itemize
Trajectory segment (sequence of 
\begin_inset Formula $o$
\end_inset

 and 
\begin_inset Formula $a$
\end_inset

): 
\begin_inset Formula $\sigma=[(o_{0},a_{0}),(o_{1},a_{1}),\ldots,(o_{k-1},a_{k-1})]\in(\mathcal{O}\times\mathcal{A})^{k}$
\end_inset

.
\end_layout

\begin_layout Itemize
Human preference: denote 
\begin_inset Formula $\sigma^{1}\succ\sigma^{2}$
\end_inset

 as human preference of 
\begin_inset Formula $\sigma^{1}$
\end_inset

 over 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Itemize
Human database: 
\begin_inset Formula $\mathcal{D}$
\end_inset

 contains triples 
\begin_inset Formula $(\sigma^{1},\sigma^{2},\mu)$
\end_inset

 where 
\begin_inset Formula $\mu$
\end_inset

 is the distribution over 
\begin_inset Formula $\{1,2\}$
\end_inset

 for user preference.
\end_layout

\begin_layout Itemize
Goal: produce sequences preferred by human.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHP :: Explained [3/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Reinforcement Learning from Human Preferences, 1706.03741
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Method
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Maintain two policies: 
\begin_inset Formula $\pi:\mathcal{O}\rightarrow\mathcal{A}$
\end_inset

, and a reward estimate 
\begin_inset Formula $\hat{r}:\mathcal{O}\times\mathcal{A}\rightarrow\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout ExampleBlock
Preference predictor
\begin_inset Formula 
\[
\hat{P}[\sigma^{1}\succ\sigma^{2}]=\frac{\exp\sum\hat{r}(o_{t}^{1},a_{t}^{2})}{\exp\sum\hat{r}(o_{t}^{1},a_{t}^{1})+\exp\sum\hat{r}(o_{t}^{2},a_{t}^{2})}
\]

\end_inset


\end_layout

\begin_layout ExampleBlock
Minimize cross entropy between predictor and human label
\begin_inset Formula 
\[
\mathscr{L}(\hat{r})=-\sum_{(\sigma^{1},\sigma^{2},\mu)\in\mathcal{D}}\mu(1)\log\hat{P}[\sigma^{1}\succ\sigma^{2}]+\mu(2)\log\hat{P}[\sigma^{2}\succ\sigma^{1}]
\]

\end_inset


\end_layout

\begin_layout ExampleBlock
There are still many other details, which are omitted here.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Instruction/Alignment Tuning [1/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
InstructGPT: Training language models to follow instructions with human
 feedback, 2203.02155
\end_layout

\begin_layout Standard

\size footnotesize
GPT-3 is not well aligned to human intent.
 Sometimes generates unsafe answers.
\end_layout

\end_deeper
\begin_layout Frame

\size footnotesize
This is due to the training task (predicting next token on web-based corpus)
 is different from 
\begin_inset Quotes eld
\end_inset

follow the user's instructions helpfully and safely
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted34.png
	special width=0.7\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\bar under
Instruction Finetuning:
\bar default
 collect examples of (instruction, output) pairs across many tasks and ft
 the LM.
 See Flan-T5 (page 
\begin_inset CommandInset ref
LatexCommand ref
reference "page:flan-t5"
plural "false"
caps "false"
noprefix "false"

\end_inset

) for examples.
 Evaluate on unseen task.
\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Training language models to follow instructions with human feedback,
 2203.02155 (OpenAI)
\end_layout

\begin_layout Frame
[2] Finetuned Language Models Are Zero-Shot Learners, 2109.01652 (Google)
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHF: Reinforcement Learning from Human Feedback [2/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
InstructGPT: Training language models to follow instructions with human
 feedback, 2203.02155
\end_layout

\end_deeper
\begin_layout Frame

\bar under
TL;DR: use human preferences as a reward signal to fine-tune our models.
\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted35.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHF :: Reward Modeling & Reinforcement LG [3/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
InstructGPT: Training language models to follow instructions with human
 feedback, 2203.02155
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Supervised Fine-Tuning (SFT): Start with GPT-3 on the instruction dataset.
\end_layout

\begin_layout Enumerate
Reward Modeling (RM): 6B model, denoted as 
\begin_inset Formula $r_{\theta}(x,y_{l})$
\end_inset


\begin_inset Newline newline
\end_inset

input=(prompt, response), output=scalar reward.
\begin_inset Newline newline
\end_inset

A labler is presented with 
\begin_inset Formula $K=4\sim9$
\end_inset

 responses to rank – i.e., 
\begin_inset Formula $(_{2}^{K})$
\end_inset

 comparisons.
\begin_inset Formula 
\[
\mathcal{L}_{\text{RM}}(\theta)=\frac{1}{(_{2}^{K})}\mathbb{E}_{(x,y_{w},y_{l})\sim D}\Big\{\log\big(\sigma[r_{\theta}(x,y_{w})-r_{\theta}(x,y_{l})]\big)\Big\}
\]

\end_inset

where 
\begin_inset Formula $x$
\end_inset

 is prompt, 
\begin_inset Formula $y$
\end_inset

 is completion.
 The 
\begin_inset Formula $y_{w}$
\end_inset

 is prefered out of the pair 
\begin_inset Formula $(y_{w},y_{l})$
\end_inset

.
 The 
\begin_inset Formula $D$
\end_inset

 is dataset.
\end_layout

\begin_layout Enumerate
Reinforcement Learning w/ PPO:
\begin_inset Newline newline
\end_inset

Environment: bandit environment which presents a random customer prompt
 and expects a response to prompt.
\begin_inset Newline newline
\end_inset

Also add per-token KL penalty from SFT model at each token to mitigate RM
 over-optimization 
\begin_inset Formula 
\begin{align*}
\text{Obj}(\phi) & =\mathbb{E}_{(x,y)\sim D_{\pi_{\phi}^{RL}}}\big[r_{\theta}(x,y)-\beta\log(\pi_{\phi}^{RL}(y|x)/\pi^{SFT}(y|x))\big]\\
 & +\gamma\mathbb{E}_{x\sim D_{pretrain}}\big[\log(\pi_{\phi}^{RL}(x))\big]
\end{align*}

\end_inset

where 
\begin_inset Formula $\pi_{\phi}^{RL}$
\end_inset

 is RL policy, 
\begin_inset Formula $\pi^{SFT}$
\end_inset

 is supervised trained model, 
\begin_inset Formula $D_{pretrain}$
\end_inset

 is pretrain distribution, 
\begin_inset Formula $\beta$
\end_inset

 is KL reward coef.
 For PPO model, 
\begin_inset Formula $\gamma=0$
\end_inset

.
 The 
\begin_inset Formula $\gamma$
\end_inset

 term introduces pretraining gradients in order to fix performance regression
 on public NLP tasks.
 Gradient ascent.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
ChatGPT!
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
https://openai.com/blog/chatgpt
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Methods
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Trained using RLHF (same as InstructGPT).
\end_layout

\begin_layout Itemize
Slightly different in data collection setup.
\end_layout

\begin_layout Itemize
Performed several iterations of the (RM, RLHF) steps.
\end_layout

\end_deeper
\begin_layout Standard
Not really much information.
 
\series bold
:-(
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
RL is very tricky to get right.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Reward hacking (a common problem in RL)
\begin_inset Quotes erd
\end_inset

 ChatBot are rewarded by responses that seem authorative and helpful, regardless
 of truth.
\end_layout

\begin_layout Itemize
This can result in making up facts and hallucinations.
\end_layout

\begin_layout Itemize
Models (RM) of human preference are even more unreliable.
\end_layout

\begin_layout Itemize

\bar under
AI misalignment is a real concern.
\end_layout

\begin_layout Itemize
What are they doing recently? (https://openai.com/research)
\begin_inset Newline newline
\end_inset

Very frequent keywords: 
\bar under
Safety & Alignment, Responsible AI
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHF Datarequirements?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
RLAIF! RL from AI Feedback.
 
\end_layout

\begin_layout Itemize
Constitutional AI: Harmlessness from AI Feedback, 2212.08073
\end_layout

\begin_layout Itemize
Large Language Models Can Self-Improve, 2210.11610
\begin_inset Newline newline
\end_inset


\color lightgray
Generate 
\begin_inset Quotes eld
\end_inset

high-confidence
\begin_inset Quotes erd
\end_inset

 rationale-augmented answers using CoT prompting and self-consistency.
 And then fine-tune LN with those generated answers.
\end_layout

\begin_layout Itemize
STaR: Bootstrapping Reasoning With Reasoning, 2203.14465
\begin_inset Newline newline
\end_inset


\color lightgray
Generate chain-of-thought data.
 Fine-tune LM itself with generated data.
\end_layout

\begin_layout Itemize
Self-Instruct: Aligning Language Models with Self-Generated Instructions,
 2212.10560 (ACL2023)
\begin_inset Newline newline
\end_inset


\color lightgray
Generate instructions, input, and output samples from a language model,
 then filter invalid or similar ones before using them to finetune the original
 model.
\color inherit

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Itemize
Convergence and Collapse? [TODO]
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
Further readings:
\end_layout

\begin_layout Frame
[1] Learning to summarize from human feedback, 2009.01325
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Emergent Properties
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
In-Context Learning (ICL) a.k.a.
 Prompt Engineering
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
One of LLM's emergent properties when model is large enough.
 Small model, e.g., BERT do not exhibit it.
\begin_inset Newline newline
\end_inset

Should you try prompt engineering a small LM, you'll find the model not
 smart at all.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted39.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted40.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] GPT-3: Language Models are Few-Shot Learners, 2005.14165
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Chain-of-Thought Prompting
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
One of LLM's emergent abilities.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
A series of intermediate reasoning steps – significantly improves the ability
 of large language models to perform complex reasoning.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Graphics
	filename pasted32.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,
 2201.11903
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Zero-Shot Chain-of-Thought
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
LLMs are decent zero-shot reasoners by simply adding 
\bar under
“Let’s think step by step”
\bar default
 before each answer.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted33.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
Two prompts make a NeurIPS 2022 paper?
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Large Language Models are Zero-Shot Reasoners, NeurIPS 2022 (2005.11916)
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
New Dark Art of 
\begin_inset Quotes eld
\end_inset

Prompt Engineering?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Asking LLM for reasoning
\end_layout

\begin_layout Itemize
Stable diffusion prompts (e.g., artstation, depth of field, 4k, masterpiece)
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Jail-breaking
\begin_inset Quotes erd
\end_inset

 LLMs (societal impact & ethics)
\end_layout

\begin_layout Itemize
Use google code header (e.g., 
\begin_inset Quotes eld
\end_inset

Copyright (C) 2022, Google LLC
\begin_inset Quotes erd
\end_inset

) to generate more 
\begin_inset Quotes eld
\end_inset

professional
\begin_inset Quotes erd
\end_inset

 code?
\end_layout

\begin_layout Itemize
etc.
\end_layout

\begin_layout Standard
Further readings:
\end_layout

\begin_layout Itemize
https://en.wikipedia.org/wiki/Prompt_engineering
\end_layout

\begin_layout Itemize

\bar under
https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
What about visual prompting in computer vision?
\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
Prompt engineering is an emergent property.
\end_layout

\begin_layout AlertBlock
Does this really work for small-sized vision models?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Prompt Engineering Hints
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Reference: https://arxiv.org/pdf/2303.18223.pdf
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Key Ingredients
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\size small
Task description
\begin_inset Newline newline
\end_inset

and necessary clarifications
\end_layout

\begin_layout Itemize

\size small
Input data format
\begin_inset Newline newline
\end_inset

e.g., linearization of structured data
\end_layout

\begin_layout Itemize

\size small
Contextual information
\begin_inset Newline newline
\end_inset

e.g., background of the topic
\end_layout

\begin_layout Itemize

\size small
Prompt style
\begin_inset Newline newline
\end_inset

e.g., 
\begin_inset Quotes eld
\end_inset

Let us think step by step
\begin_inset Quotes erd
\end_inset

,
\begin_inset Newline newline
\end_inset

e.g., 
\begin_inset Quotes eld
\end_inset

You are an expert on this task
\begin_inset Quotes erd
\end_inset

,
\end_layout

\end_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Design Principles
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\size small
Expressing the task goal clearly.
\end_layout

\begin_layout Itemize

\size small
Decomposing into easy, detailed sub-tasks.
\end_layout

\begin_layout Itemize

\size small
Providing few-shot demonstrations.
\end_layout

\begin_layout Itemize

\size small
Utilizing model-friendly format.
\begin_inset Newline newline
\end_inset

e.g., using ### or 
\begin_inset Quotes eld
\end_inset


\begin_inset Quotes erd
\end_inset


\begin_inset Quotes erd
\end_inset

 as stop symbol for OpenAI model to separate instruction and context.
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Automatic Prompt Engineering
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Lazy enough? No problem!
\end_layout

\begin_layout Itemize

\series bold
AutoPrompt:
\series default
 Eliciting Knowledge from Language Models with Automatically Generated Prompts,
 2010.15980
\end_layout

\begin_layout Itemize

\series bold
Prefix-Tuning:
\series default
 Optimizing Continuous Prompts for Generation, 2101.00190
\end_layout

\begin_layout Itemize

\series bold
P-Tuning:
\series default
 GPT Understands, Too, 2103.10385
\end_layout

\begin_layout Itemize

\series bold
Prompt-Tuning:
\series default
 The Power of Scale for Parameter-Efficient Prompt Tuning, 2104.08691
\end_layout

\begin_layout Itemize

\series bold
Automatic Prompt Engineer:
\series default
 Large Language Models Are Human-Level Prompt Engineers, 2211.01910
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Decoding Algorithm
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Decoding Algorithms
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Performance improvements for 
\begin_inset Quotes eld
\end_inset

free
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
The Re-ranking Paradigm for Decoding
\end_layout

\end_inset


\end_layout

\begin_layout Block
1.
 Decode a bunch of sequences.
\end_layout

\begin_layout Block
2.
 Define a score to approximate sequence quality and re-rank by this score.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\size footnotesize
Self-Consistency Improves Chain of Thought Reasoning in Language Models,
 2203.11171
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock

\size small
Sample multiple pairs of CoT reasoning path and answer 
\begin_inset Formula $(r_{i},a_{i})$
\end_inset

.
 Self-consistency marginalizes 
\begin_inset Formula $r_{i}$
\end_inset

 by taking the majority vote over 
\begin_inset Formula $a_{i}$
\end_inset

, i.e., 
\begin_inset Formula $\arg\max_{a}\sum_{i=1}^{m}1\{a_{i}=a\}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\size footnotesize
Generate & rank: A multi-task framework for math word problems, 2109.03034
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock

\size small
Adds an MLP binary classifier on top of final layer hidden state of the
 last decoder token, as the ranker.
 Training objective of the ranker is cross-entropy.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\size footnotesize
Towards a human-like open-domain chatbot, 2001.09977
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock

\size small
Sample-and-rank.
 Sample 
\begin_inset Formula $N$
\end_inset

 independent candidate responses using plain random sampling with temperature
 
\begin_inset Formula $T$
\end_inset

.
 Then select the candidate response with the highest probablity.
\end_layout

\end_deeper
\begin_layout Subsection
Leaderboards
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Benchmark & Leaderboards
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Where you can pick an LLM for further work.
\end_layout

\begin_layout Itemize
Open LLM Leaderboard (HuggingFace)
\begin_inset Newline newline
\end_inset

https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
\end_layout

\begin_layout Itemize
[1] Holistic Evaluation of Language Models (Piercy Liang; Stanford)
\begin_inset Newline newline
\end_inset

https://crfm.stanford.edu/helm/latest/
\end_layout

\begin_layout Itemize
[2] Measuring Massive Multitask Language Understanding, ICLR21
\end_layout

\begin_layout Itemize
[3] Beyond the Imitation Game: Quantifying and extrapolating the capabilities
 of language models, 2206.04615
\end_layout

\begin_layout Itemize
...
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Some Notes if you want to try LLM locally
\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{
\backslash
linewidth}{!}{
\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disk Space
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Inference Batch
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Inference Precition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Inference Mode
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GPU Requirement
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Falcon-7B-Instruct
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
14GB
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bf16
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Single GPU
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1 * 16GB
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Falcon-40B-Instruct
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80GB
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bf16
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pipeline Parallel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4 * 24GB
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2 * 48GB
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Non-GPT sota LLMs
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted37.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] A Survey of Large Language Models, 2303.18223
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted41.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Non-GPT SoTA LLMs
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
We've got just, toooooooooooooooooooo many of them.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{
\backslash
linewidth}{!}{
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Tabular
<lyxtabular version="3" rows="17" columns="7">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Name
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Year
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Trainer
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#Params
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Arch
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Arxiv
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Comment
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BERT
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2018
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Google
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Enc-only
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Already introduced in previous slides.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
T5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2019
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Google
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Enc-only
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1910.10683
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Already introduced in previous slides.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
GPT-3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2020
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OpenAI
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
175B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dec-only
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2005.14165
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Milestone.
 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
T0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2021
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BigScience
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Enc-Dec
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2110.08207
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Explicit multi-task learning for zero-shot generalization.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
PaLM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Google
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
540B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dec-only
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2204.02311
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Understand the impact of scale on few-shot learning.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OPT
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
175B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2205.01068
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Those models are difficult to replicate without significant capital.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GLM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tsinghua
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
130B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2210.02414
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bilingual (English & Chinese)
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Galactica
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
120B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2211.09085
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Can store, combine and reason about scientific knowledge.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BLOOM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BigScience
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
176B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dec-only
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2211.05100 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LLMs are developed by resource-rich organizations and kept from public
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BLOOMZ
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BigScience
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
176B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dec-only
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2211.01786
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Multitask prompted finetuning
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LLaMA-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2023
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
65B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dec-only
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2302.13971
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
train state-of-the-art models using publicly available datasets exclusively
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Alpaca
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2023
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Stanford
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
65B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
N/A (2303)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Instruction fine-tuned LLaMA-1.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Vicuna
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2023
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Berkeley
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
13B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
N/A (2303)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pythia
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2023
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
EleutherAI
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
12B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2304.01373 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
How do evolving patterns change as models scale?
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Falcon
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2023
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
TII.UAE
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
40B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2306.01116
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
properly filtered+deduplicated web data alone can lead to powerful models
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LLaMA-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2023
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
70B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2307.09288
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Available for free for research and commercial use.
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\end_layout

\end_inset

 I chose those beucase they are either famous, or frequently appear in the
 related work section of relevant papers.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLaMA-1 :: Explained
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Llama: Open and efficient foundation language models, 2023
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Motivation
\end_layout

\end_inset


\end_layout

\begin_layout Block
1.
 Training and inference efficiency
\end_layout

\begin_layout Block
2.
 Only use publically available data.
 No proprietary or inaccessible data.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Modifications to standard Transformer
\end_layout

\end_inset


\end_layout

\begin_layout Block
(1) pre-normalization [GPT3] for training stability
\end_layout

\begin_layout Block
(2) SwiGLU activation [PaLM] in place of ReLU for performance
\end_layout

\begin_layout Block
(3) rotary embedding [GPTNeo] instead of absolute positional embeddings
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Very Fun Fact: Training Cost
\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
Single Model training: 2048 A100 GPUs (80GB) for 21 days.
\end_layout

\begin_layout AlertBlock
Development took 5 months, and 2,638 MWh electricity.
\end_layout

\begin_layout AlertBlock

\color lightgray
FYI: A typical nuclear reactor produces 1 gigawatt (GW) of electricity.
\end_layout

\begin_layout AlertBlock
Electricity bill = 2638 MWh * $0.23 / kWh = $0.6M 
\begin_inset Formula $\approx$
\end_inset

 37 A100 GPUs (80G PCIE; $16255 each) 
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLaMA-2 :: Explained
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Llama 2: Open Foundation and Fine-Tuned Chat Models, 2307.09288
\end_layout

\begin_layout Block

\size small
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Motivation
\end_layout

\end_inset


\end_layout

\begin_layout Block

\size small
Optimized for dialogue use cases.
 Open access for both academic and commercial use cases.
\begin_inset Newline newline
\end_inset

Arch diff from LLaMA-1: increased context length and grouped query attention
 (GQA).
\end_layout

\begin_layout Block

\size small
Introduced GhostAttention to prevent the LM from forgetting the initial
 instruction.
\end_layout

\begin_layout Block

\size small
Training data updated to a new mix of publically available online data.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Pretraining
\end_layout

\end_inset


\end_layout

\begin_layout Block

\end_layout

\begin_layout Block
1.
 Self-supervised learning (pretraining) using the standard language modeling.
\end_layout

\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Fine-Tuning
\end_layout

\end_inset


\end_layout

\begin_layout Block
2.
 supervised fine-tuning
\end_layout

\begin_layout Block
3.
 RLHF iterations
\end_layout

\end_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Evaluation
\end_layout

\end_inset


\end_layout

\begin_layout Block

\size small
Code, Commonsense Reasoning, World knowledge, reading comprehension, Math,
 etc.
\end_layout

\end_deeper
\begin_layout Subsection
Position Embedding
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Position Embedding [1/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Sinusoid position embededing, or absolute position embedding from vanilla
 transformer
\end_layout

\end_deeper
\begin_layout Frame

\size footnotesize
\begin_inset Quotes eld
\end_inset

Since our model contains no recurrence and no convolution, ......, we must inject
 some information about the relative or absolute position of the tokens
 in the sequence.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_deeper
\begin_layout ExampleBlock

\size small
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Absolute Position Embedding
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\size small
Typically, position embedding 
\begin_inset Formula $p_{i}$
\end_inset

 is added onto its correponding token 
\begin_inset Formula $k_{i}$
\end_inset

 in the token sequence,
\begin_inset Formula 
\[
x_{i}+p_{i}\quad p_{i}\in\mathbb{R}^{d}
\]

\end_inset

which applies to query, key, and value:
\begin_inset Formula 
\[
f_{\{q,k,v\}}(x_{i},i)\triangleq W_{\{q,k,v\}}(x_{i}+p_{i})
\]

\end_inset


\end_layout

\begin_layout Standard

\size small
For instance, the sinusoid position embedding is
\begin_inset Formula 
\begin{align*}
p_{(i,2t)} & =\sin(i/10000^{2t/d})\\
p_{(i,2t+1)} & =\cos(i/10000^{2t/d})
\end{align*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\size small
You can also learn the position embedding.
 But sinusoid embedding allows you to extrapolate to sequence lengths longer
 than the ones encountered during the training process.
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Attention is all you need, 1706.03762
\end_layout

\begin_layout Frame
[2] Convolutional Sequence to Sequence Learning, 1705.03122
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Position Embedding [2/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Efficiently consider representations of the relative positions, or distances
 between sequence elements.
 (T5, Gopher)
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Relative Position Embedding
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Trainable relative position embedding 
\begin_inset Formula $\tilde{p}_{r}^{k}$
\end_inset

 and 
\begin_inset Formula $\tilde{p}_{r}^{v}$
\end_inset

 only to key and value
\begin_inset Formula 
\begin{align*}
f_{q}(x_{m})=W_{q}x_{m} & \quad\Rightarrow\quad & f_{q}(x_{m})=W_{q}x_{m}\\
f_{k}(x_{n},n)=W_{k}(x_{n}) & \quad\Rightarrow\quad & f_{k}(x_{n},n)=W_{k}(x_{n}+\tilde{p}_{r}^{k})\\
f_{v}(x_{n},n)=W_{v}(x_{n}) & \quad\Rightarrow\quad & f_{v}(x_{n},n)=W_{v}(x_{n}+\tilde{p}_{r}^{v})
\end{align*}

\end_inset

Note that 
\begin_inset Formula $r=\text{clip}(m-n,r_{\min},r_{\max})$
\end_inset

 is relative distance between position 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

.
\end_layout

\begin_layout ExampleBlock
The relative distance is clipped with the hypothesis that precise relative
 position information is not useful beyond a certain distance.
\end_layout

\end_deeper
\begin_layout Frame
There are other variants of relative position embeddings.
 See [2].
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Self-Attention with Relative Position Representations, 1803.02155
\end_layout

\begin_layout Frame
[2] RoFormer: Enhanced Transformer with Rotary Position Embedding, 2104.09864
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Position Embedding [3/3]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Unifies absolute and relative approaches [1].
 Used in (LLaMA, PaLM).
 Involves length math.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Rotary Position Embedding (RoPE) : 2d Case
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock

\size small
Since 
\begin_inset Formula $q^{\mathsf{T}}k$
\end_inset

 enables knowledge conveyance between tokens at different positions, we
 hope their inner product encodes position information only in the relative
 form:
\begin_inset Formula 
\[
\langle f_{q}(x_{m},m),f_{k}(x_{n},n)\rangle=g(x_{m},x_{n},m-n)
\]

\end_inset

Using geometric property of vectors, a solution can be
\begin_inset Formula 
\begin{align*}
f_{q}(x_{m})=W_{q}x_{m} & \quad\Rightarrow\quad & f_{q}(x_{m})=(W_{q}x_{m})e^{im\theta}\\
f_{k}(x_{n},n)=W_{k}(x_{n}) & \quad\Rightarrow\quad & f_{k}(x_{n},n)=(W_{k}x_{n})e^{in\theta}\\
 &  & g(x_{m},x_{n},m-n)=\Re[(W_{q}x_{m})(W_{k}x_{n})^{\mathsf{H}}e^{i(m-n)\theta}]
\end{align*}

\end_inset


\end_layout

\begin_layout ExampleBlock

\size small
This is, in fact, simply rotating the affine-transformed token embedding
 by amount of angle multiples of its position index.
\begin_inset Formula 
\[
f_{q}(x_{m},m)=\begin{bmatrix}\cos m\theta & -\sin m\theta\\
\sin m\theta & \cos m\theta
\end{bmatrix}\begin{bmatrix}w_{q}^{(1,1)} & w_{q}^{(1,2)}\\
w_{q}^{(2,1)} & w_{q}^{(2,2)}
\end{bmatrix}\begin{bmatrix}x_{m}^{(1)}\\
x_{m}^{(2)}
\end{bmatrix}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] RoFormer: Enhanced Transformer with Rotary Position Embedding, 2104.09864
\end_layout

\begin_layout Frame
[2] https://blog.eleuther.ai/rotary-embeddings/
\end_layout

\begin_layout Subsection
Param Efficient FT
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Parameter Efficient Fine-Tuning
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\size small
Adapter Tuning: Parameter-efficient transfer learning for nlp, 1902.00751
\begin_inset Newline newline
\end_inset

Insert adapter layers into the model.
 Only train adapter and keep original model frozen.
\end_layout

\begin_layout Itemize

\size small
Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning,
 2104.08691
\begin_inset Newline newline
\end_inset

Prepend task-specific prefix (virtual tokens).
 Only train prefix, the rest is fronzen.
\end_layout

\begin_layout Itemize

\size small
Prefix Tuning: Prefix-Tuning: Optimizing Continuous Prompts for Generation,
 2101.00190
\begin_inset Newline newline
\end_inset

Prepend task-specific prefix (transformer activation).
 Only train prefix, the rest is frozen.
\end_layout

\begin_layout Itemize

\size small
LoRA: Low-Rank Adaptation of Large Language Models, 2106.09685
\begin_inset Newline newline
\end_inset

Learns a low-rank 
\begin_inset Quotes eld
\end_inset

diff
\begin_inset Quotes erd
\end_inset

 between the pretrained and fine-tuned weight matrices.
 (easier than prefix tuning)
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture9-pretraining.pd
f
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LoRA: Low-Rank Adaptation, 2106.09685
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\size small
\begin_inset Quotes eld
\end_inset

Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number
 of trainable parameters by 10,000 times and the GPU memory requirement
 by 3 times.
\begin_inset Quotes erd
\end_inset

 – From abstract.
\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted43.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout ColumnsTopAligned

\size small
We only train 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

.
 The rest parameters are all frozen during fine-tuning.
\end_layout

\begin_layout ColumnsTopAligned
They only adapt the attention weights 
\begin_inset Formula $W_{q}$
\end_inset

, 
\begin_inset Formula $W_{k}$
\end_inset

, 
\begin_inset Formula $W_{v}$
\end_inset

, 
\begin_inset Formula $W_{o}$
\end_inset

.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned

\size small
Key insight: Pre-trained LMs have a low 
\begin_inset Quotes eld
\end_inset

intrinsic dimension
\begin_inset Quotes erd
\end_inset

 and can still learn efficiently despite a random projection to a smaller
 subspace.
\end_layout

\begin_layout ColumnsTopAligned

\size small
For pretrained weight 
\begin_inset Formula $W_{0}\in\mathbb{R}^{d\times k}$
\end_inset

, we constrain its update by low-rank decomposition 
\begin_inset Formula 
\begin{align*}
W_{0}+\Delta W & =W_{0}+BA\\
 & B\in\mathbb{R}^{d\times r},A\in\mathbb{R}^{r\times k}\\
 & r<<\min(d,k)
\end{align*}

\end_inset

The forwards pass is modified as
\begin_inset Formula 
\[
h=W_{0}x+\Delta Wx=W_{0}x+BAx
\]

\end_inset


\end_layout

\begin_layout ColumnsTopAligned

\size small
* LoRA is a generallization of full fine-tuning.
\end_layout

\begin_layout ColumnsTopAligned

\size small
* LoRA does not induce inference latency.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Alignment & Ethics
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Generated Text Detection
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
A Watermark for Large Language Models, 2301.10226
\end_layout

\begin_layout Itemize
DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability
 Curvature, 2301.11305 
\end_layout

\begin_layout Itemize

\bar under
Can AI-Generated Text be Reliably Detected?, 2303.11156
\bar default
 
\end_layout

\begin_deeper
\begin_layout Itemize

\size small
paraphrasing attacks can break a whole range of detectors.
\end_layout

\begin_layout Itemize

\size small
for a sufficiently good language model, even the best possible detector
 can only perform marginally better than a random classifier.
\end_layout

\begin_layout Itemize

\size small
watermarking is vulnerable against spoofing attacks where adversarial humans
 can infer hidden watermarking signatures.
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Bias
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Calibrate Before Use: Improving Few-Shot Performance of Language Models,
 2102.09690
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Quotes eld
\end_inset

GPT-3 is biased towards certain answers due to the prompt and the model’s
 intrinsic biases.
\begin_inset Quotes erd
\end_inset

 – Section 5.
\end_layout

\begin_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Influence of language model bias
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
GPT-3's few-shot learning can be unstable: the choice of prompt format,
 training examples, and even the order of the training examples can cause
 accuracy to vary from near chance to near state-of-the-art.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Contextual Calibration
\end_layout

\end_inset


\end_layout

\begin_layout Block
Adjust output probabilities with an affine transformation
\begin_inset Formula 
\[
\hat{q}=\text{softmax}(W\hat{p}+b)
\]

\end_inset

The weight matrix 
\begin_inset Formula $W$
\end_inset

 is restricted to be diagonal in this paper (vector scaling).
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Safety & Security
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
For instance, jail break attacks to bypass the safety checks.
 A part of alignment issue.
\end_layout

\begin_layout Itemize
https://openai.com/research
\end_layout

\begin_layout Itemize
Baseline Defenses for Adversarial Attacks Against Aligned Language Models,
 2309.00614
\begin_inset Newline newline
\end_inset

Discusses detection (preplexity based), input preprocessing (paraphrase
 and retokenization), and adversarial training.
\end_layout

\begin_layout Itemize
[TODO]
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Extension & Multi-Modality
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM + More data?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Mathematical Capabilities of ChatGPT, 2301.13867
\begin_inset Newline newline
\end_inset

Presents a new dataset.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted44.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Data Quality?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Phi-1: Textbooks are all you need, 2306.11644 [MSFT]
\begin_inset Newline newline
\end_inset

Improving data quality can dramatically change the shape of the scaling
 laws.
\begin_inset Newline newline
\end_inset

A small LM with 1.3B parameter can show surprising emergent properties compared
 to the base model.
\begin_inset Newline newline
\end_inset

Performance comparable to 5x larger state of the art model.
\end_layout

\begin_layout Itemize
Textbooks Are All You Need II: phi-1.5 technical report, 2309.05463 (Sept
 11 2023) [MSFT]
\begin_inset Newline newline
\end_inset

Can exhibit 
\begin_inset Quotes eld
\end_inset

think step by step
\begin_inset Quotes erd
\end_inset

 (zero-shot CoT) ability with only 1.3B parameters.
\end_layout

\begin_layout Itemize

\bar under
Q: Vision Datasets: the larger the better?
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM + Information Retrieval
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Internet-augmented language models through few-shot prompting for open-domain
 question answering, 2203.05115
\end_layout

\begin_layout Itemize
Overcome some of their challenges with respect to grounding to factual and
 up-to-date information.
\end_layout

\begin_layout Itemize
Condition LM on google search results.
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM + Symbolic Engine Aid?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted45.png
	special width=0.8\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
[1] PAL: Program-aided Language Models, 2211.10435
\end_layout

\begin_layout Standard
[2] Program of Thoughts Prompting: Disentangling Computation from Reasoning
 for Numerical Reasoning Tasks, 2211.12588
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM + External APIs
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
TALM: Tool Augmented Language Models, 2205.12255
\end_layout

\begin_layout Itemize
Toolformer: Language Models Can Teach Themselves to Use Tools, 2302.04761
\end_layout

\begin_layout Itemize
Augmented Language Models: a Survey, 2302.07842 (Yann LeCun)
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted46.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted47.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted48.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Calling other models from LLM
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face,
 2303.17580
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted49.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM + Multimodal = MLLM
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted51.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
[2] A Survey on Multimodal Large Language Models, 2306.13549
\end_layout

\begin_layout Frame
[1] Language Is Not All You Need: Aligning Perception with Langauge Models,
 2302.14045
\end_layout

\begin_layout Frame
[3] Towards Language Models That Can See: Computer Vision Through the LENS
 of Natural Language, 2306.16410
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
KOSMOS-1
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Language Is Not All You Need: Aligning Perception with Langauge Models,
 2302.14045
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted50.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Input Representation
\end_layout

\end_inset


\end_layout

\begin_layout Block
Flatten input as a sequence decorated with spetial tokens.
 <s> and </s> for sequence.
 <image> and </image> for encoded image embeddings.
\end_layout

\begin_layout Block
For instance, 
\begin_inset Quotes eld
\end_inset

<s> paragaph <image> IMAGE_EMBEDDING </image> paragraph </s>
\begin_inset Quotes erd
\end_inset

 is an interleaved image-text input.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LENS
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Towards Language Models That Can See: Computer Vision Through the LENS of
 Natural Language, 2306.16410
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted52.png
	special width=0.9\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Multi-Modal Instruct-Tuning / ICL / CoT?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language,
 2204.00598 (ICLR23)
\begin_inset Newline newline
\end_inset

Multimodal prompt engineering.
 Combines different modalities with language as the bridge.
 (VLM+LLM)
\end_layout

\begin_layout Itemize
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models
\begin_inset Newline newline
\end_inset

More or less share similar ideas to the previously shown works.
\end_layout

\begin_layout Itemize
Too many papers and growing very rapidly.
 I refrain from expanding the list here.
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Multi-Modal Scaling Law?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Scaling laws for generative mixed modal language models, 2301.03728
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted55.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
There are also discussions on the emergent properties in this paper.
 See preprint for details.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Language as Visual Representation?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen
 LLMs, 2306.17842 (Google + CMU)
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted53.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Language Prior in Downstream Task?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Lmpriors: Pre-trained language models as task-specific priors, 2210.12530
 (NeurIPSw)
\end_layout

\end_deeper
\begin_layout Frame
Incorporates auxiliary natural language metadata about the machine learning
 task—such as variable names and descriptions—to encourage downstream model
 outputs to be consistent with the LM’s common-sense reasoning based on
 the metadata.
\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted56.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Itemize
Only tried on several simple machine learning tasks.
 No vision task.
\end_layout

\begin_layout Itemize
Requires textual information about 
\begin_inset Formula $x$
\end_inset

, such as descriptions.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Evaluation Metric for Vision?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
LLMScore: Unveiling the Power of Large Language Models in Text-to-Image
 Synthesis Evaluation, 2305.11116
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted54.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\bar under
Do not stack multiple layers of errors and uncertainty.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Closing
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Future Topics
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
What is OpenAI doing recently? Secretly training GPT-5?
\begin_inset Newline newline
\end_inset

https://openai.com/research
\end_layout

\end_deeper
\begin_layout Frame
Better alignment & safety design of LLM.
 (can vision help this?)
\end_layout

\begin_layout Frame
More natural ways to prompt stable diffusion.
 (no more werid prompting please)
\end_layout

\begin_layout Frame
Detecting and source-tracking AI-generated contents.
 (false information)
\end_layout

\begin_layout Frame
Safety and ethics: reduce NSFW from Stable diffusion, prevent LLM jailbreaking.
\end_layout

\begin_layout Frame
.......
\end_layout

\begin_layout Frame
How can vision tasks leverage LLMs?
\end_layout

\begin_layout Frame
(LLaMA2, Falcon, Vicuna) are recommended for quick assessment.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Takeaways
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Language Modeling is to build the conditional probability
\begin_inset Formula 
\[
P(x_{t}|x_{t-1},\ldots,x_{2},x_{1})
\]

\end_inset


\end_layout

\begin_layout Itemize
The largest language models are Decoder only architecture.
\end_layout

\begin_layout Itemize
Instruction tuning and RLHF are important to make LLM useful and harmless.
\end_layout

\begin_layout Itemize
OpenAI seems to put their focus on alignment recently (Responsible AI, Safety
 & Alignment).
\begin_inset Newline newline
\end_inset

https://openai.com/research
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Q&A Session
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quote
Congrats!
\begin_inset Newline newline
\end_inset

You have gone through not only CS224N, but also some latest papers.
\end_layout

\begin_layout Quote
You are able to read LLM papers afterwards without much doubt.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Fun Fact
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
The survey 
\begin_inset Quotes eld
\end_inset

A Survey of Large Language Models
\begin_inset Quotes erd
\end_inset

 (2303.18223) cited 610 papers.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
* NLP topics not covered: including but not limited to question answering,
 linguistics, TreeLSTM/TreeRNN or CNN for sequence modeling, code generation,
 coreference resolution, model interpretability,
\begin_inset Newline newline
\end_inset

* LLM topics not covered: including but not limited to dataset collection
 and curating, LLM training details, LLM quantization, LLM for task planning,
 LLM evaluation and benchmarking, LLM interpretability,
\end_layout

\end_deeper
\end_body
\end_document
