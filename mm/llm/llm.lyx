#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
%\usetheme{Warsaw}
\usetheme{Boadilla}
% or ...

%\usecolortheme{orchis}
\setbeamertemplate{footline}[frame number]{}
\usefonttheme[onlymath]{serif}

%\setbeamercovered{transparent}
% or whatever (possibly just delete it)
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "biolinum" "default"
\font_typewriter "default" "default"
\font_math "libertine-ntxm" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Brief Review on Large Language Models
\end_layout

\begin_layout Author
Mo Zhou
\begin_inset Newline newline
\end_inset

Johns Hopkins University
\end_layout

\begin_layout Date
Sept.
 6 2023
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quotation
Simple algorithms that scale well are the core of deep learning.
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
flushright
\end_layout

\end_inset

— Kaiming He
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Masked Autoencoders Are Scalable Vision Learners, 2111.06377
\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

Quoted from Section 6 
\begin_inset Quotes eld
\end_inset

Discussion and Conclusion
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Table of Contents
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
tableofcontents[sections={1}]{}
\end_layout

\end_inset


\end_layout

\begin_layout Column
5cm
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
tableofcontents[sections={2}]{}
\end_layout

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Section
Natural Langauge Processing
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\bar under
Part I: Natural Language Processing
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quote
A portion of this part is borrowed from CS224N (Stanford).
\end_layout

\begin_layout Quote
NLP = Natural Language Understanding + Generation.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
NLP: Lexical Tokenization
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
The task of splitting a text into meaningful segments, called tokens.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted3.png
	special width=0.6\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout AlertBlock
There is no standard way of tokenization.
 Modern models still use different tokenizers – some are simple and native,
 while some use intricated ones.
 
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] SpaCy Linguistic Features: https://spacy.io/usage/linguistic-features
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Processing
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
A couple of foundamental aspects.
\end_layout

\begin_layout Itemize
Part-of-speech-tagging (Language Parsing)
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted1.png
	special width=1.0\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
[1] SpaCy Linguistic Features: https://spacy.io/usage/linguistic-features
\end_layout

\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Processing
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Dependency Tree Parsing (Language Parsing)
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted2.png
	special width=1.0\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] SpaCy Linguistic Features: https://spacy.io/usage/linguistic-features
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Processing
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Understanding tasks requires a stronger language representation.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
GLUE/SuperGLUE Benchmarks (understanding)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
https://gluebenchmark.com/tasks
\end_layout

\begin_layout Itemize
https://super.gluebenchmark.com/tasks
\end_layout

\end_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Example: Semantic Textual Similarity Benchmark (STS-B)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
(1) The bird is bathing in the sink.
\end_layout

\begin_layout Itemize
(2) Birdie is washing itself in the water basin.
\end_layout

\begin_layout Standard
Measure 
\series bold
semantic similarity
\series default
 between two sentences.
\end_layout

\begin_layout Standard
Evaluation is 
\series bold
Pearson correlation
\series default
 w.r.t.
 human.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Word Vectors
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Word Vectors: Words Represented by Context
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
How to represent the meaning of a single word?
\end_layout

\begin_layout Itemize
Before the introduction of word2vec, people use 
\series bold
WordNet
\series default
.
\begin_inset Newline newline
\end_inset

(ImageNet/ILSVRC class identifiers use WordNet.)
\end_layout

\begin_layout Itemize
WordNet representation (one-hot vector) does not encode similarity.
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

A word's meaning is given by the words that frequently appear close-by.
\begin_inset Quotes erd
\end_inset

 (statistical NLP)
\end_layout

\begin_layout Itemize
We use the many contexts of 
\begin_inset Formula $w$
\end_inset

 to build up the representation of 
\begin_inset Formula $w$
\end_inset

.
\end_layout

\begin_layout Itemize
Used as input tokens for RNN/LSTM/GRU for a long while.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Word2Vec
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Use similarity between word 
\begin_inset Formula $c$
\end_inset

 and context 
\begin_inset Formula $o$
\end_inset

 to calculate 
\begin_inset Formula $P(o|c)$
\end_inset

, then adjust word vectors to maximize it.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted4.png
	special width=0.6\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Likelyhood -> NLL objective function
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $L(\theta)=\prod_{t=1}^{T}\prod_{j\in\text{"window"}}P(w_{t+j}|w_{t};\theta)\quad\Rightarrow\quad J(\theta)=-\frac{1}{T}\log L(\theta)$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
We use two vectors per word 
\begin_inset Formula $w$
\end_inset

 — 
\begin_inset Formula $v_{w}$
\end_inset

 for center word; 
\begin_inset Formula $u_{w}$
\end_inset

 for context word.
 For a center word 
\begin_inset Formula $c$
\end_inset

 and context word 
\begin_inset Formula $o$
\end_inset

,
\begin_inset Formula 
\[
P(o|c)=\frac{\exp(u_{o}^{T}v_{c})}{\sum_{w\in V}\exp(u_{w}^{T}v_{c})}
\]

\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] Efficient Estimation of Word Representations in Vector Space, 1301.3781
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Word2vec: extensions and further work
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\begin_inset Quotes eld
\end_inset

Learning from context
\begin_inset Quotes erd
\end_inset

 -> computer vision?
\end_layout

\begin_layout Itemize
The previously shown method is the skip-gram (SG) variant – predicting context
 words given center word.
\end_layout

\begin_layout Itemize
We can also use the continuous bag of words (CBoW) variant – predicting
 center word given context words.
 
\end_layout

\begin_layout Itemize
Negative sampling (a true pair + several 
\begin_inset Quotes eld
\end_inset

noise
\begin_inset Quotes erd
\end_inset

 pairs) can be used for less computational overhead in normalization term.
\end_layout

\begin_layout Itemize
SoTA word representations for a long period of time
\begin_inset Newline newline
\end_inset


\bar under
GloVe: Global Vectors for Word Representation, EMNLP2014
\begin_inset Newline newline
\end_inset

ELMo: Extending a Parser to Distant Domains Using a Few Dozen Partially
 Annotated Examples, ACL2018
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Language Modeling
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Language Modeling
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Language Modeling
\series default
 is the task of predicting what word comes next.
 i.e., 
\begin_inset Formula 
\[
P(x_{t+1}|x_{t},\ldots,x_{2},x_{1})
\]

\end_inset


\end_layout

\begin_layout Itemize
Can also assign a probability to a piece of text (chain rule)
\begin_inset Formula 
\[
P(x_{1},\ldots,x_{T})=\prod_{t=1}^{T}P(x_{t}|x_{t-1},\ldots,x_{1})
\]

\end_inset


\end_layout

\begin_layout Itemize
Flexible enough (chain rule) to deal with issues like
\begin_inset Formula 
\[
P(y_{1},\ldots,y_{M}|x_{1},\ldots,x_{T})=\prod_{m=1}^{M}P(y_{1},\ldots,y_{m}|x_{1},\ldots,x_{T})
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Alex Graves, Supervised Sequence Labelling with Recurrent Neural Networks
 (Book)
\end_layout

\begin_layout Frame
[2] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
N-Gram Language Models
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Pretty old.
 But good to know.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
n-gram examples
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
unigrams: “the”, “students”, “opened”, ”their”
\end_layout

\begin_layout Itemize
bigrams: “the students”, “students opened”, “opened their”
\end_layout

\begin_layout Itemize
trigrams: “the students opened”, “students opened their”
\end_layout

\begin_layout Itemize
four-grams: “the students opened their”
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame
The we can use Markov model, using the assumption that 
\begin_inset Formula $x_{t+1}$
\end_inset

 only depends on the preceding 
\begin_inset Formula $n-1$
\end_inset

 words.
\begin_inset Formula 
\[
P(x_{t+1}|x_{t},\ldots,x_{1})=P(x_{t+1}|x_{t},\ldots,x_{t-n+2})=\frac{P(x_{t+1},x_{t},\ldots,x_{t-n+2})}{P(x_{t},\ldots,x_{t-n+2})}
\]

\end_inset


\end_layout

\begin_layout Frame
Such model can be statically approximated by counting on an corpus.
\end_layout

\begin_layout Frame
Then you can generate language from it in the auto-regressive manner.
\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset

 [1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Recurrent Neural Network
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Neural Language Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
They have became the past since the introduction of transformers – 
\series bold
but they incubated attention
\series default
.
\end_layout

\begin_layout Itemize
Markov model
\begin_inset Newline newline
\end_inset

A larger window will greatly increase model size, and introduce sparsity
 issue.
\end_layout

\begin_layout Itemize
Fixed-window neural language model
\begin_inset Newline newline
\end_inset

MLP for predicting 
\begin_inset Formula $x_{t+1}$
\end_inset

 based on the previous window.
\begin_inset Newline newline
\end_inset

No longer need to store all n-grams.
\begin_inset Newline newline
\end_inset

But fixed window is still too small.
\end_layout

\begin_layout Itemize
We need a neural architecture that can process variable length input.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Y.
 Bengio, A Neural Probabilistic Language Model (2000/2003)
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Recurrent Neural Network
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Core idea: apply the same weights 
\begin_inset Formula $W$
\end_inset

 repeatedly across the whole sequence.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted5.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] A.
 Graves, Generating Sequences With Recurrent Neural Networks
\end_layout

\begin_layout Frame
[2] Alex Graves, Supervised Sequence Labelling with Recurrent Neural Networks
 (Book)
\end_layout

\begin_layout Frame
[3] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Simple RNN Language Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Can process any-length input.
 Trained using cross-entropy loss.
\begin_inset Newline newline
\end_inset

But slow since input tokens are not processed in parallel, and difficult
 to access information for long range.
 Also suffers from vanishing gradient and exploding gradient issue (grad
 clipping) issue.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted6.png
	special width=0.6\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Frame
[2] On the difficulty of training recurrent neural networks, 1211.5063
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Long-Short Term Memory (LSTM)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Forget gate, input gate, and output gate.
 Cell state and hidden state.
 Dominant between 2013-2015.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-0.5cm}
\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted7.png
	special width=0.8\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-0.5cm}
\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Alleviated long-term dependency issue.
 But what about even longer distance dependency?
\end_layout

\begin_layout Itemize
LSTM is much slower than RNN.
 The input sequence is not processed in parallel.
\end_layout

\begin_layout Itemize
People removed several gates from the model and then it becomes Gated Recurrent
 Unit (GRU).
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Frame
[2] Improved Semantic Representations From Tree-Structured Long Short-Term
 Memory Networks, ACL2015
\end_layout

\begin_layout Frame
[3] Very Deep Convolutional Networks for Text Classification, 1606.01781
\end_layout

\begin_layout Frame
[4] Convolutional Neural Networks for Sentence Classification.
 EMNLP 2014
\end_layout

\begin_layout Frame
[5] Parsing Natural Scenes and Natural Language with Recursive Neural Networks,
 ICML2011 
\series bold
Distinguished Paper Awards
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Sequence To Sequence
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Neural Machine Translation (NMT)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
The sequence-to-sequence (seq2seq) model is an example of conditional language
 model.
 The first commercially successful NLP deep learning domain.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted8.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/
\end_layout

\begin_layout Frame
[2] Y.
 Bengio, Neural Machine Translation by Jointly Learning to Align and Translate,
 1409.0473
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Information Bottleneck & Attention
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Sequence-to-sequence with attention mechanism.
 Core Idea: on each decoder step, use direct connection to the encoder to
 focus on a particular part of the source sequence.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted9.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Y.
 Bengio, Neural Machine Translation by Jointly Learning to Align and Translate,
 1409.0473
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Attention Is All You Need (NMT)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Transformer: eschewing recurrence and instead relying entirely on an attention
 mechanism.
 Solved many previously existing issues, e.g., parallelism, interaction distance.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted10.png
	special width=0.4\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Attention Is All You Need, 1706.03762
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Sequence + Multi-Modality
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Sequence + Multimodal
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Retrieval (image<>text)
\begin_inset Newline newline
\end_inset

Early models: Visual Semantic Embedding (Frome 2013)
\begin_inset Newline newline
\end_inset

Contrastive models: CLIP (Radford 2021), ALIGN (Jia 2021), 
\end_layout

\begin_layout Itemize
Captioning (image->text)
\begin_inset Newline newline
\end_inset

Early models: Show and tell (Vinyals 2015)
\end_layout

\begin_layout Itemize
Generation(text->image)
\begin_inset Newline newline
\end_inset

Early models: GAN (Goodfellow 2014)
\end_layout

\begin_layout Itemize
VQA (image+text->text)
\end_layout

\begin_layout Itemize
Multimodal CLS (image+text->label)
\end_layout

\begin_layout Itemize
Vision Sequence?
\begin_inset Newline newline
\end_inset

ViT, SwinT, etc.
\end_layout

\begin_layout Itemize
V+L Foundation Models:
\begin_inset Newline newline
\end_inset

Visual BERT models, ViLT (Kim 2021), Flamingo (Alayrac 2022), BLIP-2 (Junnan
 2023) ......
\end_layout

\begin_layout Itemize
...
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
[1] https://web.stanford.edu/class/cs224n/slides/Multimodal-Deep-Learning-CS224n-K
iela.pdf
\end_layout

\begin_layout Subsection
Pre-training Paradigm
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Only Word Embeddings is Pretrained
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
The past tense (before 2017): Start with pretrained word emb, then learn
 to incorporate context in LSTM/Transformer on 
\series bold
specific task
\series default
.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted11.png
	special width=0.4\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Example
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Consider I 
\series bold
record
\series default
 the 
\series bold
record
\series default
: the two instances of record mean different things.
\end_layout

\begin_layout ExampleBlock
-> See ELMo
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining in Modern NLP
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle

\series bold
All parameters are initialized via pretraining
\series default
 — hiding parts of the input from the model, and train the model to reconstruct
 those parts.
 Does not require datasets for specific task.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted12.png
	special width=0.35\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
This practice leads to exceptionally strong:
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
representations of language
\end_layout

\begin_layout Itemize
parameter initializations
\end_layout

\begin_layout Itemize
probability distributions
\end_layout

\begin_layout Standard
Even if the pre-training task is simply next word prediction [1].
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Quoc V.
 Le, Semi-supervised Sequence Learning, 1511.01432
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Feasible Pretraining Task Depends on Architecture
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
We don't know which architecture is the best.
\end_layout

\begin_layout Itemize

\series bold
Encoder-Only
\series default
 Architecture
\begin_inset Newline newline
\end_inset

Can obtain bidirectional context – but accessing future means it is infeasible
 for language modeling.
\end_layout

\begin_layout Itemize

\series bold
Encoder-Decoder
\series default
 Architecture
\begin_inset Newline newline
\end_inset

What is the best way to pretrain them?
\end_layout

\begin_layout Itemize

\series bold
Decoder-Only
\series default
 Architecture
\begin_inset Newline newline
\end_inset

Suitable for LMs.
 Nice for generation.
 Cannot condition on future words.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Encoder-Only Pretraining
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining for Encoder-Only Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
It has got bi-directional context (can condition on the future), so cannot
 do language modeling.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted13.png
	special width=0.5\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Reconstructing masked input: Masked LM
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Stanford University is located in __________, California.
\end_layout

\begin_layout ExampleBlock
I put ___ fork down on the table.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Bidirectional Encoder Representations from Transformers, 2018
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Masked LM — BERT
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Bidirectional Encoder Representations from Transformers, 2018
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-0.3cm}
\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted14.png
	special width=0.9\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\backslash
vspace{-0.9cm}
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Task #1: Masked LM
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Randomly replace 15% of all WordPiece tokens.
\end_layout

\begin_deeper
\begin_layout Enumerate
80%: w/ [MASK] token
\end_layout

\begin_layout Enumerate
10%: w/ random token
\end_layout

\begin_layout Enumerate
with itself 10% of the time
\end_layout

\end_deeper
\begin_layout Itemize
Then predict the masked word.
\end_layout

\end_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Task #2: Next Sentence Pred
\end_layout

\end_inset


\end_layout

\begin_layout Block
Bert pretraining input is a pair of sentence
\end_layout

\begin_deeper
\begin_layout Itemize
Sentence B is the next sentence of A 50% of the time
\end_layout

\begin_layout Itemize
Sentence B is not next sentence of A 50% of the time
\end_layout

\end_deeper
\begin_layout Block
Beneficial for some downstream tasks like QA and NLI.
\end_layout

\begin_layout Block
Demonstrated not necessary by later works.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
More on BERT
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Model Size
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
BERT-base: 12 layers, 768-dim hidden states, 12 attention heads, 110 million
 params.
\end_layout

\begin_layout Itemize
BERT-large: 24 layers, 1024-dim hidden states, 16 attention heads, 340 million
 params.
\end_layout

\begin_layout Itemize
PyTorch-ResNet50-ILSVRC: 25.6M params
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Issues
\end_layout

\end_inset


\end_layout

\begin_layout Block
Does not naturally lead to autoregressive methods.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Extensions
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
RoBERTa: mainly just train BERT for longer and remove next sentence prediction.
\begin_inset Newline newline
\end_inset


\bar under
More compute, more data can improve pretraining even when not changing the
 underlying Transformer encoder.
\end_layout

\begin_layout Itemize
SpanBERT: masking contiguous spans of words makes pretraining task harder.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] RoBERTa: A Robustly Optimized BERT Pretraining Approach, 1907.11692
\end_layout

\begin_layout Frame
[2] SpanBERT: Improving Pre-training by Representing and Predicting Spans,
 1907.10529
\end_layout

\begin_layout Subsection
Encoder-Decoder Pretraining
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining for Encoder-Decoder Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
We can do something like language modeling, but a prefix of every input
 is provided to encoder and is not predicted.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted15.png
	special width=0.36\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\begin_inset Formula 
\begin{align*}
h_{1,}\ldots,h_{T} & ={\color{blue}\text{Encoder}}(w_{1},\ldots,w_{T})\\
h_{T+1},\ldots,h_{2T} & =\text{{\color{red}Decoder}}(w_{T+1},\ldots,w_{2T};h_{1},\ldots,h_{T})
\end{align*}

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The encoder portion benefits from bidirectional context.
\end_layout

\begin_layout Itemize
The decoder portion trains the whole model through language modeling.
 (triangular attn mask)
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text
 Transformer, 1910.10683
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Text-to-Text w/ Span-Corruption Pretraining
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text
 Transformer, 1910.10683
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted16.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hrulefill
\end_layout

\end_inset


\end_layout

\begin_layout Frame

\size small
Every task considered is cast as feeding (task-specific) text prefix and
 input, and then generating some target text (teacher-forcing objective).
\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted17.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
More on T5
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
T5 Can be finetuned to answer a wide range of questions, retrieving knowledge
 from its parameters.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Model Size
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\backslash
small
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Small
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Base
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Large
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#Params
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60M
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
220M
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
770M
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Flan-T5: Scaling Instruction-Finetuned Language Models, 2210.11416
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset CommandInset label
LatexCommand label
name "page:flan-t5"

\end_inset


\end_layout

\begin_layout Block

\size footnotesize
Instruction/chain-of-thought finetuning, while scaling number of tasks and
 model size.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Block
\begin_inset Graphics
	filename pasted18.png
	special width=0.7\linewidth

\end_inset


\end_layout

\begin_layout Block

\end_layout

\end_deeper
\begin_layout Subsection
Decoder-Only Pretraining
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Pretraining for Decoder-Only Model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
All the biggest pretrained models are Decoders.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Pre-training
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Graphics
	filename pasted19.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Block
\begin_inset Formula 
\begin{align*}
h_{1},\ldots,h_{T} & =\text{Decoder}(w_{1},\ldots,w_{T})\\
w_{t} & \sim Ah_{t-1}+b
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Fine-tuning
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Graphics
	filename pasted20.png
	special width=\linewidth

\end_inset


\begin_inset Formula 
\begin{align*}
h_{1},\ldots,h_{T} & =\text{Decoder}(w_{1},\ldots,w_{T})\\
y & \sim Ah_{T}+b
\end{align*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-1: Generative Pretrained Transformer
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Improving Language Understanding by Generative Pre-Training, 2018
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: generative pre-training and discriminative fine-tuning.
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Transformer Decoder w/ 12 layers.
 117M params.
 Trained on BooksCorpus (> 7k books).
 Contains long spans of contiguous text (long distance dependency learning).
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Unsupervised Pretraining
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_layout Block
Given an unsup corpus of tokens 
\begin_inset Formula 
\[
U=\{u_{1},\ldots,u_{n}\}
\]

\end_inset


\end_layout

\begin_layout Block
Standard LM for maximizing likelihood
\begin_inset Formula 
\[
L_{1}(U)=\sum_{i}\log P(u_{i}|u_{i-k},\ldots,u_{i-1};\Theta)
\]

\end_inset

the 
\begin_inset Formula $k$
\end_inset

 is context window size.
\end_layout

\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Supervised Fine-tuning
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_layout Block
Dataset 
\begin_inset Formula $C$
\end_inset

 where 
\begin_inset Formula $x_{1},\ldots,x_{m}$
\end_inset

 has label 
\begin_inset Formula $y$
\end_inset

.
\end_layout

\begin_layout Block
Last block activation 
\begin_inset Formula $h_{m}^{l}$
\end_inset

 for prediction
\begin_inset Formula 
\begin{align*}
P(y|x_{1},\ldots,x_{m}) & =\text{softmax}(h_{m}^{l}W_{y})
\end{align*}

\end_inset


\begin_inset Formula 
\[
L_{2}(C)=\sum_{(x,y)}\log P(y|x_{1},\ldots,x_{m})
\]

\end_inset


\end_layout

\begin_layout Block
Pretraining as regularization
\begin_inset Formula 
\[
L_{3}(C)=L_{2}(C)+\lambda\times L_{1}(C)
\]

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-1 :: Architecture
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Generative model can learn good representation for discriminative task.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted21.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-2
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Language Models are Unsupervised Multitask Learners, 2019
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: w/ Larger dataset, LM begins to learn sup tasks w/o sup label.
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
GPT-2 is a (117M, 345M, 762M, 1.5B) decoder model, almost same as GPT architectur
e.
\end_layout

\begin_layout Itemize
Building LMs which learn to perform tasks from their naturally occuring
 demonstrations.
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Pre-training
\end_layout

\end_inset


\end_layout

\begin_layout Block
Same as GPT-1.
\end_layout

\begin_layout Block
Although there should be something hidden in details.
\end_layout

\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Fine-tuning
\end_layout

\end_inset


\end_layout

\begin_layout Block
Same as GPT-1.
\end_layout

\begin_layout Block
Although there should be something hidden in details.
\end_layout

\end_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Limitations
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
Tends to 
\begin_inset Quotes eld
\end_inset

stray off topic
\begin_inset Quotes erd
\end_inset

 when generating long text.
\end_layout

\begin_layout ExampleBlock
Can become repetitive or nonsensical when generating long text.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Language Models are Few-Shot Learners, 2005.14165
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: Very large LM 
\begin_inset Quotes eld
\end_inset

learns
\begin_inset Quotes erd
\end_inset

 without gradient within contexts
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
small
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
GPT-3 is 175B model (800GB disk), using the same arch as GPT-2, evaluated
 without fine-tuning.
\end_layout

\begin_layout ExampleBlock
Apart from sampling from LM's distribution, and fine-tuning them and take
 their distributions, very large LMs enables in-context learning (as well
 as prompt engineering).
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
6cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted23.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted24.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3 :: In-Context Learning (Inference)
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
No gradient update at all.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
4cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted25.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
4cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted26.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
4cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted27.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3 :: Model Size Scaling Law
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Larger model -> requires larger batch size but smaller learning rate.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted22.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted28.png
	special width=0.8\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-3.5
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: ChatGPT (2022) is fine-tuned version of GPT-3.5
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
No much technical details are disclosed from OpenAI.
\end_layout

\begin_layout Itemize
(Chat) gpt-3.5-turbo
\end_layout

\begin_layout Itemize
(Text completion) text-davinci-003
\end_layout

\begin_layout Itemize
(Text completion) text-davinci-002
\end_layout

\begin_layout Standard
FYI: text-davinci-001 migbt be InstructGPT-3, not included in GPT-3.5.
\end_layout

\end_deeper
\begin_layout Frame
InstructGPT will be covered later.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
[1] https://en.wikipedia.org/wiki/GPT-3#GPT-3.5
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
GPT-4
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
GPT-4 Technical Report, 2303.08774
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
TL;DR: larger scale; multi-modality extension; human-level
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
Did not present much useful information other than showing off.
\end_layout

\end_deeper
\begin_layout Itemize

\size small
GPT-4 is a Transformerbased model pre-trained to predict the next token
 in a document.
\end_layout

\begin_layout Itemize

\size small
The post-training alignment process results in improved performance on measures
 of factuality and adherence to desired behavior.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted36.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Figure source: https://arxiv.org/pdf/2303.18223.pdf
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Why does next-word prediction work?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Taken from Jensen Huang and Ilya's Talk: https://lifearchitect.ai/ilya/
\end_layout

\begin_layout Quotation

\size small
So, I’d like to take a small detour and to give an analogy that will hopefully
 clarify why more accurate prediction of the next word leads to more understandi
ng, real understanding.
 Let’s consider an example.
 
\bar under
Say you read a detective novel.
 It’s like complicated plot, a storyline, different characters, lots of
 events, mysteries like clues, it’s unclear.
 Then, let’s say that at the last page of the book, the detective has gathered
 all the clues, gathered all the people
\bar default
 and saying, “okay, I’m going to reveal the identity of whoever committed
 the crime and that person’s name is”.
 
\bar under
Predict that word.

\bar default
 Predict that word, exactly.
 My goodness.
 Right? Yeah, right.
 Now, there are many different words.
 But predicting those words better and better and better, the understanding
 of the text keeps on increasing.
 GPT-4 predicts the next word better.
\end_layout

\begin_layout Quotation
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
flushright
\end_layout

\end_inset

– Ilya
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Natural Langauge Genration
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Natural Language Generation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Previous discussion only covers a small part of generation.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Plot Generation
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Graphics
	filename pasted29.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Visual Description
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Graphics
	filename pasted30.png
	special width=0.6\linewidth

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Outline-Conditioned Generation with Dynamic Plot State Tracking, EMNLP20
\end_layout

\begin_layout Frame
[2] A Hierarchical Approach for Generating Descriptive Image Paragraphs,
 CVPR17
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Categorization of NLG Tasks
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
One way of formalizing categorization this is by 
\series bold
entropy
\series default
.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset Graphics
	filename pasted31.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Open-ended generation
\begin_inset Newline newline
\end_inset

the output distribution still has high freedom
\end_layout

\begin_layout Itemize
Non-open-ended generation
\begin_inset Newline newline
\end_inset

the input mostly determines the output generation.
\end_layout

\begin_layout Itemize
The two types of tasks require different 
\series bold
decoding
\series default
 and/or 
\series bold
training
\series default
 approaches.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Autoregressive Generation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
GPT Family is auto-regressive.
 Note, non-autoregressive LM models do exist.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Model 
\begin_inset Formula $f(\cdot),$
\end_inset

Vocab 
\begin_inset Formula $V$
\end_inset

, Score 
\begin_inset Formula $S=f(\{y_{<t}\},\theta\}\in R^{V}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Formula 
\begin{align*}
P(y_{t}=w|\{y_{<t}\}) & =\frac{\exp(S_{w})}{\sum_{w'\in V}\exp(S_{w'})}\\
\hat{y}_{t} & \leftarrow P(y_{t}|y_{1},\ldots y_{t-1})\\
\hat{y}_{t+1} & \leftarrow P(y_{t+1}|y_{1},\ldots,y_{t-1},\hat{y}_{t})\\
\hat{y}_{t+2} & \leftarrow P(y_{t+2}|y_{1},\ldots,y_{t-1},\hat{y}_{t},\hat{y}_{t+1})\\
\ldots & \ldots\\
\mathcal{L} & =-\sum_{t=1}^{T}\log P(y_{t}^{*}|\{y_{<t}^{*}\})
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
For non-open-ended tasks (e.g., NMT), we typically use encoder-decoder model,
 where the autoregressive model serves as the decoder, and the bidirectional
 encoder deals with the inputs.
\end_layout

\begin_layout Itemize
For open-ended tasks (e.g., story generation), autoregressive generation is
 often the only component.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decoding Algorithms
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Decoding algorithm defines a function to select to token from the distribution.
\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Decoding algorithm 
\begin_inset Formula $g(\cdot)$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Formula 
\[
\hat{y}_{t}=g\big\{ P(y_{t}|\{y_{<t}\})\big\}
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Greedy Decoding
\series default
: highest probability for the next token at each step.
\begin_inset Formula 
\[
\hat{y}_{t}=\arg\max_{w\in V}P(y_{t}=w|\{y_{<t}\})
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Beam Search
\series default
: find strings that maximizes the log-prob, with wider exploration of candidates.
 Frequently used in tasks like NMT.
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Issue
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
Good for low-entropy tasks like MT and summarization.
\end_layout

\begin_layout Standard
Bad for open-ended generation – most likely going repetitive.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decoding :: Random Sampling
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Sample a token from the token distribution
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Formula 
\[
\hat{y}_{t}\sim P(y_{t}=w|\{y_{<t}\})
\]

\end_inset


\end_layout

\begin_layout Itemize
Vanilla sampling may fall into the long-tail of the distribution (the long
 tail has a considerable mass), where many tokens are really wrong.
\end_layout

\begin_layout Itemize
Top-k sampling.
 Only sampling within the top-k (e.g., 50) tokens.
\end_layout

\begin_deeper
\begin_layout Itemize
Larger 
\begin_inset Formula $k$
\end_inset

 leads to more diverse but risky outputs.
\end_layout

\begin_layout Itemize
Smaller 
\begin_inset Formula $k$
\end_inset

 leads to safe but generic outputs.
\end_layout

\begin_layout Itemize
Not adaptive to the distribution shape,either too small or too large.
\end_layout

\end_deeper
\begin_layout Itemize
Top-
\begin_inset Formula $p$
\end_inset

 (nucleus) sampling.
 Sampling from the tokens in top-
\begin_inset Formula $p$
\end_inset

 cumulative probability mass.
\end_layout

\begin_layout Itemize
Other decoding algorithms...
 (re-ranking; will cover it later)
\end_layout

\begin_layout Itemize
Scaling randomness through 
\series bold
Temperature
\series default
 (See Hinton distillation)
\begin_inset Formula 
\[
P(y_{t}=w|\ldots)=\frac{\exp(S_{w}/\tau)}{\sum_{w'\in V}\exp(S_{w'}/\tau)}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] The Curious Case of Neural Text Degeneration, ICLR20
\end_layout

\begin_layout Frame
[2] G.
 Hinton, Distilling the Knowledge in a Neural Network, NIPSw2014
\end_layout

\begin_layout Section
Large Language Models
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\bar under
Part II: Large Language Models
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quote
Is scaling up everything the ultimate answer towards intelligence?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Scaling Law
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Scaling Law [1/2]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Scaling can largely improve the model capacity of LLMs, and show emergent
 properties.
\end_layout

\begin_layout Standard

\size footnotesize
Power law between model performance and model size (
\begin_inset Formula $N$
\end_inset

), dataset size (
\begin_inset Formula $D$
\end_inset

), and amount of compute (
\begin_inset Formula $C$
\end_inset

).
\begin_inset Newline newline
\end_inset

These notations are constants: 
\begin_inset Formula $N_{c}$
\end_inset

, 
\begin_inset Formula $D_{c}$
\end_inset

, 
\begin_inset Formula $C_{c}$
\end_inset

, 
\begin_inset Formula $\alpha_{N}$
\end_inset

, 
\begin_inset Formula $\alpha_{D}$
\end_inset

, 
\begin_inset Formula $\alpha_{C}$
\end_inset

 to be found through curve fitting.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Kaplan Scaling Law (OpenAI)
\end_layout

\end_inset


\end_layout

\begin_layout Block
\begin_inset Graphics
	filename pasted38.png
	special width=\linewidth

\end_inset


\begin_inset Formula 
\[
L(N)\approx\Big[\frac{N_{c}}{N}\Big]^{\alpha_{N}}\quad L(D)\approx\Big[\frac{D_{c}}{D}\Big]^{\alpha_{D}}\quad L(C)\approx\Big[\frac{C_{c}}{C}\Big]^{\alpha_{C}}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] A Survey of Large Language Models, 2303.18223
\end_layout

\begin_layout Frame
[2] (Kaplan Scaling Law) Scaling Laws for Neural Language Models, 2001.08361
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Scaling Law [2/2]
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Given a fixed FLOPs budget, how should one trade-off model size and the
 number of training tokens?
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Chinchilla Scaling Law (DeepMind)
\end_layout

\end_inset


\end_layout

\begin_layout Block

\size footnotesize
Minimizing pretraining loss 
\begin_inset Formula $L$
\end_inset

 under the constraint FLOPs
\begin_inset Formula $(N,D)=C$
\end_inset

 for optimal allocation of 
\begin_inset Formula $N$
\end_inset

 and 
\begin_inset Formula $D$
\end_inset

:
\size default

\begin_inset Formula 
\[
N_{\text{opt}}(C),D_{\text{opt}}(C)=\underset{N,D\text{ s.t. FLOPs}(N,D)=C}{\text{argmin}}L(N,D)
\]

\end_inset

With many analysis, they propose the following functional form to fit:
\begin_inset Formula 
\[
\hat{L}(N,D)\triangleq E+\frac{A}{N^{\alpha}}+\frac{B}{D^{\beta}}\qquad\text{const.}(A,B,E,\alpha,\beta)
\]

\end_inset

After estimating the coefficients using L-BFGS on the Huber loss, they obtain
\begin_inset Formula 
\[
N_{\text{opt}}(C)=G\big[\frac{C}{6}\big]^{a}\quad D_{\text{opt}}(C)=G^{-1}\big[\frac{C}{6}\big]^{b}\quad\text{where }G=\big(\frac{\alpha A}{\beta B})^{\frac{1}{\alpha+\beta}},a=\frac{\beta}{\alpha+\beta},b=\frac{\alpha}{\alpha+\beta}
\]

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
But emergent properties cannot be predicted through scaling law.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
[1] Chinchilla: Training Compute-Optimal Large Language Models, 2203.15556
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Fine-Tuning & Alignment
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Instruction/Alignment Tuning
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
InstructGPT: Training language models to follow instructions with human
 feedback, 2203.02155
\end_layout

\begin_layout Standard

\size footnotesize
GPT-3 is not well aligned to human intent.
 Sometimes generates unsafe answers.
\end_layout

\end_deeper
\begin_layout Frame

\size footnotesize
This is due to the training task (predicting next token on web-based corpus)
 is different from 
\begin_inset Quotes eld
\end_inset

follow the user's instructions helpfully and safely
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\end_inset


\begin_inset Graphics
	filename pasted34.png
	special width=0.7\linewidth

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\bar under
Instruction Finetuning:
\bar default
 collect examples of (instruction, output) pairs across many tasks and ft
 the LM.
 See Flan-T5 (page 
\begin_inset CommandInset ref
LatexCommand ref
reference "page:flan-t5"
plural "false"
caps "false"
noprefix "false"

\end_inset

) for examples.
 Evaluate on unseen task.
\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Training language models to follow instructions with human feedback,
 2203.02155 (OpenAI)
\end_layout

\begin_layout Frame
[2] Finetuned Language Models Are Zero-Shot Learners, 2109.01652 (Google)
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHF: Reinforcement Learning from Human Feedback
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
InstructGPT: Training language models to follow instructions with human
 feedback, 2203.02155
\end_layout

\end_deeper
\begin_layout Frame

\bar under
TL;DR: use human preferences as a reward signal to fine-tune our models.
\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted35.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHF :: Reward Modeling & Reinforcement LG
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
InstructGPT: Training language models to follow instructions with human
 feedback, 2203.02155
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Supervised Fine-Tuning (SFT): Start with GPT-3 on the instruction dataset.
\end_layout

\begin_layout Enumerate
Reward Modeling (RM): 6B model, denoted as 
\begin_inset Formula $r_{\theta}(x,y_{l})$
\end_inset


\begin_inset Newline newline
\end_inset

input=(prompt, response), output=scalar reward.
\begin_inset Newline newline
\end_inset

A labler is presented with 
\begin_inset Formula $K=4\sim9$
\end_inset

 responses to rank – i.e., 
\begin_inset Formula $(_{2}^{K})$
\end_inset

 comparisons.
\begin_inset Formula 
\[
\mathcal{L}_{\text{RM}}(\theta)=\frac{1}{(_{2}^{K})}\mathbb{E}_{(x,y_{w},y_{l})\sim D}\Big\{\log\big(\sigma[r_{\theta}(x,y_{w})-r_{\theta}(x,y_{l})]\big)\Big\}
\]

\end_inset

where 
\begin_inset Formula $x$
\end_inset

 is prompt, 
\begin_inset Formula $y$
\end_inset

 is completion.
 The 
\begin_inset Formula $y_{w}$
\end_inset

 is prefered out of the pair 
\begin_inset Formula $(y_{w},y_{l})$
\end_inset

.
 The 
\begin_inset Formula $D$
\end_inset

 is dataset.
\end_layout

\begin_layout Enumerate
Reinforcement Learning w/ PPO:
\begin_inset Newline newline
\end_inset

Environment: bandit environment which presents a random customer prompt
 and expects a response to prompt.
\begin_inset Newline newline
\end_inset

Also add per-token KL penalty from SFT model at each token to mitigate RM
 over-optimization 
\begin_inset Formula 
\begin{align*}
\text{Obj}(\phi) & =\mathbb{E}_{(x,y)\sim D_{\pi_{\phi}^{RL}}}\big[r_{\theta}(x,y)-\beta\log(\pi_{\phi}^{RL}(y|x)/\pi^{SFT}(y|x))\big]\\
 & +\gamma\mathbb{E}_{x\sim D_{pretrain}}\big[\log(\pi_{\phi}^{RL}(x))\big]
\end{align*}

\end_inset

where 
\begin_inset Formula $\pi_{\phi}^{RL}$
\end_inset

 is RL policy, 
\begin_inset Formula $\pi^{SFT}$
\end_inset

 is supervised trained model, 
\begin_inset Formula $D_{pretrain}$
\end_inset

 is pretrain distribution, 
\begin_inset Formula $\beta$
\end_inset

 is KL reward coef.
 For PPO model, 
\begin_inset Formula $\gamma=0$
\end_inset

.
 The 
\begin_inset Formula $\gamma$
\end_inset

 term introduces pretraining gradients in order to fix performance regression
 on public NLP tasks.
 Gradient ascent.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
ChatGPT!
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
https://openai.com/blog/chatgpt
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Methods
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Trained using RLHF (same as InstructGPT).
\end_layout

\begin_layout Itemize
Slightly different in data collection setup.
\end_layout

\begin_layout Itemize
Performed several iterations of the (RM, RLHF) steps.
\end_layout

\end_deeper
\begin_layout Standard
Not really much information.
\end_layout

\begin_layout Standard
:-(
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
RL is very tricky to get right.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Reward hacking (a common problem in RL)
\begin_inset Quotes erd
\end_inset

 ChatBot are rewarded by responses that seem authorative and helpful, regardless
 of truth.
\end_layout

\begin_layout Itemize
This can result in making up facts and hallucinations.
\end_layout

\begin_layout Itemize
Models (RM) of human preference are even more unreliable.
\end_layout

\begin_layout Itemize

\bar under
AI misalignment is a real concern.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
RLHF Datarequirements?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
RLAIF! RL from AI Feedback.
 
\end_layout

\begin_layout Itemize
Constitutional AI: Harmlessness from AI Feedback, 2212.08073
\end_layout

\begin_layout Itemize
Large Language Models Can Self-Improve, 2210.11610
\begin_inset Newline newline
\end_inset

Generate 
\begin_inset Quotes eld
\end_inset

high-confidence
\begin_inset Quotes erd
\end_inset

 rationale-augmented answers using CoT prompting and self-consistency.
 And then fine-tune LN with those generated answers.
\end_layout

\begin_layout Itemize
STaR: Bootstrapping Reasoning With Reasoning, 2203.14465
\begin_inset Newline newline
\end_inset

Generate chain-of-thought data.
 Fine-tune LM itself with generated data.
\end_layout

\begin_layout Itemize
Convergence issue?
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
Further readings:
\end_layout

\begin_layout Frame
[1] Learning to summarize from human feedback, 2009.01325
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Emergent Properties (e.g., ICL)
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
In-Context Learning (ICL) a.k.a.
 Prompt Engineering
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
One of LLM's emergent properties when model is large enough.
 Small model, e.g., BERT do not exhibit it.
\begin_inset Newline newline
\end_inset

Should you try prompt engineering a small LM, you'll find the model not
 smart at all.
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted39.png
	special width=\linewidth

\end_inset


\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\end_deeper
\begin_layout ColumnsTopAligned
\begin_inset Graphics
	filename pasted40.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] GPT-3: Language Models are Few-Shot Learners, 2005.14165
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Chain-of-Thought Prompting
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
One of LLM's emergent abilities.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
A series of intermediate reasoning steps – significantly improves the ability
 of large language models to perform complex reasoning.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Graphics
	filename pasted32.png
	special width=\linewidth

\end_inset


\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,
 2201.11903
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Zero-Shot Chain-of-Thought
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
LLMs are decent zero-shot reasoners by simply adding 
\bar under
“Let’s think step by step”
\bar default
 before each answer.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted33.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
Two prompts make a NeurIPS 2022 paper?
\end_layout

\end_deeper
\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Large Language Models are Zero-Shot Reasoners, NeurIPS 2022 (2005.11916)
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
New Dark Art of 
\begin_inset Quotes eld
\end_inset

Prompt Engineering?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Asking LLM for reasoning
\end_layout

\begin_layout Itemize
Stable diffusion prompts (e.g., artstation, depth of field, 4k, masterpiece)
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Jail-breaking
\begin_inset Quotes erd
\end_inset

 LLMs (societal impact & ethics)
\end_layout

\begin_layout Itemize
Use google code header (e.g., 
\begin_inset Quotes eld
\end_inset

Copyright (C) 2022, Google LLC
\begin_inset Quotes erd
\end_inset

) to generate more 
\begin_inset Quotes eld
\end_inset

professional
\begin_inset Quotes erd
\end_inset

 code?
\end_layout

\begin_layout Itemize
etc.
\end_layout

\begin_layout Standard
Further readings:
\end_layout

\begin_layout Itemize
https://en.wikipedia.org/wiki/Prompt_engineering
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
What about visual prompting in computer vision?
\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
Prompt engineering is an emergent property.
\end_layout

\begin_layout AlertBlock
Does this really work for small-sized vision models?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Prompt Engineering Hints
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Reference: https://arxiv.org/pdf/2303.18223.pdf
\end_layout

\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Key Ingredients
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\size small
Task description
\begin_inset Newline newline
\end_inset

and necessary clarifications
\end_layout

\begin_layout Itemize

\size small
Input data format
\begin_inset Newline newline
\end_inset

e.g., linearization of structured data
\end_layout

\begin_layout Itemize

\size small
Contextual information
\begin_inset Newline newline
\end_inset

e.g., background of the topic
\end_layout

\begin_layout Itemize

\size small
Prompt style
\begin_inset Newline newline
\end_inset

e.g., 
\begin_inset Quotes eld
\end_inset

Let us think step by step
\begin_inset Quotes erd
\end_inset

,
\begin_inset Newline newline
\end_inset

e.g., 
\begin_inset Quotes eld
\end_inset

You are an expert on this task
\begin_inset Quotes erd
\end_inset

,
\end_layout

\end_deeper
\begin_layout Column
5.5cm
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Design Principles
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\size small
Expressing the task goal clearly.
\end_layout

\begin_layout Itemize

\size small
Decomposing into easy, detailed sub-tasks.
\end_layout

\begin_layout Itemize

\size small
Providing few-shot demonstrations.
\end_layout

\begin_layout Itemize

\size small
Utilizing model-friendly format.
\begin_inset Newline newline
\end_inset

e.g., using ### or 
\begin_inset Quotes eld
\end_inset


\begin_inset Quotes erd
\end_inset


\begin_inset Quotes erd
\end_inset

 as stop symbol for OpenAI model to separate instruction and context.
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Leaderboards
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Benchmark & Leaderboards
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Where you can pick an LLM for further work.
\end_layout

\begin_layout Itemize
Open LLM Leaderboard (HuggingFace)
\begin_inset Newline newline
\end_inset

https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
\end_layout

\begin_layout Itemize
[1] Holistic Evaluation of Language Models (Piercy Liang; Stanford)
\begin_inset Newline newline
\end_inset

https://crfm.stanford.edu/helm/latest/
\end_layout

\begin_layout Itemize
[2] Measuring Massive Multitask Language Understanding, ICLR21
\end_layout

\begin_layout Itemize
[3] Beyond the Imitation Game: Quantifying and extrapolating the capabilities
 of language models, 2206.04615
\end_layout

\begin_layout Itemize
...
\end_layout

\begin_layout AlertBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Some Notes if you want to try LLM locally
\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{
\backslash
linewidth}{!}{
\end_layout

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="6">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Disk Space
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Inference Batch
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Inference Precition
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Inference Mode
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GPU Requirement
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Falcon-7B-Instruct
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
14GB
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bf16
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Single GPU
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1 * 16GB
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Falcon-40B-Instruct
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80GB
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bf16
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pipeline Parallel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4 * 24GB
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout AlertBlock
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Non-GPT sota LLMs
\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted37.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] A Survey of Large Language Models, 2303.18223
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Graphics
	filename pasted41.png
	special width=\linewidth

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Non-GPT SoTA LLMs
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
We've got just, toooooooooooooooooooo many of them.
\end_layout

\end_deeper
\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
resizebox{
\backslash
linewidth}{!}{
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="5">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Name
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Year
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Trainer
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
#Params
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Comment
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
T5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2019
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Google
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Already introduced in previous slides.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
T0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2021
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
PaLM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Google
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OPT
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
175B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GLM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tsinghua
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
130B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Galactica
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
120B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BLOOMZ
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2022
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
176B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LLaMA v1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2023
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
65B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Alpaca
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Stanford
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LLaMA v2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Falcon
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
TII.UAE
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Vicuna
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Berkeley
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Position Embedding
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Position Embedding
\end_layout

\end_inset


\end_layout

\begin_layout Frame
Absolute position embededing (vanilla transformer)
\begin_inset Formula 
\[
x_{i}=x_{i}+p_{i}
\]

\end_inset


\end_layout

\begin_layout Frame
Relative position embedding (T5, Gopher)
\begin_inset Formula 
\[
A_{ij}=W_{q}x_{i}x_{j}^{T}W_{k}^{T}+r_{i-j}
\]

\end_inset


\end_layout

\begin_layout Frame
Rotary position embedding (LLaMA, PaLM).
 Unifies absolute and relative.
\begin_inset Formula 
\[
A_{ij}=W_{q}x_{i}R_{\theta,i-j}x_{j}^{T}W_{k}^{T}
\]

\end_inset


\end_layout

\begin_layout Frame
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
scriptsize
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Survey: https://arxiv.org/pdf/2303.18223.pdf
\end_layout

\begin_layout Frame
[2] Self-Attention with Relative Position Representations, 1803.02155
\end_layout

\begin_layout Frame
[3] RoFormer: Enhanced Transformer with Rotary Position Embedding, 2104.09864
\end_layout

\begin_layout Frame
[4] https://blog.eleuther.ai/rotary-embeddings/
\end_layout

\begin_layout Subsection
Decoding Algorithm
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Decoding Algorithms
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
Performance improvements for 
\begin_inset Quotes eld
\end_inset

free
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Block
\begin_inset Argument 2
status open

\begin_layout Plain Layout
The Re-ranking Paradigm for Decoding
\end_layout

\end_inset


\end_layout

\begin_layout Block
1.
 Decode a bunch of sequences.
\end_layout

\begin_layout Block
2.
 Define a score to approximate sequence quality and re-rank by this score.
\end_layout

\end_deeper
\begin_layout Subsection
PEFT
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Parameter Efficient Fine-Tuning
\end_layout

\end_inset


\end_layout

\begin_layout Frame
Adapter Tuning
\end_layout

\begin_layout Frame
Prefix Tuning
\end_layout

\begin_layout Frame
Prompt Tuning
\end_layout

\begin_layout Frame
LoRA: Low-Rank Adaptation (easier than prefix tuning)
\end_layout

\begin_layout Frame
Learns a low-rank 
\begin_inset Quotes eld
\end_inset

diff
\begin_inset Quotes erd
\end_inset

 between the pretrained and fine-tuned weight matrices.
\end_layout

\begin_layout Frame
[1] http://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture9-pretraining.pd
f
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LoRA: Low-Rank Adaptation
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Multi-Modality
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Multi-Modality
\end_layout

\end_inset


\end_layout

\begin_layout Frame
[1] Language Is Not All You Need: Aligning Perception with Langauge Models
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Multi-Modal Prompting?
\end_layout

\end_inset


\end_layout

\begin_layout Frame
Multimodal “Chain of Thought” (Zhang et al., 2023)
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Multi-Modal Scaling Law?
\end_layout

\end_inset


\end_layout

\begin_layout Frame
Scaling laws for generative mixed modal language models
\end_layout

\begin_layout Subsection
Extra Capability
\end_layout

\begin_layout Standard
external tool
\end_layout

\begin_layout Standard
math
\end_layout

\begin_layout Standard
coding
\end_layout

\begin_layout Standard
etc.
\end_layout

\begin_layout Subsection
Societal Impact & Ethics
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Generated Text Detection
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
LLM :: Security & Ethics
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
For instance, jail break attacks to bypass the NSFW/Ethics check.
\end_layout

\end_deeper
\begin_layout Frame
AI Alignment Forum: https://www.alignmentforum.org/
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Make Titles Informative.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Theorem
On first slide.
\end_layout

\begin_layout Corollary
On second slide.
\end_layout

\begin_layout Corollary

\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Section
Closing
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Future Topics
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout FrameSubtitle
What is OpenAI doing recently? Secretly training GPT-5?
\begin_inset Newline newline
\end_inset

https://openai.com/research
\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame
More natural ways to prompt stable diffusion.
\end_layout

\begin_layout Frame
Detecting and source-tracking AI-generated contents.
\end_layout

\begin_layout Frame
Safety and ethics: reduce NSFW from Stable diffusion, prevent LLM jailbreaking.
\end_layout

\begin_deeper
\begin_layout ColumnsTopAligned

\end_layout

\begin_deeper
\begin_layout Column
5cm
\end_layout

\begin_layout Theorem
In left column.
\end_layout

\begin_layout Column
5cm
\end_layout

\begin_layout Corollary
In right column.
\begin_inset Newline newline
\end_inset

New line
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Q&A Session
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Quote
Congrats!
\begin_inset Newline newline
\end_inset

You have gone through not only CS224N, but also some latest papers.
\end_layout

\begin_layout Quote
You are able to read LLM papers afterwards without much doubt.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
\begin_inset Argument 2
status open

\begin_layout Plain Layout
Fun Fact
\end_layout

\end_inset


\end_layout

\begin_layout ExampleBlock
The survey 
\begin_inset Quotes eld
\end_inset

A Survey of Large Language Models
\begin_inset Quotes erd
\end_inset

 (2303.18223) cited 610 papers.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vfill
\backslash
footnotesize
\end_layout

\end_inset


\end_layout

\begin_layout Standard
* NLP topics not covered: including but not limited to question answering,
 linguistics, TreeLSTM/TreeRNN or CNN for sequence modeling, code generation,
 coreference resolution, model interpretability,
\begin_inset Newline newline
\end_inset

* LLM topics not covered: including but not limited to dataset collection
 and curating, LLM training details, LLM quantization, LLM for task planning,
 LLM evaluation and benchmarking, LLM interpretability,
\end_layout

\end_deeper
\end_body
\end_document
