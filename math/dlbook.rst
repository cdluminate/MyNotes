Deep Learning, Ian Goodfellow, et al
====================================

Part I: Applied Math and ML Basics
----------------------------------

Part II: Deep Networks: Modern Practices
----------------------------------------

Ch6: Deep Feedforward Networks
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The intermediate layers are called hidden layers because the training data
does not show the desired output for each of the layers. (p. 168)

Feed forward nets: function approximation machine that is designed to achieve
statistical generalization, occasionally drawing some insights from what we
know about the brain, rather than as model of brain function. (p. 168)

A general principle: improving models by learning features. (p. 169)

Output units can also be used as hidden units. (p. 180)

Linear units does not saturate. (p. 181)

Most common output type: linear, sigmoid, softmax. (p. 186)

There is not guiding theoretical principle for hidden unit design. It is also
difficult to determine when to use what type of hidden unit. (p. 190)

Part III: Deep Learning Research
--------------------------------

Reference
---------

1. Deep Learning Book: https://www.deeplearningbook.org
