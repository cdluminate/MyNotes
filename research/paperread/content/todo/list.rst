---
title: "List"
date: 2018-08-12T02:43:13Z
draft: true
---

TODO
====

Tier 1

* https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/
* http://openaccess.thecvf.com/content_cvpr_2017/papers/Khoreva_Simple_Does_It_CVPR_2017_paper.pdf
* https://arxiv.org/pdf/1703.08774v2.pdf

Tier 2

* https://arxiv.org/pdf/1801.08297.pdf
* https://arxiv.org/pdf/1801.07853.pdf
* https://arxiv.org/pdf/1801.07829.pdf
* https://arxiv.org/pdf/1801.08100.pdf

* https://arxiv.org/pdf/1308.0850.pdf Generating Sequences With Recurrent Neural Networks

* deep face recognition (VGG) - dataset and deep neural net summarization

Unsupervised segmentation of natural images via lossy data compression, CVIU 2007
---------------------------------------------------------------------------------

todo

Supervised Sequence Labelling with Recurrent Neural Networks
------------------------------------------------------------
http://www2.cs.uh.edu/~ceick/7362/Kunal2_Book.pdf

A. Graves. / Textbook, Studies in Computational Intelligence, Springer, 2012. / RNN

Progress: pdf-pp.16

TODO

Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks
--------------------------------------------------------------------------------------
https://arxiv.org/pdf/1503.00075.pdf
 
TODO

- http://www.cs.cmu.edu/~aayushb/pixelNet/pixelnet.pdf

- https://research.fb.com/wp-content/uploads/2017/08/maskrcnn.pdf

- https://people.eecs.berkeley.edu/%7Ejonlong/long_shelhamer_fcn.pdf

-  adam: a method for stochastic optimization

-  representation learning: a review and new perspectives

-  going deeper with convolution

-  deep residual learning for image recognition

-  distributed representations of words and phrases and their
   compositionality

-  decaf: a deep convolutional activation feature for generic visual
   recognition

-  building high-level features using large scale unsupervised learning

-  [Tracking] High-Speed Tracking with Kernelized Correlation Filters \|
   TODO

-  训练的神经网络不工作？一文带你跨过这37个坑
   https://mp.weixin.qq.com/s?src=3&timestamp=1500958337&ver=1&signature=gNkHjxyIfDfLuuR8Vmxxt4Q-Lqz0a2MHtWDTW807L\ *MWvzg7JGoCrr5UPUNZ-8bmzuWQ*\ LtOmZiUwgN9Z4hoH15eOx9P4SrPdD85G4\ *TJiuT3XQl9IIQ5u9Zf2l3H*\ dhLwo6GNBlMhfVW5Vxl5U10l8OQWqC9VVU2ZYBrY7jTk4=

-  `Analysis and Optimization of Convolutional Neural Network
   Architectures <https://arxiv.org/pdf/1707.09725.pdf>`__ \| master
   thesis, key: topology learning

-  low-bit CNN, BMVC, (WTH the efficiency analysis is missing?) \|
   Learning Accurate Low-Bit Deep Neural Networks with Stochastic
   Quantization https://arxiv.org/pdf/1708.01001.pdf

-  inception v1 https://arxiv.org/pdf/1409.4842.pdf

-  inception v2 https://arxiv.org/pdf/1502.03167.pdf (BN)

-  inception v3 https://arxiv.org/pdf/1512.00567.pdf

-  inception v4 https://arxiv.org/pdf/1602.07261.pdf


- Convolution, Pooling, Fully-Connected, activation, Softmax. R-CNN, fast R-CNN, faster R-CNN, SSD, YOLO ... ...

-  Deep Residual Learning for Image Recognition \| TODO

-  Large-Scale Video Classification with Convolutional Neural Networks
   \| TODO

-  Learning deep features for scene recognition using places database \|
   TODO

-  Multi-scale Orderless Pooling of Deep Convolutional Activation
   Features \| TODO

-  Simultaneous Detection and Segmentation \| TODO

-  One Millisecond Face Alignment with an Ensemble of Regression Trees

-  Generative adversarial nets \| TODO

- AlphaGo


Google Brain Guy Blog TODO http://www.wildml.com/

Dropout: a simple way to prevent neural networks from overfitting
-----------------------------------------------------------------


`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift <https://arxiv.org/pdf/1502.03167.pdf>`__
---------------------------------------------------------------------------------------------------------------------------------------


http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html

http://cthorey.github.io./backpropagation/


