#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "newtxmath" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 3cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Miscellaneous Paper Reviews
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section*
ToDo List
\end_layout

\begin_layout Enumerate
Improving Referring Expression Groundingwith Cross-modal Attention-guided
 Erasing
\end_layout

\begin_layout Enumerate
SEMI-SUPERVISEDCLASSIFICATION WITHGRAPHCONVOLUTIONALNETWORKS
\end_layout

\begin_layout Subsection*
Daily Task
\end_layout

\begin_layout Enumerate
http://www.arxiv-sanity.com/
\end_layout

\begin_layout Enumerate
https://arxiv.org/list/cs.CV/pastweek
\end_layout

\begin_layout Enumerate
https://mijisou.com/
\end_layout

\begin_layout Part
Story Lines
\end_layout

\begin_layout Section
Story: Adversarial Example: Attack & Defense
\end_layout

\begin_layout Standard
Description: Adversarial examples are inputs that have been specifically
 designed by an adversary to cause a machine learning algorithm to produce
 a misclassification.
\end_layout

\begin_layout Standard
This research area largely began with 
\begin_inset CommandInset citation
LatexCommand cite
key "ad-ex-image-0,ad-ex-0"
literal "false"

\end_inset

, who first studied adversarial examples for deep neural networks.
 (Initial works on adversarial examples focused mainly in the domain of
 image classification.) Adversarial examples are known to exist on domains
 ranging from reinforcement learning to reading comprehension to speech
 recognition 
\begin_inset CommandInset citation
LatexCommand cite
key "ad-ex-speech-0,ad-ex-speech-1"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
I guess the success of adversarial examples stems from abusing unused model
 capacity.
 (I was wrong)
\end_layout

\begin_layout Standard
Some external materials: https://adversarial-ml-tutorial.org/
\end_layout

\begin_layout Subsection
Possible Future work Directions:
\end_layout

\begin_layout Enumerate
Non-
\begin_inset Formula $l_{p}$
\end_inset

-based metrics for images.
\end_layout

\begin_layout Enumerate
Other kind of physical objects instead of printed paper.
\end_layout

\begin_layout Enumerate
Other kinds of machine learning systems such as reinforcement learning (black
 box).
\end_layout

\begin_layout Enumerate
Physical attacks that achieve higher success rate.
\end_layout

\begin_layout Enumerate
Defending methods.
\end_layout

\begin_layout Enumerate
Adversarial Ranking for Visual Semantic Embedding Space.
 Attacking the ranking loss function.
\end_layout

\begin_layout Enumerate
Adversarial training, while maintaining state of the art accuracy on clean
 inputs.
\end_layout

\begin_layout Enumerate
BlackBox Attack.
\end_layout

\begin_layout Enumerate
Defenses.
\end_layout

\begin_layout Standard
Additional Note on PGD: Difference between gradient descent and projected
 gradient descent? At a basic level, projected gradient descent is just
 a more general method for solving a more general problem.
 Gradient descent minimizes a function by moving in the negative gradient
 direction at each step.
 There is no constrant on the variable.
 On the other hand, projected gradient descent minimizes a function subject
 to a constraint.
 At each step we move in the direction of the negative gradient, and then
 
\begin_inset Quotes eld
\end_inset

project
\begin_inset Quotes erd
\end_inset

 onto the feasible set.
\begin_inset Formula 
\[
\min_{x}f(x)\rightarrow x_{k+1}=x_{k}-t_{k}\nabla f(x_{k})
\]

\end_inset


\begin_inset Formula 
\begin{align*}
\min_{x}f(x)\text{ s.t. }x\in C\rightarrow & y_{k+1}=x_{k}-t_{k}\nabla f(x_{k}),\\
\rightarrow & x_{k+1}=\arg\min_{x\in C}||y_{k+1}-x||
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Definitions
\end_layout

\begin_layout Standard
White box model and black box model.
 In the white box model the adversary has full access to the model architecture
 and parameters, while in the black box model the adversary only is only
 able to feed an input and observe the output.
 Attacking methods: FGSM (fast gradient sign method), FGM (fast gradient
 method), IGSM (iterative gradient sign method).
 Defending methods: adversarial training, gradient masking, randomization
 (additional network component), denoising (pre-process).
\end_layout

\begin_layout Standard
Targeted Attack & Untargetted Attack
\end_layout

\begin_layout Standard
Untargetted: doesn't specify the target class.
\end_layout

\begin_layout Subsubsection
Implementation and Supported Attacks
\end_layout

\begin_layout Standard
(Ian) https://cleverhans.readthedocs.io/en/latest/source/attacks.html
\end_layout

\begin_layout Enumerate
BasicIterativeMethod (ProjectedGradientDescent)
\end_layout

\begin_layout Enumerate
BoundaryAttackPlusPlus (1904.02144)
\end_layout

\begin_layout Enumerate
CarliniWagnerL2 (1608.04644)
\end_layout

\begin_layout Enumerate
DeepFool (1511.04599)
\end_layout

\begin_layout Enumerate
ElasticNetMethod (1709.04114)
\end_layout

\begin_layout Enumerate
FastFeatureAdversaries (1511.05122)
\end_layout

\begin_layout Enumerate
FastGradientMethod (Fast Gradient Sign Method) (1412.6572)
\end_layout

\begin_layout Enumerate
LBFGS (1312.6199)
\end_layout

\begin_layout Enumerate
MadryEtAl (2017)
\end_layout

\begin_layout Enumerate
MaxConfidence (ICLR19:Reject)
\end_layout

\begin_layout Enumerate
MomentumIterativeMethod (1710.06081:NIPS17 Winner)
\end_layout

\begin_layout Enumerate
Noise (1802.00420)
\end_layout

\begin_layout Enumerate
SPSA (1802.05666)
\end_layout

\begin_layout Enumerate
SaliencyMapMethod (1511.07528) – aka JSMA
\end_layout

\begin_layout Enumerate
Semantic (1703.06857)
\end_layout

\begin_layout Enumerate
SpatialTransformationMethod (?)
\end_layout

\begin_layout Enumerate
VirtualAdversarialMethod (1507.00677)
\end_layout

\begin_layout Enumerate
FGM - Fast Gradient Method (1611.01236)
\end_layout

\begin_layout Enumerate
VATM (1507.00677)
\end_layout

\begin_layout Standard
https://github.com/baidu/AdvBox
\end_layout

\begin_layout Standard
White-Box: L-BFGS FGSM BIM ILCM MI-FGSM JSMA DeepFool C/W
\end_layout

\begin_layout Standard
Black-Box: Single Pixel Attack, Local Search Attack
\end_layout

\begin_layout Standard
Defense: Feature Squeezing, Spatial Smoothing, Label Smoothing, Gaussian
 Augmentation, Adversarial Training, Thermometer Encoding
\end_layout

\begin_layout Subsubsection
1712.07107: Adversarial Examples: Attacks and Defenses forDeep Learning
\end_layout

\begin_layout Standard
In thispaper, we review recent findings on adversarial examples fordeep
 neural networks, summarize the methods for generatingadversarial examples,
 and propose a taxonomy of these methods.
\end_layout

\begin_layout Standard
This is a good overview.
\end_layout

\begin_layout Subsubsection
1610.00768: Technical Report on thecleverhans v2.1.0 Adversarial Examples Library
\end_layout

\begin_layout Standard
Attacks: L-BFGS, FGSM, C&W, EAD (ElasticNet), BIM (Basic Iterative), PGD
 (L8), MIM (Momentum), JSMA, DeepFool, FeatureAdversaries, SPSA.
\end_layout

\begin_layout Standard
Defences: Adversarial Training.
\end_layout

\begin_layout Subsection
Classical Countermeasure
\end_layout

\begin_layout Subsubsection

\series bold
2004-KDD: Adversarial Classification
\end_layout

\begin_layout Standard
Essentially all data mining algorithms assume that the data generating process
 is independent of the data miner's activities.
 However, in many domains, including spam detection, intrusion detection,
 fraud detection, surveillance and counter-terrorism, this is far from the
 case: the data is actively manipulated by an adversary seeking to make
 the classifier produce false negatives.
 In these domains, the performance of a classifier can degrede rapidly after
 it is deployed, as the adversary learns to defeat it.
 Currently the obly solution to this is repeated, manual, ad-hoc reconstruction
 of the classifier.
 In this paper we develop a formal framework and algorithms for this problem.
 We view classification as a game between the classifier and the adversary,
 and produce a classifier that is optimal given the adversary's optimal
 strategy.
\end_layout

\begin_layout Standard
Future work: Repeated games, theory, incomplete information, approximately
 optimal strategies, generalization to other classifiers, interaction with
 humans, multiple adversaries, variants of the problem, other domains and
 tasks.
\end_layout

\begin_layout Subsubsection
2008-USENIX: Exploiting Machine Learning to Subvert Your Spam Filter
\end_layout

\begin_layout Standard
This paper shows how an adversary can exploitstatistical machine learning,
 as used in the SpamBayesspam filter, to render it useless—even if the adversary
’saccess is limited to only 1% of the training messages.
\end_layout

\begin_layout Subsubsection
2015-ICITR: The Probability Ranking Principle is Not Optimal in Adversarial
 Retrieval Settings
\end_layout

\begin_layout Standard
The probability ranking principle (PRP) — ranking docu- ments in response
 to a query by their relevance probabili- ties — is the theoretical foundation
 of most ad hoc docu- ment retrieval methods.
 A key observation that motivates our work is that the PRP does not account
 for potential post-ranking effects, specifically, changes to documents
 that result from a given ranking.
 Yet, in adversarial retrieval settings such as the Web, authors may consistentl
y try to promote their documents in rankings by changing them.
 We prove that, indeed, the PRP can be sub-optimal in adversar- ial retrieval
 settings.
\end_layout

\begin_layout Subsection
Adversarial Attacks & Transferability
\end_layout

\begin_layout Standard
Adversarial examples have been studied most extensively in the image domain.
 In this domain, adversarial examples can be constructed by imperceptibly
 modifying images to cause misclassification, and are practical in the physical
 world.
\end_layout

\begin_layout Subsubsection

\series bold
1312.6199: Intriguing properties of neural networks (LBFGS, iterative, targeted)
\end_layout

\begin_layout Standard
The reson deep neural networks succeed is their expressiveness, which also
 causes them to learn uninterpretable solutions that could have counter-intuitiv
e properties.
 First, this paper found that there is no distinction between individual
 high level units and random linear combinations of high level units, according
 to various methods of unit analysis.
 It suggests that it is the space, rather than the individual units, that
 contains the semantic information in the high layers of neural networks.
 Second, this paper found that deep neural networks learn input-output mappings
 that are fiarly discontinuous to a significant extent.
 We can cause the network to misclassify an image by applying a certain
 hardly perceptible perturbation, which is found by maximizing the network's
 prediction error.
\end_layout

\begin_layout Standard
* On some datasets, such as ImageNet, the adversarial examples were so close
 to the original examples that the differences were indistinguishable to
 the human eye.
\end_layout

\begin_layout Standard
* The same adversarial example is often misclassified by a variety of classifier
s with different architectures or trained on different subsets of the training
 data.
\end_layout

\begin_layout Standard
* Shallow softmax regression models are also vulnerable to adversarial examples.
\end_layout

\begin_layout Standard
* Training on adversarial examples can regularize the model – however, this
 was not practical at the time due to the need for expensive constrained
 optimization in the inner loop.
\end_layout

\begin_layout Standard
For the second point, the authors aim to solve the following optimization
 problem:
\begin_inset Formula 
\begin{align*}
\min &  & ||r||_{2}\\
s.t. &  & f(x+r)=l\\
 &  & x+r\in[0,1]^{m}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In general, the exact computation of the minimizer is a hard problem, so
 we approximate it by using a box-constrained L-BFGS.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\min &  & c|r|+loss_{f}(x+r,l)\\
s.t. &  & x+r\in[0,1]^{m}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This penalty function method would yield the exact solution in the case
 of convex losses, however neural networks are non-convex in general, so
 we end up with an approximation in this case.
\end_layout

\begin_layout Subsubsection
1412.1897: Deep Neural Networks are Easily Fooled:High Confidence Predictions
 for Unrecognizable Images (Noise)
\end_layout

\begin_layout Standard
Here we show a related result: it is easy to produce images that are completely
 unrecognizable to humans, but that state-of-the-art DNNs believe to be
 recognizable objects with 99% confidence.
 Specifically, we take convolutional neural networks trained to perform
 well on either the imagenet of mnist datasets and then find images with
 evolutionary algorithms or gradient ascent that DNNs label with high confidence
 as belonging to each dataset class.
 In the second approach, optimization begins at the imagenet mean plus a
 small Gaussian noise (to break symmetry) and continus until DNN confidence
 for the target class reaches 99%.
\end_layout

\begin_layout Standard
This is the first CVPR paper I've ever seen that doesn't contain any mathematica
l formula.
\end_layout

\begin_layout Subsubsection
1412.6572: Explaining and Harnessing Adversarial Examples (Ian, FGSM)
\end_layout

\begin_layout Standard
Early attemps at explaining this phenomenon focused on nonlinearity and
 overfitting.
 We argue instead that the primary cause of neural network's vulnerability
 to adversarial perturbation is their linear nature.
\end_layout

\begin_layout Standard
The cause of these adversaral examples was a mystery, and speculative explanatio
ns have suggested it is due to extreme nonlinearity of deep neural networks,
 perhaps combined with insufficient model averaging and insufficient regularizat
ion of the purely supervised learning problem.
 We show that these speculative hypotheses are unnecessary.
 Linear behavior in high-dimensional space is sufficient to cause adversarial
 examples.
 This view enables us to design a fast method of generating adversarial
 examples that makes adversarial traning practical.
 We show that adversarial traning can provide an additional regularization
 benefit beyond that provided by using dropout alone.
 Generic regularization strategies such as dropout, pretraining, and model
 averaging do not confer a significant reduction in a model's vulnerability
 to adversarial examples, but changing to nonlinear model families such
 as RBF networks can do so.
\end_layout

\begin_layout Standard
The modern machine learning techniques, even those that obtain excellent
 performance on the test set, are not learning the true underlying concepts
 that determine the correct output label.
 Instead, these algorithms have built a Potemkin village that works well
 on naturally occuring data, but is exposed as a fake when on visits points
 in space that do not have high probability in the data distribution.
 This is particularly disappointing because a popular approach in computer
 vision is to use convolutional network features as a space where Euclidean
 distance approximates perceptual distance.
 This resumblance is clearly flawed if images that have an immeasurebly
 small perceptual distance correcpond to completely different classes in
 the netwrok's representation.
 Some works have already begun the first steps toward designing models that
 resist adversarial perturbation, though no model has yet successfully done
 so while maintaining state of the art accuracy on clean inputs.
\end_layout

\begin_layout Standard
Linear Explanation of adversarial examples 
\begin_inset Formula $\tilde{x}=x+\eta$
\end_inset

 where 
\begin_inset Formula $||\eta||_{\infty}<\epsilon$
\end_inset

.
 Consider the dot produce between a weight vector 
\begin_inset Formula $w$
\end_inset

 and an adversarial example 
\begin_inset Formula $\tilde{x}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w^{T}\tilde{x}=w^{T}x+w^{T}\eta
\]

\end_inset


\end_layout

\begin_layout Standard
We can maximize the activation increase 
\begin_inset Formula $w^{T}\eta$
\end_inset

 subject to the max norm constraint on 
\begin_inset Formula $\eta$
\end_inset

 by assigning 
\begin_inset Formula $\eta=\text{sign}(w)$
\end_inset

 .
 If size(w) is 
\begin_inset Formula $n$
\end_inset

, mean(w) is 
\begin_inset Formula $m$
\end_inset

, then the activation will grow by 
\begin_inset Formula $\epsilon mn$
\end_inset

.
 The max norm doesn't grow with the dimensionality of the problem.
 For high dimensional problems, we can make many infinitesimal changes to
 the input that add up to one large change to the output.
 We can think of this as a sort of 
\begin_inset Quotes eld
\end_inset

accidental steganography
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
We hypothesize that the neural networks are too linear to resist linear
 adversarial perturbation.
 LSTMs, ReLUs, and maxout networks are all intentionally designed to behave
 in very likear ways, so that they are easier to optimize.
 More nonlineaer models such as sigmoid networks are carefully tuned to
 spend most of their time in the non-saturating, more linear regime for
 the same reason.
 This linear behavior suggests that cheap, analytical perturbations of a
 linear model should also damage neural networks.
\end_layout

\begin_layout Standard
We can obtain an optimal max-norm constrained pertubation, which can be
 computed efficiently using backpropagation.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\eta=\epsilon\text{sign}\Big(\nabla_{x}J(\theta,x,y)\Big),x'=x+\eta
\]

\end_inset


\end_layout

\begin_layout Standard
Other simple methods of generating adversarial examples are possible.
 For example, we also found that rotating x by a small angle in the direction
 of the gradient reliably produces adversarial examples.
\end_layout

\begin_layout Standard
Training with an adversarial objective function based on the fast gradient
 sign method was an effective regularizer:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tilde{J}(\theta,x,y)=\alpha J(\theta,x,y)+(1-\alpha)J(\theta,x+\epsilon\text{sign}(\nabla_{x}J(\theta,x,y)))
\]

\end_inset


\end_layout

\begin_layout Standard
Noise with zero mean and zero covariance is very inefficient at preventing
 adversarial examples.
 The expected dot product between any reference vector and such a noise
 vector is zero.
\end_layout

\begin_layout Standard
RBF networks are neturally immune to adversarial examples, in the sense
 that they have low confidence when they are fooled.
 A shallow RBF network's confidence on clean test examples are much higher
 than that on adversarial examples.
 RBF units are unfortunately not invariant to any significant transformations
 so they cannot generalize very well.
\end_layout

\begin_layout Standard
Correct classifications occur only on a thin manifold where x occurs in
 the data.
\end_layout

\begin_layout Standard
This paper has a nice summary section for its observations.
 Further observations concerning rubbish class examples are presented in
 the appendix.
\end_layout

\begin_layout Subsubsection
1511.04599: DeepFool: a simple and accurate method to fool deep neural networks
\end_layout

\begin_layout Standard
In this paper, we fill thisgap and propose the DeepFool algorithm to efficiently
 com-pute perturbations that fool deep networks, and thus reli-ably quantify
 the robustness of these classifiers.
\end_layout

\begin_layout Standard
Formally, for a given classifier, we define an adversarial perturbation
 as the minimal perturation 
\begin_inset Formula $r$
\end_inset

 that is sufficient to change the estimated label 
\begin_inset Formula $\hat{k}(x)$
\end_inset

, specifically, we call
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Delta(x;\hat{k}):=\min_{r}||r||_{2},s.t.\hat{k}(x+r)\ne\hat{k}(x)
\]

\end_inset


\end_layout

\begin_layout Standard
the robustness of 
\begin_inset Formula $\hat{k}$
\end_inset

 at point 
\begin_inset Formula $x$
\end_inset

.
 The robustness of classifier 
\begin_inset Formula $\hat{k}$
\end_inset

 is then defined as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\rho_{\text{adv}}(\hat{k})=\mathbb{E}_{x}\frac{\Delta(x;\hat{k})}{||x||_{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
DeepFool for binary classifiers (iterative)
\begin_inset Formula 
\begin{align*}
r_{*}(x_{0}) & =\arg\min||r||_{2}\\
s.t. & sgn(f(x_{0}+r))\ne sgn(f(x_{0}))\\
 & =-\frac{f(x_{0})}{||w||_{2}^{2}}w
\end{align*}

\end_inset


\begin_inset Formula 
\[
r_{i}\leftarrow-\frac{f(x_{i})}{||\nabla f(x_{i})||_{2}^{2}}\nabla f(x_{i})
\]

\end_inset


\end_layout

\begin_layout Standard
The logic of this paper resembles (linear) SVM.
 DeepFool for multiclass classifiers is also proposed.
 This is a good paper to read.
\end_layout

\begin_layout Subsubsection

\color red
1511.05122: Adversarial Manipulation of Deep Representations
\end_layout

\begin_layout Standard
We show that the image representations in a deep neural network (DNN) can
 bemanipulated to mimic those of other natural images, with only minor,
 impercep-tible perturbations to the original image.
 Here we instead concentrate on the internal layers of DNN representations,to
 produce a new class of adversarial images that differs qualitatively from
 others.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
I_{a} & =\arg\min_{r}||\phi_{k}(I_{s}+r)-\phi_{k}(I_{g})||_{2}^{2}\\
s.t. & ||r||_{\infty}<\delta
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Euclidean distance.
\end_layout

\begin_layout Subsubsection
1511.07528: The Limitations of Deep Learninging Adversarial Settings (JSMA,
 Papernot)
\end_layout

\begin_layout Standard
This paper presents an attack method based on forward derivative and saliency
 map.
\end_layout

\begin_layout Standard
The forward derivative for the given sample 
\begin_inset Formula $X$
\end_inset

 is the Jacobian of the function corresponding to what the neural network
 learned during training.
 Note, we take the derivative of the network directly rather than on its
 cost function.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla F(X)=\frac{\partial F(X)}{\partial X}=\Big[\frac{\partial F_{j}(X)}{\partial x_{i}}\Big]
\]

\end_inset


\end_layout

\begin_layout Standard
Adversarial saliency maps are defined to suit problem specific adversarial
 goals.
 For instance, the output of a network classifier is a probability vector
 across classes, and the adversary can accomplish this by increasing input
 features using the follwing saliency map 
\begin_inset Formula $S(X,t)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
S(X,t)[i]= & \begin{cases}
0 & \partial F_{t}(X)/\partial X_{i}<0\\
0 & \partial F_{j}(X)/\partial X_{i}>0\\
(\frac{\partial F_{t}(X)}{\partial X_{i}})|\sum_{j}\frac{\partial F_{j}(X)}{\partial X_{i}}| & \text{otherwise}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Adversarial sample is obtained through iterative perturbation.
 Let 
\begin_inset Formula $i_{\max}=\arg\max_{i}S(X,Y^{*})[i]$
\end_inset

,
\begin_inset Formula 
\[
X^{*}=X+\theta\hat{e}_{i_{\max}}
\]

\end_inset


\end_layout

\begin_layout Standard
This paper is poorly written.
\end_layout

\begin_layout Subsubsection
2016: Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art
 Face Recognition (CMU)
\end_layout

\begin_layout Standard
The broad use of machine learning makes it important tounderstand the extent
 to which machine-learning algorithmsare subject to attack, particularly
 when used in applicationswhere physical security or safety is at risk.
\end_layout

\begin_layout Standard
We de-fine and investigate a novel class of attacks: attacks thatarephysically
 realizableandinconspicuous, and allow an at-tacker to evade recognition
 or impersonate another individ-ual.
 We develop a systematic method to automatically gen-erate such attacks,
 which are realized through printing a pairof eyeglass frames.
\end_layout

\begin_layout Standard
Our investigation focuses onwhite-box face-recognition systems, but we also
 demonstratehow similar techniques can be used in black-box scenarios,as
 well as to avoid facedetection.
\end_layout

\begin_layout Subsubsection
1602.02697: Practical Black-Box Attacks against Machine Learning (Ian)
\end_layout

\begin_layout Standard
The only capa-bility of our black-box adversary is to observe labels givenby
 the DNN to chosen inputs.
 Our attack strategy consistsin training a local model to substitute for
 the target DNN,using inputs synthetically generated by an adversary andlabeled
 by the target DNN.
 We use the local substitute tocraft adversarial examples, and find that
 they are misclas-sified by the targeted DNN.
\end_layout

\begin_layout Standard
To perform a real-world andproperly-blinded evaluation, we attack a DNN
 hosted byMetaMind, an online deep learning API.
 We find that theirDNN misclassifies 84.24% of the adversarial examples craftedwi
th our substitute.
\end_layout

\begin_layout Standard
Many potential defense mechanisms fall into a category wecallgradient masking.
 These techniques construct a modelthat does not have useful gradients,
 e.g., by using a nearestneighbor classifier instead of a DNN.
 We show a more general flaw in the category of gradientmasking.
 We show that theblack-box attack based on transfer from a substitute modeloverc
omes gradient masking defenses.
\end_layout

\begin_layout Standard
We introduced an attack, based on a novel substitutetraining algorithm using
 synthetic data generation, to craftadversarial examples misclassified by
 black-box DNNs.
 Our attackevades a category of defenses, which we callgradient mask-ing,
 previously proposed to increase resilience to adversarialexamples.
\end_layout

\begin_layout Subsubsection
1605.07277: Transferability in Machine Learning: from Phenomena to Black-Box
 Attacks using Adversarial Samples
\end_layout

\begin_layout Standard
We extend these recenttechniques usingreservoir samplingto greatly enhance
 theefficiency of the training procedure for the substitute model.
 We introduce new transferability attacks between previouslyunexplored (substitu
te, victim) pairs of machine learningmodel classes, most notably SVMs and
 decision trees.
\end_layout

\begin_layout Standard
...
 thereby showing that existing machinelearning approaches arein generalvulnerabl
e to systematicblack-box attacks regardless of their structure
\end_layout

\begin_layout Standard
This paper overviewed attacks to DNN, multi-class logistic regression, nearest
 neighbors, multi-class support vector machines, decision trees.
\end_layout

\begin_layout Subsubsection
1606.04435: Adversarial Perturbations Against Deep Neural Networksfor Malware
 Classification
\end_layout

\begin_layout Standard
Yet, it re-mains unclear how such attacks translate to more security-sensitive
 applications such as malware detection–which maypose significant challenges
 in sample generation and ar-guably grave consequences for failure.
\end_layout

\begin_layout Standard
The application domain of malwareclassification introduces additional constraint
s in the adver-sarial sample crafting problem when compared to the com-puter
 vision domain.
\end_layout

\begin_layout Standard
While feature reduction did not prove to have a positive impact, distillation
 and re-training on ad-versarially crafted samples show promising results.
\end_layout

\begin_layout Subsubsection

\series bold
1607.02533: Adversarial examples in the physical world (Ian, IterativeGradientSig
n)
\end_layout

\begin_layout Standard
Up to now, all previous work has assumed a thread model in which the adversary
 can feed data directly into the machine learning classifier.
 This is not always the case for systems operating in the physical world,
 for example those which are using signals from cameras and other sensors
 as input.
\end_layout

\begin_layout Standard
The main distribution of this paper is the definition and illustration of
 block box attack (in which the attack is constructed without access to
 the model).
\end_layout

\begin_layout Standard
* The adversarial examples are misclassified far more often than examples
 that have been perturbed by noise, even if the magnitude of the noise is
 much larger than the magnitude of the adversarial perturbation.
\end_layout

\begin_layout Standard
* In many scenarios the adversary cannot rely on the ability of fine-grained
 per-pixel modifications of the input data.
 Is it still possible to craft adversarial examples and perform adversarial
 attacks on machine learning systems which are operating in the physical
 world and perceiving data through various sensors, rather than digital
 representation?
\end_layout

\begin_layout Standard
* The work is different from 
\begin_inset Quotes eld
\end_inset

Accessorize to a crime: Real and stealthy attacks on state-of-the-art face
 recognition
\begin_inset Quotes erd
\end_inset

 in these aspects: (1) this paper uses a cheap closed-form attack, while
 that work uses a more expenstive attack based on an optimization algorithm;
 (2) this paper makes no particular effort to modify the adversarial example
 to improve their chances of surviving the printing and photography process.
 They simply make the scientific observation that very many adversarial
 examples do survive this process without any intervention.
 (3) that work is restricted in the number of pixels they can modify.
\end_layout

\begin_layout Standard
* This work uses white-box thread model.
 (full knowledge about network architecture and parameter values.
 Black-box threat model.
\end_layout

\begin_layout Standard
Fast method
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X^{adv}=X+\epsilon\text{sign}(\nabla_{X}J(X,y_{true}))
\]

\end_inset


\end_layout

\begin_layout Standard
which is subject to a 
\begin_inset Formula $L_{\infty}$
\end_inset

 constraint.
 This is accomplished in closed form, for the cost of one call to back-propagati
on.
\end_layout

\begin_layout Standard
Basic Iterative Method
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{N+1}^{adv}=\text{Clip}_{X,\epsilon}\Big\{ X_{N}^{adv}+\alpha\text{sign}(\nabla_{X}J(X_{N}^{adv},y_{true}))\Big\}
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Quotes eld
\end_inset

Clip
\begin_inset Quotes erd
\end_inset

 function is used to ensure that pixel values are in the 
\begin_inset Formula $L_{\infty}\epsilon$
\end_inset

-neighbourhood of the original image.
\end_layout

\begin_layout Standard
Iterative Least-Likely Class Method
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y_{LL}=\arg\min_{y}\{p(y|X)\}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{N+1}^{adv}=\text{Clip}_{X,\epsilon}\{X_{N}^{adv}-\alpha\text{sign}(\nabla_{X}J(X_{N}^{adv},y_{LL}))\}
\]

\end_inset


\end_layout

\begin_layout Standard
* Least likely class method is a very efficient attacking method.
 Basic iterative method stoped descrising the accuracy too early.
 Fast method incurs accuracy degradation too slowly.
\end_layout

\begin_layout Standard
* This paper attacks Inception-v3.
\end_layout

\begin_layout Standard
* This work also proposed the 
\begin_inset Quotes eld
\end_inset

destruction rate
\begin_inset Quotes erd
\end_inset

 of adversarial examples.
\end_layout

\begin_layout Standard
* The 
\begin_inset Quotes eld
\end_inset

fast
\begin_inset Quotes erd
\end_inset

 method still perform very well when performing over-the-air attack.
\end_layout

\begin_layout Standard
* The least likely class method achieves the highest destruction rate.
\end_layout

\begin_layout Standard
* Adversarial examples generated by the fast method are the most robust
 to artificial transformations.
 Those from the L-L method are least robust.
\end_layout

\begin_layout Standard
* Changing brightness and contrast does not affect adversarial examples
 much.
 Blur, noise and JPEG encoding have a higher destruction rate than them.
\end_layout

\begin_layout Subsubsection

\color blue
1607.04311: Defensive Distillation is Not Robust to Adversarial Examples
 (C&W)
\end_layout

\begin_layout Standard
We show that, with a slight mod-ification to a standard attack, one can
 find adversarial ex-amples on defensively distilled networks.
\end_layout

\begin_layout Subsubsection
1607.05113: On the Effectiveness of Defensive Distillation (Papernot)
\end_layout

\begin_layout Standard
We report experimental results indicating that defensive distillation suc-cessfu
lly mitigates adversarial samples crafted using the fast gradient signmethod,
 in addition to those crafted using the Jacobian-based iterativeattack on
 which the defense mechanism was originally evaluated.
\end_layout

\begin_layout Subsubsection
1608.04644: Towards Evaluating the Robustness of Neural Networks (C&W, Iterative)
\end_layout

\begin_layout Standard
This work attacks defensive distillation with three new algorithms with
 100% probability.
 It constructs three new attacks (under three previously used distance metrics:
 
\begin_inset Formula $L_{0}$
\end_inset

, 
\begin_inset Formula $L_{2}$
\end_inset

, and 
\begin_inset Formula $L_{\infty}$
\end_inset

) that succeed in finding adversarial examples for 100% of images on defensively
 distilled networks.
 While defensive distillation stops previously published attacks, it cannot
 resist the more powerful attack techniques we introduce in this paper.
 This paper is also the first work that successfully caused targeted misclassifi
cation on the imagenet dataset.
 This paper also argues the choice of objective function for finding adversarial
 examples can dramatically impact the efficacy of an attack.
\end_layout

\begin_layout Standard
Defensive distillation does not remove adversarial examples.
 One potential reson this may occur is that others have argued the reason
 adversarial examples exist is not due to blind spots in a highly non-linear
 neural network, but due only to the locally-linear nature of neural networks.
\end_layout

\begin_layout Standard
Box Constraint: (1) Projected Gradient Descent performs one step of standard
 gradient descent; (2) Clipped Gradient Descent incorporates the clipping
 into the objective function.
 (3) change of variables introduces a new variable, we apply a change-of-variabl
es and optimize over the new variable.
 The solution will automatically be valid in terms of the box constraint.
\begin_inset Formula 
\[
\delta_{i}=\frac{1}{2}(\tanh(w_{i})+1)-x_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
This paper uses the alternative formulation 
\begin_inset Formula $\min||\delta||_{p}+c\cdot f(x+\delta)$
\end_inset

 , and proposes 7 possible choices of 
\begin_inset Formula $f$
\end_inset

.
\end_layout

\begin_layout Standard
This paper also provides a good overview.
\end_layout

\begin_layout Subsubsection

\color blue
1610.08401: Universal adversarial perturbations
\end_layout

\begin_layout Standard
Given a state-of-the-art deep neural network classifier,we show the existence
 of a universal(image-agnostic) andvery small perturbation vector that causes
 natural imagesto be misclassified with high probability.
 We propose a sys-tematic algorithm for computing universal perturbations,and
 show that state-of-the-art deep neural networks arehighly vulnerable to
 such perturbations, albeit being quasi-imperceptible to the human eye.
\end_layout

\begin_layout Standard
Algorithm: for each datapoint update perturbation.
\end_layout

\begin_layout Standard
In particular, we showed that universal perturbations generalize well across
 different classification models, resulting in doubly-universal perturbations
 (image-agnostic, network-agnostic).
\end_layout

\begin_layout Subsubsection
1611.02770: Delving into Transferable Adversarial Examples and Black-Box
 Attacks
\end_layout

\begin_layout Standard
In thiswork, we are the first to conduct an extensive study of the transferabili
ty overlarge models and a large scale dataset, and we are also the first
 to study the trans-ferability of targeted adversarial examples with their
 target labels.
 We study bothnon-targetedandtargetedadversarial examples, and show that
 while transferablenon-targeted adversarial examples are easy to find, targeted
 adversarial examplesgenerated using existing approaches almost never transfer
 with their target labels.
 Therefore, we propose novel ensemble-based approaches to generating transfer-ab
le adversarial examples.
 Using such approaches, we observe a large proportionof targeted adversarial
 examples that are able to transfer with their target labels forthe first
 time.
\end_layout

\begin_layout Standard
We study geometric properties of the models in our evaluation.
 In particular, we show that thegradient directions of different models
 are orthogonal to each other.
 We also show that decisionboundaries of different models align well with
 each other, which partially illustrates why adversarialexamples can transfer.
\end_layout

\begin_layout Subsubsection
1612.06299: Simple Black-Box Adversarial Perturbations for Deep Networks
 (Heuristic Black-Box)
\end_layout

\begin_layout Standard
Our attackstreat the network as an oracle (black-box) and only assume that
 the output of the network can be observedon the probed inputs.
 Our first attack is based on a simple idea of adding perturbation to a
 randomlyselected single pixel or a small set of them.
 We then improve the effectiveness of this attack by carefullyconstructing
 a small set of pixels to perturb by using the idea of greedy local-search.
 Our proposedattacks also naturally extend to a stronger notion of misclassifica
tion.
\end_layout

\begin_layout Subsubsection
1707.07397: Synthesizing Robust Adversarial Examples (ICML18)
\end_layout

\begin_layout Standard
Standard methods for generating adversarial ex-amples for neural networks
 do not consistentlyfool neural network classifiers in the physicalworld
 due to a combination of viewpoint shifts,camera noise, and other natural
 transformations,limiting their relevance to real-world systems.
 Wedemonstrate the existence of robust 3D adversar-ial objects, and we present
 the first algorithm forsynthesizing examples that are adversarial over
 achosen distribution of transformations.
 We syn-thesize two-dimensional adversarial images thatare robust to noise,
 distortion, and affine trans-formation.
 We apply our algorithm to complexthree-dimensional objects, using 3D-printing
 tomanufacture the first physical adversarial objects.Our results demonstrate
 the existence of 3D ad-versarial objects in the physical world.
\end_layout

\begin_layout Standard
Amazing.
\end_layout

\begin_layout Subsubsection
1707.08945: Robust Physical-World Attacks on Deep Learning Visual Classification
\end_layout

\begin_layout Standard
We propose a general attack algorithm,Robust Physical Perturbations (RP2),
 to generate robustvisualadversarial perturbations under different physicalcondi
tions.
 Using the real-world case of road sign classifi-cation, we show that adversaria
l examples generated usingRP2achieve high targeted misclassification rates
 againststandard-architecture road sign classifiers in the physicalworld
 under various environmental conditions, includingviewpoints.
 Due to the current lack of a standardized testingmethod, we propose a two-stage
 evaluation methodology forrobust physical adversarial examples consisting
 of lab andfield tests.
\end_layout

\begin_layout Subsubsection
1708.06131: Evasion attacks against machine learning at test time
\end_layout

\begin_layout Standard
In this work, we present a simple but effective gradient-based approach
 that can be exploited to systematically assess the securityof several,
 widely-used classification algorithms against evasion attacks.
\end_layout

\begin_layout Subsubsection
1709.04114: EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial
 Examples
\end_layout

\begin_layout Standard
In this paper, we formulate the process of attacking DNNs viaadversarial
 examples as an elastic-net regularized optimiza-tion problem.
 Ourelastic-netattacks toDNNs (EAD) fea-tureL1-oriented adversarial examples
 and include the state-of-the-artL2attack as a special case.
\end_layout

\begin_layout Subsubsection
1710.06081: Boosting Adversarial Attacks with Momentum (MI-FGSM, ICLR17 winner)
\end_layout

\begin_layout Standard
By inte-grating the momentum term into the iterative process forattacks,
 our methods can stabilize update directions andescape from poor local maxima
 during the iterations, re-sulting in more transferable adversarial examples.
\end_layout

\begin_layout Subsubsection
1710.08864: One Pixel Attack for Fooling Deep Neural Networks (OnePixel)
\end_layout

\begin_layout Standard
In this paper,we analyze an attack in an extremely limited scenario where
 onlyone pixel can be modified.
 For that we propose a novel methodfor generating one-pixel adversarial
 perturbations based on dif-ferential evolution (DE).
 It requires less adversarial information(a black-box attack) and can fool
 more types of networks dueto the inherent features of DE.
\end_layout

\begin_layout Subsubsection
1712.09665: Adversarial Patch
\end_layout

\begin_layout Standard
We present a method to create universal, robust, targeted adversarial image
 patchesin the real world.
 The patches are universal because they can be used to attackany scene,
 robust because they work under a wide variety of transformations,and targeted
 because they can cause a classifier to output any target class.
\end_layout

\begin_layout Standard
(Large Perturbation.
 Not imperceptible)
\end_layout

\begin_layout Subsubsection
1801.02612: SPATIALLY TRANSFORMED ADVERSARIAL EXAMPLES
\end_layout

\begin_layout Standard
Perturbations generated through spatial transformation could result in largeLpdi
stance measures, but our extensive experiments show that such spatially
 trans-formed adversarial examples are perceptually realistic and more difficult
 to defendagainst with existing defense systems.
 This potentially provides a new directionin adversarial example generation
 and the design of corresponding defenses.
\end_layout

\begin_layout Subsubsection
1802.00420: Obfuscated Gradients Give a False Sense of Security: Circumventing
 Defenses to Adversarial Examples (Author: C&W)
\end_layout

\begin_layout Standard
We identify obfuscated gradients, a kind of gradi-ent masking, as a phenomenon
 that leads to a falsesense of security in defenses against adversarialexamples.
 While defenses that cause obfuscatedgradients appear to defeat iterative
 optimization-based attacks, we find defenses relying on thiseffect can
 be circumvented.
 We describe charac-teristic behaviors of defenses exhibiting the effect,and
 for each of the three types of obfuscated gra-dients we discover, we develop
 attack techniquesto overcome it.
 In a case study, examining non-certified white-box-secure defenses at ICLR
 2018,we find obfuscated gradients are a common occur-rence, with 7 of 9
 defenses relying on obfuscatedgradients.
 Our new attacks successfully circum-vent 6 completely, and 1 partially,
 in the originalthreat model each paper considers.
\end_layout

\begin_layout Subsubsection
1802.09707: UNDERSTANDING AND ENHANCING THE TRANSFERABILITY OF ADVERSARIAL
 EXAMPLES (vr-IGSM)
\end_layout

\begin_layout Standard
In this work, we systematically study how two classes of factors that might
 influencethe transferability of adversarial examples.
 One is about model-specific factors,including network architecture, model
 capacity and test accuracy.
 The other is thelocal smoothness of loss function for constructing adversarial
 examples.
 Basedon these understanding, a simple but effective strategy is proposed
 to enhancetransferability.
 We call itvariance-reduced attack, since it utilizes the variance-reduced
 gradient to generate adversarial example.
\end_layout

\begin_layout Subsubsection
1803.06978: Improving Transferability of Adversarial Examples with Input
 Diversity (DI-FGSM)
\end_layout

\begin_layout Standard
To this end, we propose to improve the trans-ferability of adversarial examples
 by creating diverse in-put patterns.
 Instead of only using the original images togenerate adversarial examples,
 our method applies randomtransformations to the input images at each iteration.
 Ex-tensive experiments on ImageNet show that the proposed at-tack method
 can generate adversarial examples that trans-fer much better to different
 networks than existing base-lines.
\end_layout

\begin_layout Subsubsection
1804.03286: On the Robustness of the CVPR 2018 White-Box Adversarial Example
 Defenses
\end_layout

\begin_layout Standard
n this note, we evaluate thetwo white-box defenses that appeared at CVPR2018
 and find they are ineffective: when applyingexisting techniques, we can
 reduce the accuracyof the defended models to 0%.
\end_layout

\begin_layout Standard
This paper attacks Pixel Deflection (CVPR18) and High-level representation
 Guided Denoiser (HGR) (CVPR18) with PGD.
\end_layout

\begin_layout Subsubsection
1806.11146: ADVERSARIAL REPROGRAMMING OF NEURALNETWORKS (Ian)
\end_layout

\begin_layout Standard
We introduceattacks that insteadreprogramthe target model to perform a task
 chosen by theattacker—without the attacker needing to specify or compute
 the desired outputfor each test-time input.
 This attack finds a single adversarial perturbation, thatcan be added to
 all test-time inputs to a machine learning model in order to causethe model
 to perform a task chosen by the adversary—even if the model was nottrained
 to do this task.
 These perturbations can thus be considered a programfor the new task.
 We demonstrate adversarial reprogramming on six ImageNetclassification
 models, repurposing these models to perform a counting task, as wellas
 classification tasks: classification of MNIST and CIFAR-10 examples presentedas
 inputs to the ImageNet model.
\end_layout

\begin_layout Subsubsection
1811.09020: Task-generalizable Adversarial Attack based on Perceptual Metric
 (NRDM)
\end_layout

\begin_layout Standard
We propose a novel approach to create adversarial ex-amples that can broadly
 fool different networks on multi-ple tasks.
 Our approach is based on the following intu-ition: “Perpetual metrics based
 on neural network featuresare highly generalizable and show excellent performan
cein measuring and stabilizing input distortions.
 Thereforean ideal attack that creates maximum distortions in the net-work
 feature space should realize highly transferable ex-amples”.
\end_layout

\begin_layout Standard
We propose a novel attack algorithm to demonstratehow to benefit from generic
 internal neural representationsof pretrained models (e.g., VGG-16) on ImageNet
 datasetto exhibit cross-architecture, cross-dataset and cross-tasktransferabili
ty.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\max F(x')|_{k}-F(x)|_{k}
\]

\end_inset


\end_layout

\begin_layout Standard
This paper proposes to directly maximize the perceptual metric based on
 representation loss of deep feature activations by solving the optimizaion
 problem.
 This attack is untargeted, and is similar to the FeatureAdversary work.
 This paper is poor.
\end_layout

\begin_layout Subsubsection
1811.09600: Decoupling Direction and Norm for Efficient Gradient-BasedL2Adversari
al Attacks and Defenses
\end_layout

\begin_layout Standard
ConsideringL2norm distortions, the Carlini and Wagnerattack is presently
 the most effective white-box attack in theliterature.
 However, this method is slow since it performsa line-search for one of
 the optimization terms, and oftenrequires thousands of iterations.
 In this paper, an efficientapproach is proposed to generate gradient-based
 attacks thatinduce misclassifications with lowL2norm, by decouplingthe
 direction and the norm of the adversarial perturbationthat is added to
 the image.
\end_layout

\begin_layout Standard
This paper aims at outperforming C&W in terms of both efficiency and performance.
\end_layout

\begin_layout Subsubsection
2019-AAAI: Perceptual-Sensitive GAN for Generating Adversarial Patches
\end_layout

\begin_layout Standard
Recently, adversarial patch,with noise confined to a small and localized
 patch, emergedfor its easy accessibility in real-world.
 However, existing at-tack strategies are still far from generating visually
 naturalpatches with strong attacking ability, since they often ignorethe
 perceptual sensitivity of the attacked network to the ad-versarial patch,
 including both the correlations with the im-age context and the visual
 attention.
 To address this problem,this paper proposes a perceptual-sensitive generative
 adver-sarial network (PS-GAN) that can simultaneously enhancethe visual
 fidelity and the attacking ability for the adversar-ial patch.
 To improve the visual fidelity, we treat the patchgeneration as a patch-to-patc
h translation via an adversari-al process, feeding any types of seed patch
 and outputtingthe similar adversarial patch with high perceptual correla-tion
 with the attacked image.
 
\end_layout

\begin_layout Subsubsection
2019-ICLR: EVALUATIONMETHODOLOGY FORATTACKSAGAINST CONFIDENCETHRESHOLDINGMODELS
 (Confidence)
\end_layout

\begin_layout Standard
Current machine learning algorithms can be easily fooled byadversarial exam-ples.
 One possible solution path is to make models that useconfidence threshold-ingto
 avoid making mistakes.
 Such models refuse to make a prediction when theyare not confident of their
 answer.
 We propose to evaluate such models in termsof tradeoff curves with the
 goal of highsuccess rateon clean examples and lowfailure rateon adversarial
 examples.
 Existing untargeted attacks developed formodels that do not use confidence
 thresholding tend to underestimate such mod-els’ vulnerability.
 We propose theMaxConfidencefamily of attacks, which areoptimal in a variety
 of theoretical settings, including one realistic setting: attacksagainst
 linear models.
\end_layout

\begin_layout Subsubsection
1904.01160: Curls & Whey: Boosting Black-Box Adversarial Attacks (CVPR19)
\end_layout

\begin_layout Standard
Image classifiers based on deep neural networks sufferfrom harassment caused
 by adversarial examples.
 Two de-fects exist in black-box iterative attacks that generate ad-versarial
 examples by incrementally adjusting the noise-adding direction for each
 step.
 On the one hand, existingiterative attacks add noises monotonically along
 the direc-tion of gradient ascent, resulting in a lack of diversity andadaptabi
lity of the generated iterative trajectories.
 On theother hand, it is trivial to perform adversarial attack byadding
 excessive noises, but currently there is no refine-ment mechanism to squeeze
 redundant noises.
 In this work,we propose Curls & Whey black-box attack to fix the abovetwo
 defects.
 During Curls iteration, by combining gradi-ent ascent and descent, we ‘curl’
 up iterative trajectoriestointegrate more diversity and transferability
 into adversar-ial examples.
 Curls iteration also alleviates the diminishingmarginal effect in existing
 iterative attacks.
 The Whey op-timization further squeezes the ‘whey’ of noises by exploit-ing
 the robustness of adversarial perturbation.
\end_layout

\begin_layout Subsubsection
1904.02884: Evading Defenses to Transferable Adversarial Examples byTranslation-I
nvariant Attacks
\end_layout

\begin_layout Standard
Several state-of-the-art defensesare shown to be robust against transferable
 adversarial ex-amples.
 In this paper, we propose a translation-invariantattack method to generate
 more transferable adversarial ex-amples against the defense models.
 By optimizing a pertur-bation over an ensemble of translated images, the
 generatedadversarial example is less sensitive to the white-box modelbeing
 attacked and has better transferability.
\end_layout

\begin_layout Standard
Translation invariant.
 link to Universal adversarial perturbations (CVPR17).
\end_layout

\begin_layout Subsection
Defense, Analysis, Theory
\end_layout

\begin_layout Standard
In general, there are two different approaches one can take to evaluate
 the robustness of a neural network: attempt to provea lower bound, or construct
 attacks that demonstrate an upperbound.
\end_layout

\begin_layout Standard
There are many defense measures.
 The first being proposed was adversarial training: (Ian, 1412.6572, FGSM).
\end_layout

\begin_layout Standard
Defensive Distillation (1511.04508).
 Denoising (1712.02976).
 Randomization (1711.01991).
 StabilityTraining (1604.04326)
\end_layout

\begin_layout Subsubsection
1412.5608: Towards Deep Neural Network Architectures Robust To Adversarial
 Examples (DAE+CAE)
\end_layout

\begin_layout Standard
We perform variousexperiments to assess the removability of adversarial
 examples by corrupting withadditional noise and pre-processing with denoising
 autoencoders (DAEs).
 Wefind that DAEs can remove substantial amounts of the adversarial noise.
 How-ever, when stacking the DAE with the original DNN, the resulting network
 canagain be attacked by new adversarial examples with even smaller distortion.
 As asolution, we propose Deep Contractive Network, a model witha new end-to-end
training procedure that includes a smoothness penalty inspired by the contractiv
eautoencoder (CAE).
\end_layout

\begin_layout Standard
We conclude that neural network’s sensitivity toadversarial examples is
 more relatedto intrinsic deficiencies in the training procedure and objective
 function than to model topology.The crux of the problem is then to come
 up with an appropriate training procedure and objectivefunction that can
 efficiently make the network learn flat, invariant regions around the training
 data.We propose Deep Contractive Networks to explicitly learn invariant
 features at each layer and showsome positive initial results.
\end_layout

\begin_layout Subsubsection
1502.02590: Analysis of classifiers’ robustness to adversarial perturbations
\end_layout

\begin_layout Standard
We provide a theoretical framework for analyzing therobustness of classifiers
 to adversarial perturbations, and show fundamental upper bounds on the
 robustness of classifiers.
\end_layout

\begin_layout Standard
Capacity alone helps.
\end_layout

\begin_layout Standard
FGSM adversaries don’t increase robustness (for largeε).
\end_layout

\begin_layout Standard
Weak models may fail to learn non-trivial classifiers.
\end_layout

\begin_layout Standard
The value of the saddle point problem decreases as we increase the capacity.
\end_layout

\begin_layout Standard
More capacity and stronger adversaries decrease transferability.
\end_layout

\begin_layout Standard
This is an important paper.
\end_layout

\begin_layout Subsubsection
1503.02531: Distilling the Knowledge in a Neural Network (Distillation, Hinton)
\end_layout

\begin_layout Standard
A very simple way to improve the performance of almost any machine learning
 algorithm is to train many different models on the same data and them to
 average their predictions.
 Unfortunately, making predictionsusing a whole ensembleof models is cumbersome
 and may be too computationally expensive to allow de-ployment to a large
 number of users, especially if the individual models are largeneural nets.
 We achieve some surprising results on MNIST and we show that wecan significantl
y improve the acoustic model of a heavily used commercial systemby distilling
 the knowledge in an ensemble of models into a single model.
\end_layout

\begin_layout Standard
Neural networks typically produce class probablity by using a 
\begin_inset Quotes eld
\end_inset

softmax
\begin_inset Quotes erd
\end_inset

 output layer that converts the logit 
\begin_inset Formula $z_{i}$
\end_inset

 computed for each class into a probability 
\begin_inset Formula $q_{i}$
\end_inset

 by comparing 
\begin_inset Formula $z_{i}$
\end_inset

 with the other logits,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
q_{i}=\frac{\exp(z_{i}/T)}{\sum_{j}\exp(z_{j}/T)}
\]

\end_inset


\end_layout

\begin_layout Standard
where T is a temperature that is normally set to 1.
 Using a higher value for T produces a softer probability distribution over
 classes.
 In high temperature limit, distillation is equievalent to minimizing 
\begin_inset Formula $1/2||z-v||_{2}^{2}$
\end_inset

.
\end_layout

\begin_layout Subsubsection

\color blue
1511.03034: LEARNING WITH A STRONG ADVERSARY
\end_layout

\begin_layout Standard
In this paper, we propose a new method,learning with astrong adversary,
 that learns robust classifiers from supervised data by generatingadversarial
 examples as an intermediate step.
 A new and simple way of find-ing adversarial examples is presented that
 is empirically stronger than existingapproaches in terms of the accuracy
 reduction as a function of perturbation mag-nitude.
\end_layout

\begin_layout Standard
Should carefully read.
 Good theoreticall analysis.
\end_layout

\begin_layout Subsubsection
1511.04508: Distillation as a Defense to AdversarialPerturbations against
 Deep Neural Networks (Defensive Distillation)
\end_layout

\begin_layout Standard
This paper introduces a defensive mechanism called defensive distillation
 to reduce the effectiveness of adversarial samples on DNNs.
 We formulate a new variant of distillation to provide for defense training:
 instead of transferring knowledge between different architectures, we propose
 to use the knowledge extracted from a DNN to improve it's own resilience
 to adversarial samples.
\end_layout

\begin_layout Standard
* With T=1 as the baseline, distilling with T=100 makes the adversarial
 attack success rate drop to almost 0.
 The accuracy drop is within 2%.
\end_layout

\begin_layout Standard
* Distillation also improve the network's confidence of class predictions.
 
\begin_inset Formula 
\[
\mathbb{E}C(X)=\mathbb{E}[\max_{i}F_{i}(X)\text{ if target else }0]
\]

\end_inset


\end_layout

\begin_layout Standard
This paper is detailed.
\end_layout

\begin_layout Subsubsection
1511.05432: Understanding Adversarial Training: IncreasingLocal Stability
 of Neural Nets through Robust Optimization
\end_layout

\begin_layout Standard
We propose a general framework for increasing local stability of Artificial
 NeuralNets (ANNs) using Robust Optimization (RO).
 We show that adversarial training of ANNs is in fact robustification of
 thenetwork optimization, and that our proposed framework generalizes previous
 ap-proaches for increasing local stability of ANNs.
\end_layout

\begin_layout Standard
The goal of this manuscriptis to provide a framework that yields a full
 theoretical understanding of adversarial training, as well as new optimization
 schemes, based on robust optimization.
 Specifically, we show that generatingand using adversarial examples during
 training of ANNs can be derived from the powerful notion ofRobust Optimization
 (RO), which has many applications in machine learning and is closely relatedto
 regularization.
 We propose a general algorithm for robustification of ANN training, and
 show thatit generalizes previously proposed approaches.
\end_layout

\begin_layout Subsubsection
1511.06292: FOVEATION-BASED MECHANISMS ALLEVIATE ADVERSARIAL EXAMPLES
\end_layout

\begin_layout Standard
We show that adversarial examples,i.e.,the visually imperceptible perturbationstha
t result in Convolutional Neural Networks (CNNs) fail, can be alleviated
 witha mechanism based on foveations—applying the CNN in different image
 regions.
 To see this, first, we report results in ImageNet that lead to a revision
 of the hypoth-esis that adversarial perturbations are a consequence of
 CNNs acting as a linearclassifier: CNNs act locally linearly to changes
 in the image regions with objectsrecognized by the CNN, and in other regions
 the CNN may act non-linearly.
 Then,we corroborate that when the neural responses are linear, applying
 the foveationmechanism to the adversarial example tends to significantly
 reduce the effect ofthe perturbation.
\end_layout

\begin_layout Standard
We define a foveation as a transformation of the image that selects a region
 in which the CNNis applied, discarding the information from the other regions.
\end_layout

\begin_layout Standard
The author assumes that the robustness of the CNNs to changes of scale and
 position of the object does not generalize to the perturbations.
 For small perturbations,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\text{Foveation: T}(\cdot),f(T(x+\epsilon))=wT(x)+wT(\epsilon)
\]

\end_inset


\end_layout

\begin_layout Standard
Side note from wikipedia: Foveated imaging is a digital image processing
 technique in which the image resolution, or amount of detail, varies across
 the image according to one or more "fixation points." A fixation point indicates
 the highest resolution region of the image and corresponds to the center
 of the eye's retina, the fovea.
\end_layout

\begin_layout Subsubsection
1604.04326: Improving the Robustness of Deep Neural Networks via Stability
 Training (Ian)
\end_layout

\begin_layout Standard
We present a generalstability training method to stabilize deep networks
 against small input distortions that result from various types of com-mon
 image processing, such as compression, rescaling, and cropping.
 In addition, we demonstrate that our stabilizedmodel gives robust state-of-the-
art performance on large-scale near-duplicate detection, similar-image ranking,
 and classification on noisy datasets.
\end_layout

\begin_layout Standard
Augmenting the training data by adding uncorrelated Gaussian noise can potential
ly simulate many types of perturbations.
\end_layout

\begin_layout Standard
This paper studied the effect of stability training in triplet ranking task,
 but didn't devise any measurement to attack it.
\end_layout

\begin_layout Subsubsection
1605.07262: Measuring Neural Net Robustness with Constraints
\end_layout

\begin_layout Standard
We propose metrics for measuring the robustness of a neural net anddevise
 a novel algorithm for approximating these metrics based on an encoding
 ofrobustness as a linear program.
 Furthermore, we show howexisting approaches to improving robustness “overfit”
 to adversarial examplesgenerated using a specific algorithm.
\end_layout

\begin_layout Subsubsection
1608.00853: A study of the effect of JPG compression on adversarial images
\end_layout

\begin_layout Standard
Noting that virtually every image classification dataset is composed of
 JPG images, we evaluate the effect of JPG compression on theclassification
 of adversarial images.
 For Fast-Gradient-Sign perturbations of smallmagnitude, we found that JPG
 compression often reverses the drop in classificationaccuracy to a large
 extent, but not always.
 As the magnitude of the perturbationsincreases, JPG recompression alone
 is insufficient to reverse the effect.
\end_layout

\begin_layout Standard
In the case where the perturbation is approximately orthogonal to the JPG
 subspace, JPG compression brings the adversarial example back to the datasubspa
ce.
\end_layout

\begin_layout Standard
/Me: Decreasing JPEG compression quality incurs the decrease in quantization
 interval.
 Assume 100% compression quality covers the whole image space while 90%
 compression quality cannot cover the whole space, then the author's insight
 that perturbations move samples off the 90% image set makes sense, as modern
 models are trained on JPG images.
\end_layout

\begin_layout Standard
Our experiments demonstrate that JPG compression can reverse small adversarial
 perturbationscreated by the Fast-Gradient-Sign method.
 However, if the adversarial perturbations are larger, JPGcompression does
 not reverse the adversarial perturbation.
 In this case, the strong inductive biasof neural network classifiers leads
 to incorrect yet confident misclassifications.
 Even the largestperturbations that we evaluated are barely visible to an
 untrained human eye, and so JPG compressionis far from a solution.
 We do not yet understand why JPG compression reverses small adversarialperturba
tions.
\end_layout

\begin_layout Subsubsection
1608.07690: A Boundary Tilting Perspective on the Phenomenon of Adversarial
 Examples
\end_layout

\begin_layout Standard
We propose a new perspective on the phenomenon.
 We argue that adversarial examples exist when theclassification boundary
 lies close to the submanifold of sampled data, and present a mathematical
 analysisof this new perspective in the linear case.
\end_layout

\begin_layout Subsubsection

\color blue
1611.01236: ADVERSARIAL MACHINE LEARNING AT SCALE (Ian, PGD, Label Leaking)
\end_layout

\begin_layout Standard
So far, adversarial training has primarily been applied to small prob-lems.
 In this research, we apply adversarial training to ImageNet.
\end_layout

\begin_layout Standard
We showed that adversarial training provides robustness to adversarial examples
 generated using one-step methods.
 While adversarial training didn’t help much against iterative methods we
 observed that adversarial examples generated byiterative methods are less
 likely to be transferred between networks, which provides indirect robust-ness
 against black box adversarial attacks.
 In addition we observed that increase of model capacity could also help
 to increase robustness to adversarial examples especially when used in
 conjunc-tion with adversarial training.
 Finally we discovered the effect of label leaking which resulted in higher
 accuracy on FGSM adversarial examples compared to clean examples when the
 network was adversarially trained.
\end_layout

\begin_layout Subsubsection
1702.04267: ONDETECTINGADVERSARIALPERTURBATIONS
\end_layout

\begin_layout Standard
In this work, we propose to augmentdeep neural networks with a small “detector”
 subnetwork which is trained onthe binary classification task of distinguishing
 genuine data from data containingadversarial perturbations.
 Our method is orthogonal to prior work on addressingadversarial perturbations,
 which has mostly focused on making the classificationnetwork itself more
 robust.
\end_layout

\begin_layout Subsubsection

\color blue
1703.09202: Biologically inspired protection of deep networks from adversarial
 attacks (Saturated Network)
\end_layout

\begin_layout Standard
Our scheme generates highly nonlinear, saturated neural networks that achieve
 state of the art performance on gradient based adversarial examples on
 MNIST, despite never being exposed to adversarially chosen examples during
 training.
\end_layout

\begin_layout Standard
A natural starting point to achieve adversarial robustness is to ensure
 that each element of the Jacobian of the model, 
\begin_inset Formula $J=\partial F/\partial X^{0}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
1704.01155: Feature Squeezing: Detecting Adversarial Examples in Deep Neural
 Networks
\end_layout

\begin_layout Standard
We propose a new strategy, feature squeezing , that can be used to harden
 DNN models by detecting adversarial examples.
 Feature squeezing reduces the search space available to an adversary by
 coalescing samples that correspond to many di ff erent feature vectors
 in the original space into a single sample.
 By comparing a DNN model’s prediction on the original input with that on
 squeezed inputs, feature squeezing detects adversarial examples with high
 accuracy and few false positives.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\max(|v_{0}-v_{1}|,|v_{o}-v_{2}|)>T?
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $v_{o},v_{1},v_{2}$
\end_inset

 are different feature vectors for the same sample, produced by pre-processing
 input with feature squeezers.
\end_layout

\begin_layout Subsubsection
1704.03453: The Space of Transferable Adversarial Examples (Ian)
\end_layout

\begin_layout Standard
In this work, we propose novel methods for estimating the previously unknowndime
nsionalityof the space of adversarial inputs.
 We find that adversarial examplesspan a contiguous subspace of large (~25)
 dimensionality.
 Adversarial subspaceswith higher dimensionality are more likely to intersect.
 We find that for twodifferent models, a significant fraction of their subspaces
 is shared, thus enablingtransferability.
\end_layout

\begin_layout Subsubsection
1705.07204: ENSEMBLE ADVERSARIAL TRAINING: ATTACKS AND DEFENSES (Ian)
\end_layout

\begin_layout Standard
To scale this technique to large datasets, perturbations are crafted usingfastsi
ngle-stepmethods that maximize a linear approximation of the model’s loss.We
 show that this form of adversarial training converges to a degenerate globalmin
imum, wherein small curvature artifacts near the data points obfuscate a
 lin-ear approximation of the loss.
 The model thus learns to generate weak perturba-tions, rather than defend
 against strong ones.
\end_layout

\begin_layout Standard
We find that adversarial training remains vulnerable to black-box attacks,
 where we transfer perturbations computed on undefended models, as well
 as to a powerful novel single-step attack that escapes the non-smooth vicinity
 of the input data via a small random step.
\end_layout

\begin_layout Standard
We further introduce Ensemble Adversarial Training, a technique that augments
 training data with perturbations transferred from other models.
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

Adversarial machine learning at scale.
\begin_inset Quotes erd
\end_inset

 found that these attackes fail to reliably transfer between models, and
 thus concluded that the robustness of their model should extend to black-box
 adversaries.
 Surprisingly, we show that this is not the case.
\end_layout

\begin_layout Standard
Adversarial training with single-step methods admits a degenerate global
 minimum, where in the model's loss can not be reliably approximated by
 a linear function.
 We harness this result in two ways.
 First, we show that adversarially trained models using single-stepmethods
 remain vulnerable to simple attacks.
 For black-box adversaries, we find that perturbationscrafted on an undefended
 model often transfer to an adversarially trained one.
\end_layout

\begin_layout Standard
The proposed Ensemble Adversarial Training incorporates perturbed inputs
 transferred from other pre-trained models.
 This approach decouples adversarial example generation from the parameters
 of the trained model, and increases the diversity of perturbations seen
 during training.
\end_layout

\begin_layout Standard
Bimodal phenomenon: most points x either have 0 adversarial directions or
 more than 90.
\end_layout

\begin_layout Standard
Gradient Masking Effect.
\end_layout

\begin_layout Standard
Our results, generic with respect to the application domain, sug-gest that
 adversarial training can be improved bydecouplingthe generation of adversarial
 examplesfrom the model being trained.
\end_layout

\begin_layout Standard
This is a good paper.
\end_layout

\begin_layout Subsubsection
1705.07213: MTDeep: Boosting the Security of Deep Neural Nets Against Adversarial
 Attacks with Moving Target Defense
\end_layout

\begin_layout Standard
In this paper, we derive inspiration from re-cent advances in the fields
 of cybersecurity and multi-agentsystems and propose to use the concept
 ofMoving Target De-fense (MTD)for increasing the robustness of a set of
 deepnetworks against such adversarial attacks.
 To this end, we for-malize and exploit the notion ofdifferential immunityof
 anensemble of networks to specific attacks.
 To classify an inputimage, a trained network is picked from this set of
 networksby formulating the interaction between a Defender (who hoststhe
 classification networks) and their (Legitimate and Mali-cious) Users as
 a repeatedBayesian Stackelberg Game (BSG).
\end_layout

\begin_layout Subsubsection
1705.09064: MagNet: a Two-Pronged Defense against Adversarial Examples
\end_layout

\begin_layout Standard
We propose MagNet, a framework for defending neural networkclassifiers against
 adversarial examples.
 The detectornetworks learn to differentiate between normal and adversarial
 ex-amples by approximating the manifold of normal examples.
 The reformer network moves adversarial ex-amples towards the manifold of
 normal examples, which is effectivefor correctly classifying adversarial
 examples with small pertur-bation.
\end_layout

\begin_layout Subsubsection
1706.06083: Towards Deep Learning Models Resistant to Adversarial Attacks
 (PGD)
\end_layout

\begin_layout Standard
In fact, some of the latest findings suggest that the existence of adversarialat
tacks may be an inherent weakness of deep learning models.
 To address this problem, westudy the adversarial robustness of neural networks
 through the lens of robust optimization.
\end_layout

\begin_layout Standard
This paper provides a good overview about network robustness.
\end_layout

\begin_layout Subsubsection
1707.05474: APE-GAN: Adversarial Perturbation Elimination with GAN
\end_layout

\begin_layout Standard
In this paper, a novel idea is proposed and aneffective framework based
 Generative Adversarial Netsnamed APE-GAN is implemented to defense against
 theadversarial examples.
\end_layout

\begin_layout Subsubsection
1710.10571: Certifying Some Distributional Robustness with Principled Adversarial
 Training
\end_layout

\begin_layout Standard
We address this problem through the principled lens of distributionally
 robust optimization, which guarantees performa nce under adversarial input
 perturbations.
 By considering a Lagrangian penalty formulation of perturbing the underlying
 data distribution in a Wasserstein ball, we provide a training procedur
 e that augments model parameter updates with worst-case perturbations of
 training da ta.
 For smooth losses, our pro- cedure provably achieves moderate levels of
 robustness with little c omputational or statistical cost relative to empirical
 risk minimization.
 Furthermore, our statis tical guarantees allow us to efficiently certify
 robustness for the population loss
\end_layout

\begin_layout Subsubsection

\color blue
1711.00117: Countering Adversarial Images Using Input Transformations
\end_layout

\begin_layout Standard
This paper investigates strategies that defend against adversarial-example
 attackson image-classification systems by transforming the inputs before
 feeding themto the system.
 Specifically, we study applying image transformations such asbit-depth
 reduction, JPEG compression, total variance minimization, and imagequilting
 before feeding the image to a convolutional network classifier.
\end_layout

\begin_layout Standard
The image transforms are good at countering the (iterative) fast gradient
 sign method, deepfool, and the C&W attack, even in gray-box settings in
 which the model architecture and parameters are public.
\end_layout

\begin_layout Standard
This paper provides a good overview.
\end_layout

\begin_layout Subsubsection
1711.00851: Provable Defenses against Adversarial Examples via the Convex
 Outer Adversarial Polytope (CMU)
\end_layout

\begin_layout Standard
We propose a method to learn deep ReLU-basedclassifiers that are provably
 robust against norm-bounded adversarial perturbations on the trainingdata.
\end_layout

\begin_layout Standard
The basic idea is to considera convex outer approximationof the set of acti-vati
ons reachable through a norm-bounded per-turbation, and we develop a robust
 optimizationprocedure that minimizes the worst case loss overthis outer
 region (via a linear program).
\end_layout

\begin_layout Standard
This is a good paper.
\end_layout

\begin_layout Subsubsection
1711.01991: Mitigating adversarial effects through randomization
\end_layout

\begin_layout Standard
In this paper, we propose to utilize randomizationat inference time to mitigate
 adversarial effects.
 Specifically, we use two random-ization operations: random resizing, which
 resizes the input images to a randomsize, and random padding, which pads
 zeros around the input images in a ran-dom manner.
 Extensive experiments demonstrate that the proposed randomiza-tion method
 is very effective at defending against both single-step and iterative at-tacks.
\end_layout

\begin_layout Standard
No additional training or fine-tuning.
 Very few additional computations.
 Compatible with other adversarial defense methods.
\end_layout

\begin_layout Subsubsection

\color blue
1711.02846: INTRIGUING PROPERTIES OF ADVERSARIAL EXAMPLES (QuocLe)
\end_layout

\begin_layout Standard
In attempting to explain the origin of adversarialexamples, previous studies
 have typically focused on the fact that neural networksoperate on high
 dimensional data, they overfit, or they are too linear.
 Here weargue that the origin of adversarial examples is primarily due to
 an inherent uncer-tainty that neural networks have about their predictions.
 We show that the func-tional form of this uncertainty is independent of
 architecture, dataset, and trainingprotocol; and depends only on the statistics
 of the logit differences of the network,which do not change significantly
 during training.
\end_layout

\begin_layout Standard
Finally, we study the effect of network architectures onadversarial sensitivity.
 To do this, we use neural architecture search with rein-forcement learning
 to find adversarially robust architectures on CIFAR10.
\end_layout

\begin_layout Standard
Adversarial error due to theFast Gradient Sign Method (FGSM), its L2-norm
 variant, and Projected Gradient Descent (PGD) attack grows as a power-law
 like 
\begin_inset Formula $A\epsilon^{B}$
\end_inset

 with B between 0.9 and 1.3.
 Adversarial error caused by FGSM on the training set of randomly shuffled
 labelsof MNIST (LeCun & Cortes) also has the power-law form whereB= 1.2,
 which implies that theuniversality is not a result of the specific content
 of these datasets nor the ability of the model togeneralize.
\end_layout

\begin_layout Standard
We demonstrate that the susceptibility of a model to FGSM and PGD attacks
 is in large part dictatedby the cumulative distribution of the difference
 between the most likely logit and the second mostlikely logit.
 We observe that this cumulative distribution has a universal form among
 all datasetsand models studied, including randomly produced data.
 Together, we believe these results providea compelling story regarding
 the susceptibility of machine learning models to adversarial examplesat
 small.
\end_layout

\begin_layout Standard
SURPRISING UNIVERSALITY OF ADVERSARIAL ERROR AT SMALL epsilon.
\end_layout

\begin_layout Standard
In this paper we studied common properties of adversarial examples across
 different models anddatasets.
 We theoretically derived a universality in logit differences and adversarial
 error of machinelearning models.
 We showed that architecture plays an important role in adversarial robustness,w
hich correlates strongly with clean accuracy.
\end_layout

\begin_layout Standard
This is an good and important paper.
\end_layout

\begin_layout Subsubsection
1712.00673: Towards Robust Neural Networks via Random Self-ensemble
\end_layout

\begin_layout Standard
In this paper, we propose a new defense algorithm called Random Self- Ensemble
 (RSE) by combining two important concepts: randomness and ensemble .
 To protect a targeted model, RSE adds random noise layers to the neural
 network to prevent the strong gradient-based attacks, and ensembles the
 prediction over random noises to stabilize the perfor- mance.
 We show that our algorithm is equivalent to ensemble an infinite number
 of noisy models f without any additional memory overhead, and the proposed
 training procedure based on noisy stochastic gradient descent can ensure
 the ensemble model has a good predictive capability.
\end_layout

\begin_layout Standard
This is a good paper.
\end_layout

\begin_layout Subsubsection
1712.02976: Defense against Adversarial Attacks Using High-Level Representation
 Guided Denoiser (HGD, NIPS2017 winner)
\end_layout

\begin_layout Standard
We propose high-level representation guideddenoiser (HGD) as a defense for
 image classification.
 Stan-dard denoiser suffers from the error amplification effect, inwhich
 small residual adversarial noise is progressively am-plified and leads
 to wrong classifications.
 HGD overcomesthis problem by using a loss function defined as the differ-ence
 between the target model’s outputs activated by theclean image and denoised
 image.
 Compared with ensembleadversarial training which is the state-of-the-art
 defendingmethod on large images, HGD has three advantages.
 First,with HGD as a defense, the target model is more robust toeither white-box
 or black-box adversarial attacks.
 Second,HGD can be trained on a small subset of the images andgeneralizes
 well to other images and unseen classes.
 Third,HGD can be transferred to defend models other than theone guiding
 it.
\end_layout

\begin_layout Subsubsection
1712.04006: Training Ensembles to Detect Adversarial Examples
\end_layout

\begin_layout Standard
We propose a new ensemble method for detecting and classifying adversarial
 ex-amples generated by state-of-the-art attacks, including DeepFool and
 C&W.
 Ourmethod works by training the members of an ensemble to have low classificati
onerror on random benign examples while simultaneously minimizing agreementon
 examples outside the training distribution.
\end_layout

\begin_layout Standard
Slightly reduced adversarial purturbation effectiveness.
\end_layout

\begin_layout Subsubsection
2018-ICLR: THERMOMETERENCODING: ONEHOT WAY TO RESIST ADVERSARIALEXAMPLES
\end_layout

\begin_layout Standard
We propose a simple modification to standard neural network ar-chitectures,therm
ometer encoding, which significantly increases the robustnessof the network
 to adversarial examples.
\end_layout

\begin_layout Subsubsection
1801.08926: Deflecting Adversarial Attacks with Pixel Deflection (Pixel Deflectio
n + Wavelet)
\end_layout

\begin_layout Standard
We present an algorithm to process animage so that classification accuracy
 is significantly pre-served in the presence of such adversarial manipulations.Im
age classifiers tend to be robust to natural noise, andadversarial attacks
 tend to be agnostic to object location.These observations motivate our strategy,
 which leveragesmodel robustness to defend against adversarial perturba-tions
 by forcing the image to match natural image statistics.Our algorithm locally
 corrupts the image by redistributingpixel values via a process we term
 pixel deflection.
 A subse-quent wavelet-based denoising operation softens this cor-ruption,
 as well as some of the adversarial changes.
\end_layout

\begin_layout Subsubsection
1801.09344: CERTIFIED DEFENSES AGAINST ADVERSARIAL EXAMPLES
\end_layout

\begin_layout Standard
Defenses based on regularization and ad- versarial training have been proposed,
 but often followed by new, stronger attacks that defeat these defenses.
 Can we somehow end this arms race? In this work,we study this problem for
 neural networks with one hidden layer.
 We first pro-pose a method based on a semidefinite relaxation that outputs
 acertificatethat fora given network and test input, no attack can force
 the error to exceed a certainvalue.
 Second, as this certificate is differentiable, we jointly optimize it with
 thenetwork parameters, providing anadaptive regularizer that encourages
 robustnessagainst all attacks.
\end_layout

\begin_layout Standard
On MNIST, our approach produces a network and a certificate that no attack
 that perturbs each pixel by at most 
\end_layout

\begin_layout Standard
= 0 .
 1 can cause more than 35% test error.
\end_layout

\begin_layout Subsubsection
1802.05666: Adversarial Risk and the Dangers of Evaluating Against Weak Attacks
 (ICML)
\end_layout

\begin_layout Standard
Wemotivateadversarial riskas an objective forachieving models robust to
 worst-case inputs.
 Wethen frame commonly used attacks and evaluationmetrics as defining a
 tractable surrogate objectiveto the true adversarial risk.
 This suggests thatmodels may optimize this surrogate rather thanthe true
 adversarial risk.
 We formalize this notionasobscurity to an adversary, and develop toolsand
 heuristics for identifying obscured modelsand designing transparent models.
 We demon-strate that this is a significant problem in practiceby repurposing
 gradient-free optimization tech-niques into adversarial attacks, which
 we use todecrease the accuracy of several recently proposeddefenses to
 near zero.
\end_layout

\begin_layout Subsubsection
1803.02988: Rethinking Feature Distribution for Loss Functions in Image Classific
ation
\end_layout

\begin_layout Standard
We propose a large-margin Gaussian Mixture (L-GM)loss for deep neural networks
 in classification tasks.
 By involving a classification margin and a likelihood regular-ization,
 the L-GM loss facilitates both a high classification performance and an
 accurate modeling of the training fea-ture distribution.
 As such, the L-GM loss is superior to the softmax loss and its major variants
 in the sense that besidesclassification, it can be readily used to distinguish
 abnormalinputs, such as the adversarial examples, based on their features’
 likelihood to the training feature distribution.
\end_layout

\begin_layout Subsubsection
1803.06373: Adversarial Logit Pairing (Ian)
\end_layout

\begin_layout Standard
Next, we introduce enhanced defenses using atechnique we call logit pairing,
 a method that en-courages logits for pairs of examples to be sim-ilar.
 When applied to clean examples and theiradversarial counterparts, logit
 pairing improvesaccuracy on adversarial examples over vanilla ad-versarial
 training; we also find that logit pairingon clean examples only is competitive
 with ad-versarial training in terms of accuracy on twodatasets.
\end_layout

\begin_layout Subsubsection
1803.07994: Adversarial Defense based on Structure-to-Signal Autoencoders
 (S2SNets)
\end_layout

\begin_layout Standard
We pro-pose a novel way to interpret adversarial perturbations in terms
 of theeffective input signal that classifiers actually use.
\end_layout

\begin_layout Standard
We model the defense strategy as a transformation of thedomain used by attackers
, namely gradients coming from the attacked classi-fier.
 Instead of focusing on gradient obfuscation via non-differentiable methodsor
 any other instabilities, we purposely induce a transformation on the gradi-ents
 that strip them from any semantic information.
 S2SNets work by maskingthe classifier via the function composition.
\end_layout

\begin_layout Subsubsection
1804.02485: Fortified Networks: Improving the Robustness of Deep Networks
 by Modeling the Manifold of Hidden Representations (Bengio)
\end_layout

\begin_layout Standard
We proposeFortified Networks, a simple transfor-mation of existing networks,
 which fortifies thehidden layers in a deep network by identifyingwhen the
 hidden states are off of the data manifold,and maps these hidden states
 back to parts of thedata manifold where the network performs well.
\end_layout

\begin_layout Subsubsection
1805.06605: DEFENSE-GAN: PROTECTINGCLASSIFIERS AGAINSTADVERSARIALATTACKSUSING
 GENERATIVEMODELS (Rama)
\end_layout

\begin_layout Standard
We propose Defense-GAN, a newframework leveraging the expressive capability
 of generative models to defenddeep neural networks against such attacks.
 Defense-GAN is trained to model thedistribution of unperturbed images.
 At inference time, it finds a close output to agiven image which does not
 contain the adversarial changes.
 This output is thenfed to the classifier.
\end_layout

\begin_layout Subsubsection
1805.09190: TOWARDS THE FIRST ADVERSARIALLY ROBUST NEURAL NETWORK MODEL ON
 MNIST (ABS)
\end_layout

\begin_layout Standard
We present a novel robust classification model that performs analysis by
 synthesis using learned class-conditional data distributions.
 We derive bounds on the robustness and go to great length to empirically
 evaluateour model using maximally effective adversarial attacks by (a)
 applying decision-based, score-based, gradient-based and transfer-based
 attacks for several differentLpnorms, (b) by designing a new attack that
 exploits the structure of our defendedmodel and (c) by devising a novel
 decision-based attack that seeks to minimizethe number of perturbed pixels
 (L0).
\end_layout

\begin_layout Subsubsection
1806.00081: Resisting Adversarial Attacks Using Gaussian Mixture Variational
 Autoencoders
\end_layout

\begin_layout Standard
Our model has the form of a varia-tional autoencoder with a Gaussian mixture
 prior on the latentvariable, such that each mixture component corresponds
 toa single class.
 We show how selective classification can beperformed using this model,
 thereby causing the adversarialobjective to entail a conflict.
 The proposed method leads to therejection of adversarial samples instead
 of misclassification,while maintaining high precision and recall on test
 data.
\end_layout

\begin_layout Subsubsection
1807.10454: Rob-GAN: Generator, Discriminator, and Adversarial Attacker
\end_layout

\begin_layout Standard
We show the generator can improve adversarial train-ing, and the adversarial
 attacker can improve GAN training.Based on these two insights, we proposed
 to combine gen-erator, discriminator and adversarial attacker in the samesystem
 and conduct end-to-end training.
 The proposed sys-tem simultaneously leads to a better generator and a morerobus
t discriminator compared with state-of-the-art models.
\end_layout

\begin_layout Standard
Adversarial training is acknowledged the most powerful defense algorithm.
\end_layout

\begin_layout Subsubsection
1808.06645: Stochastic Combinatorial Ensembles for Defending Against Adversarial
 Examples
\end_layout

\begin_layout Standard
To address the limitations of existing defenses, we devised a probabilisticframe
work that can generate an exponentially large ensemble of models from asingle
 model with just a linear cost.
 This framework takes advantage of neuralnetwork depth and stochastically
 decides whether or not to insert noise removal op-erators such as VAEs
 between layers.
\end_layout

\begin_layout Standard
In summary, adversarial examples are likely to exist very close to but off
 the data manifold, in regionsof low probability under the training set
 distribution.
\end_layout

\begin_layout Subsubsection
1810.01279: ADV-BNN: IMPROVED ADVERSARIAL DEFENSE THROUGH ROBUST BAYESIAN
 NEURAL NETWORK
\end_layout

\begin_layout Standard
Instead, we modelrandomness under the framework of Bayesian Neural Network
 (BNN) to formallylearn the posterior distribution of models in a scalable
 way.
 Second, we formulatethe mini-max problem in BNN to learn the best model
 distribution under adversar-ial attacks, leading to an adversarial-trained
 Bayesian neural network.
\end_layout

\begin_layout Standard
Randomness -> Bayesian.
\end_layout

\begin_layout Subsubsection
1811.01396: Handwriting Recognition in Low-resource Scripts using Adversarial
 Learning
\end_layout

\begin_layout Standard
We propose the Adversar-ial Feature Deformation Module (AFDM) that learns
 waysto elastically warp extracted features in a scalable man-ner.
 The AFDM is inserted between intermediate layers andtrained alternatively
 with the original framework, boost-ing its capability to better learn highly
 informative fea-tures rather than trivial ones.
\end_layout

\begin_layout Subsubsection
1812.00037: Adversarial Defense by Stratified Convolutional Sparse Coding
\end_layout

\begin_layout Standard
Based on convolutional sparse cod-ing, we construct a stratified low-dimensional
 quasi-naturalimage space that faithfully approximates the natural imagespace
 while also removing adversarial perturbations.
\end_layout

\begin_layout Subsubsection
1812.00740: Disentangling Adversarial Robustness and Generalization
\end_layout

\begin_layout Standard
In an effort to clar-ify the relationship between robustness and generalization,
we assume an underlying, low-dimensional data manifoldand show that: 1.
 regular adversarial examples leave themanifold; 2.
 adversarial examples constrained to the mani-fold, i.e., on-manifold adversarial
 examples, exist; 3.
 on–manifold adversarial examples are generalization errors,and on-manifold
 adversarial training boosts generaliza-tion; 4.
 regular robustness and generalization are not nec-essarily contradicting
 goals.
 These assumptions imply thatbothrobustandaccurate models are possible.
 However,different models (architectures, training strategies etc.) canexhibit
 different robustness and generalization characteris-tics.
\end_layout

\begin_layout Subsubsection
1812.03411: Feature Denoising for Improving Adversarial Robustness (Kaiming)
\end_layout

\begin_layout Standard
This study suggests thatadversarial perturbations on images lead to noise
 in thefeatures constructed by these networks.
 Motivated by thisobservation, we develop new network architectures thatincrease
 adversarial robustness by performing featuredenoising.
 Specifically, our networks contain blocks thatdenoise the features using
 non-local means or other filters;the entire networks are trained end-to-end.
 When combinedwith adversarial training, our feature denoising networkssubstanti
ally improve the state-of-the-art in adversarial robustness in both white-box
 and black-box attack set-tings.
\end_layout

\begin_layout Standard
PGD + Adversarial Training.
\end_layout

\begin_layout Subsubsection
1901.04684: The limitationsap of adversarial training and the blind-spot
 attack
\end_layout

\begin_layout Standard
The adversarial training procedure proposed by Madry et al.
 (2018) is one of themost effective methods to defend against adversarial
 examples in deep neural net-works (DNNs).
 In our paper, we shed some lights on the practicality and thehardness of
 adversarial training by showing that the effectiveness (robustness ontest
 set) of adversarial training has a strong correlation with the distance
 betweena test point and the manifold of training data embedded by the network.
 Testexamples that are relatively far away from this manifold are more likely
 to bevulnerable to adversarial attacks.
 Consequentially, an adversarial training baseddefense is susceptible to
 a new class of attacks, the“blind-spot attack”, where theinput images reside
 in “blind-spots” (low density regions) of the empirical distri-bution of
 training data but is still on the ground-truth data manifold.
\end_layout

\begin_layout Subsubsection
1902.06415: AuxBlocks: Defense Adversarial Example via Auxiliary Blocks
\end_layout

\begin_layout Standard
In this paper, we propose a new defense method based onappending information.
 We introduce the Aux Block modelto produce extra outputs as a self-ensemble
 algorithm andanalytically investigate the robustness mechanism of Aux Block.
\end_layout

\begin_layout Standard
Our main idea is to introduceAux Blockand then divide themodel into two
 versions: apublicmodel and aprivatemodel.More specifically, thepublicmodel
 is a standard convolutionalneural network and theprivateis several branching
 auxiliarymodels as shown in Fig.
 2.
 Thepublicmodel can be revealedto attackers while theprivatemodel is confidentia
l to them,so malicious hackers cannot create valid examples easily.
 Anaux Block can be any structure, and in this paper we proposea tiny neural
 network.
\end_layout

\begin_layout Subsubsection
1903.00788: AIRD: Adversarial Learning Framework for Image Repurposing Detection
\end_layout

\begin_layout Standard
In this paper, wepresent a novel method for image repurposing detection
 thatis based on the real-world adversarial interplay betweena bad actor
 who repurposes images with counterfeit meta-data and a watchdog who verifies
 the semantic consistencybetween images and their accompanying metadata,
 whereboth players have access to a reference dataset of verifiedcontent,
 which they can use to achieve their goals.
\end_layout

\begin_layout Subsubsection
1903.01015: A Kernelized Manifold Mapping to Diminish the Effect ofAdversarial
 Perturbations
\end_layout

\begin_layout Standard
The linear and non-flexible nature of deep convolutionalmodels makes them
 vulnerable to carefully crafted adver-sarial perturbations.
 To tackle this problem, we proposea non-linear radial basis convolutional
 feature mappingby learning a Mahalanobis-like distance function.
 Ourmethod then maps the convolutional features onto a linearlywell-separated
 manifold, which prevents small adversarialperturbations from forcing a
 sample to cross the decisionboundary.
\end_layout

\begin_layout Subsubsection
1903.01612: Defense Against Adversarial Images using Web-Scale Nearest-Neighbor
 Search
\end_layout

\begin_layout Standard
In this work, we hypothesize that adversarial perturbationsmove the image
 away from the image manifold in the sensethat there exists no physical
 process that could have pro-duced the adversarial image.
 This hypothesis suggests thata successful defense mechanism against adversarial
 im-ages should aim to project the images back onto the im-age manifold.
 We study such defense mechanisms, whichapproximate the projection onto
 the unknown image mani-fold by a nearest-neighbor search against a web-scale
 im-age database containing tens of billions of images.
\end_layout

\begin_layout Standard
This paper also provides two new white box attacking methods based on PGD
 against it's own defense method.
\end_layout

\begin_layout Subsubsection
1904.09290: FeatherNets: Convolutional Neural Networks as Light as Feather
 for Face Anti-spoofing
\end_layout

\begin_layout Standard
Face Anti-spoofing gains increased attentions recently inboth academic and
 industrial fields.
 With the emergenceof various CNN based solutions, the multi-modal(RGB,
 depth and IR) methods based CNN showed better perfor-mance than single
 modal classifiers.
 However, there isa need for improving the performance and reducing thecomplexit
y.
 Therefore, an extreme light network architec-ture(FeatherNet A/B) is proposed
 with a streaming modulewhich fixes the weakness of Global Average Pooling
 anduses less parameters.
\end_layout

\begin_layout Subsection
Applications
\end_layout

\begin_layout Subsubsection
1608: Hidden Voice Commands (USENIX Security)
\end_layout

\begin_layout Standard
We explore in this paper how they can be attacked with hidden voice commands
 that are unintelligible to human listeners but which are interpreted as
 commands by devices.
 We evaluate these attacks under two different threat models: black-box
 and white-box.
\end_layout

\begin_layout Standard
This is not attacking neural networks but classical algorithms.
 Several possible defenses are proposed.
\end_layout

\begin_layout Subsubsection
2017-WOOT: Adversarial Example Defenses: Ensembles of Weak Defenses are
 not Strong
\end_layout

\begin_layout Standard
Weask whether a strong defense can be created by combin-ing multiple (possibly
 weak) defenses.
 To answer thisquestion, we study three defenses that follow this ap-proach.
 Two of these are recently proposed defenses thatintentionally combine component
s designed to work welltogether.
 A third defense combines three independent de-fenses.
 For all the components of these defenses and thecombined defenses themselves,
 we show that an adaptiveadversary can create adversarial examples successfullyw
ith low distortion.
 Thus, our work implies that ensem-ble of weak defenses is not sufficient
 to provide strongdefense against adversarial examples.
\end_layout

\begin_layout Subsubsection
1702.02284: Adversarial Attacks on Neural Network Policies
\end_layout

\begin_layout Standard
In thiswork, we show adversarial attacks are also effective when targeting
 neural networkpolicies in reinforcement learning.
 Specifically, we show existing adversarial exam-ple crafting techniques
 can be used to significantly degrade test-time performanceof trained policies.
\end_layout

\begin_layout Standard
Adversarial Example Crafting with the FGSM.
\end_layout

\begin_layout Subsubsection
1702.06832: ADVERSARIAL EXAMPLES FOR GENERATIVE MODELS
\end_layout

\begin_layout Standard
We explore methods of producing adversarial examples on deep generative
 mod-els such as the variational autoencoder (VAE) and the VAE-GAN.
 Deep learningarchitectures are known to be vulnerable to adversarial examples,
 but previouswork has focused on the application of adversarial examples
 to classification tasks.
\end_layout

\begin_layout Subsubsection
1703.06748: Tactics of Adversarial Attack on Deep Reinforcement Learning
 Agents
\end_layout

\begin_layout Standard
We introduce two tactics, namely the strategically-timed attack and the
 enchanting attack, to attackreinforcement learning agents trained by deep
 re-inforcement learning algorithms using adversarialexamples.
\end_layout

\begin_layout Standard
In 5 Atari games,our strategically-timed attack reduces as much re-ward
 as the uniform attack (i.e., attacking at everytime step) does by attacking
 the agent 4 times lessoften.
 Our enchanting attack lures the agent towarddesignated target states with
 a more than 70% suc-cess rate.
\end_layout

\begin_layout Subsubsection
1707.03501: NO Need to Worry about Adversarial Examples in Object Detection
 in Autonomous Vehicles
\end_layout

\begin_layout Standard
However, these experiments ignore a crucial property ofphysical objects:
 the camera can view objects from differ-ent distances and at different
 angles.
 In this paper, we showexperiments that suggest that current constructions
 of phys-ical adversarial examples do not disrupt object detectionfrom a
 moving platform.
 Instead, a trained neural networkclassifies most of the pictures taken
 from different distancesand angles of a perturbed image correctly.
 We believe this isbecause the adversarial property of the perturbation
 is sen-sitive to the scale at which the perturbed picture is viewed,so
 (for example) an autonomous car will misclassify a stopsign only from a
 small range of distances.
\end_layout

\begin_layout Standard
Our work raises an important question: can one con-struct examples that
 are adversarial for many or most view-ing conditions? If so, the construction
 should offer very sig-nificant insights into the internal representation
 of patternsby deep networks.
 If not, there is a good prospect that ad-versarial examples can be reduced
 to a curiosity with little practical impact.
\end_layout

\begin_layout Subsubsection
1707.07328: Adversarial Examples for Evaluating Reading Comprehension Systems
\end_layout

\begin_layout Standard
Our methodtests whether systems can answer ques-tions about paragraphs that
 contain adver-sarially inserted sentences, which are au-tomatically generated
 to distract computersystems without changing the correct an-swer or misleading
 humans.
\end_layout

\begin_layout Subsubsection
1711.09856: On the Robustness of Semantic Segmentation Models to Adversarial
 Attacks
\end_layout

\begin_layout Standard
This phenomenon has recently attracted a lot ofattention but it has not
 been extensively studied on multi-ple, large-scale datasets and complex
 tasks such as seman-tic segmentation which often require more specialised
 net-works with additional components such as CRFs, dilatedconvolutions,
 skip-connections and multiscale processing.
\end_layout

\begin_layout Standard
In this paper, we present what to our knowledge is thefirst rigorous evaluation
 of adversarial attacks on mod-ern semantic segmentation models, using two
 large-scaledatasets.
 We analyse the effect of different network architec-tures, model capacity
 and multiscale processing, and showthat many observations made on the task
 of classification donot always transfer to this more complex task.
 Furthermore,we show how mean-field inference in deep structured mod-els
 and multiscale processing naturally implement recentlyproposed adversarial
 defenses
\end_layout

\begin_layout Subsubsection
2018-MM: When Deep Fool Meets Deep Prior: Adversarial Attack on Super-Resolution
 Network
\end_layout

\begin_layout Standard
We formu-late the adversarial example generation process as an optimizationprobl
em, and given super-resolution model three different types ofattack are
 designed based on the subsequent tasks: (i) style transferattack; (ii)
 classification attack; 
\color red
(iii) caption attack.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\min_{\delta}L(\text{SRnet}(I+\delta),T)+\lambda\cdot||\delta||_{2}^{2}\\
s.t.\,I+\delta\in[0,1]^{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
2018-WOOT: Fishy Faces: Crafting Adversarial Images to Poison Face Authenticatio
n
\end_layout

\begin_layout Standard
This work is thefirst to deploy apoisoningattack against an authentica-tion
 system based on a state-of-the-art face recognitiontechnique.
 The attack is executed against the underly-ing SVM learning model that
 classifies face templatesextracted by the FaceNet deep neural network.
\end_layout

\begin_layout Subsubsection
1801.01944: Audio Adversarial Examples: Targeted Attacks on Speech-to-Text
\end_layout

\begin_layout Standard
We construct targeted audio adversarial exampleson automatic speech recognition.
 Given any audio waveform,we can produce another that is over 99.9% similar,
 buttranscribes as any phrase we choose (recognizing up to 50characters
 per second of audio).
 We apply our white-boxiterative optimization-based attack to Mozilla’s
 implementationDeepSpeech end-to-end, and show it has a 100% success rate.
\end_layout

\begin_layout Subsubsection
1804.05296: Adversarial Attacks Against Medical Deep Learning Systems
\end_layout

\begin_layout Standard
In this paper,we demonstrate that adversarial examples are capable of manip-ulat
ing deep learning systems across three clinical domains.
 Foreach of our representative medical deep learning classifiers, bothwhite
 and black box attacks were highly successful.
\end_layout

\begin_layout Subsubsection
1804.05810: ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN
 Object Detector (Physical Example)
\end_layout

\begin_layout Standard
Inthis work, we proposeShapeShifter, an attack that tackles the more challenging
problem of crafting physical adversarial perturbations to fool image-based
 objectdetectors like Faster R-CNN.
 Attacking an object detector is more difficult thanattacking an image classifie
r, as it needs to mislead the classification results inmultiple bounding
 boxes with different scales.
 Extending the digital attack to thephysical world adds another layer of
 difficulty, because it requires the perturba-tion to be robust enough to
 survive real-world distortions due to different viewingdistances and angles,
 lighting conditions, and camera limitations.
 We show thattheExpectation over Transformationtechnique, which was originally
 proposedto enhance the robustness of adversarial perturbations in image
 classification, canbe successfully adapted to the object detection setting.Shape
Shiftercan generateadversarially perturbed stop signs that are consistently
 mis-detected by Faster R-CNN as other objects, posing a potential threat
 to autonomous vehicles and othersafety-critical computer vision systems.
\end_layout

\begin_layout Standard
Punches face of 1707.03501 authors.
\end_layout

\begin_layout Subsubsection

\color red
2018.0601-IJCAI: Interpretable Adversarial Perturbation in Input Embedding
 Space for Text
\end_layout

\begin_layout Standard
One promising approach directly ap- plies adversarial training developed
 in the image processing field to the input word embedding space instead
 of the discrete input space of texts.
 How- ever, this approach abandons such interpretability as generating adversari
al texts to significantly im- prove the performance of NLP tasks.
 This paper restores interpretability to such methods by restrict- ing the
 directions of perturbations toward the ex- isting words in the input embedding
 space.
\end_layout

\begin_layout Standard
The primary strategy for genrating adversarial examples in the NLP field
 clearly differs from those developed in the image processing field, which
 are rather ad-hoc, e.g.
 using human knowledge, dictionaries, or require such costly procedures
 as exhaustive searches.
\end_layout

\begin_layout Standard
This paper leverages adversarial traning (by adv example) as a measure for
 regularization or performance boost.
\end_layout

\begin_layout Subsubsection

\color red
1806.01768: Evidential Deep Learning to Quantify Classification Uncertainty
\end_layout

\begin_layout Standard
In this paper, we put our full focus on the uncertainty estimation problem
 and approach it from a Theory of Evidence perspective [ 7 , 14 ].
 We interpret softmax , the standard output of a classification network,
 as the parameter set of a categorical distribution.
 By replacing this parameter set with the parameters of a Dirichlet density,
 we represent the predictions of the learner as a distribution over possible
 softmax outputs, rather than the point estimate of a softmax output.
 In other words, this density can intuitively be understood as a factory
 of these point estimates.
 The resultant model has a specific loss function, which is minimized subject
 to neural net weights using standard backprop.
\end_layout

\begin_layout Standard
In this work, we design a predictive distribution for classification by
 placing a Dirichlet distribution on the class probabilities and assigning
 neural network outputs to its parameters.
 We fit this predictive distribution to data by minimizing the Bayes risk
 with respect to the L2-Norm loss which is regularized by an information-theoret
ic complexity term.
 The resultant predictor is a Dirichlet distribution on class probabilities,
 which provides a more detailed uncertainty model than the point estimate
 of the standard softmax-output deep nets.
 We interpret the behavior of this predictor from an evidential reasoning
 perspective by building the link from its predictions to the belief mass
 and uncertainty decomposition of the subjective logic.
\end_layout

\begin_layout Subsubsection

\color red
1806.04425: Ranking Robustness Under Adversarial Document Manipulations
\end_layout

\begin_layout Standard
For many queries in the Web retrieval setting there is an on-going ranking
 competition: authors manipulate their documents so as to promote them in
 rankings.
 Such competitions can have un- warranted effects not only in terms of retrieval
 effectiveness, but also in terms of ranking robustness .
 A case in point, rankings can (rapidly) change due to small indiscernible
 perturbations of docu- ments.
 While there has been a recent growing interest in analyzing the robustness
 of classifiers to adversarial manipulations, there has not yet been a study
 of the robustness of relevance-ranking func- tions.
\end_layout

\begin_layout Standard
This paper focuses on analysis on robustness, and doesn't mention the attack
 at all.
 Secondly, this paper talks about manual documentation manipulation instead
 of automatic adversarial example genration for candidate attack.
 Thirdly, this paper targets at RankSVM and LambdaMART models instead of
 neural networks.
\end_layout

\begin_layout Subsubsection

\color red
1808.03908: Adversarial Personalized Ranking for Recommendation
\end_layout

\begin_layout Standard
Item recommendation is a personalized ranking task.
 To this end,many recommender systems optimize models with pairwise rank-ing
 objectives, such as the Bayesian Personalized Ranking (BPR).Using matrix
 Factorization (MF) — the most widely used model inrecommendation — as a
 demonstration, we show that optimizingit with BPR leads to a recommender
 model that is not robust.
\end_layout

\begin_layout Standard
To enhance the robustness of a recommender model and thusimprove its generalizat
ion performance, we propose a new optimiza-tion framework, namelyAdversarial
 Personalized Ranking(APR), based on adversarial training.
\end_layout

\begin_layout Subsubsection
1808.05665: Adversarial Attacks Against Automatic Speech Recognition Systems
 via Psychoacoustic Hiding
\end_layout

\begin_layout Standard
In this paper, we introduce a new type of adversarial examplesbased onpsychoacou
stic hiding.
 Our attack exploits the character-istics of DNN-based ASR systems, where
 we extend the originalanalysis procedure by an additional backpropagation
 step.
\end_layout

\begin_layout Subsubsection
1809: AdvBox: FaceNet Attack
\end_layout

\begin_layout Standard
https://github.com/advboxes/AdvBox/blob/master/applications/face_recognition_atta
ck/facenet_fr.py
\end_layout

\begin_layout Standard
\begin_inset Formula $L=\sqrt{\sum(E-E_{target})^{2}}$
\end_inset


\end_layout

\begin_layout Standard
This is query attack.
\end_layout

\begin_layout Subsubsection
1809.01093: Adversarial Attacks on Node Embeddings via Graph Poisoning
\end_layout

\begin_layout Standard
The goal of network representation learning is tolearn low-dimensional node
 embeddings that cap-ture the graph structure and are useful for solvingdownstre
am tasks.
 However, despite the prolifera-tion of such methods, there is currently
 no studyof their robustness to adversarial attacks.
 We pro-vide the first adversarial vulnerability analysison the widely used
 family of methods based onrandom walks.
\end_layout

\begin_layout Subsubsection
1809.02797: Fast Gradient Attack on Network Embedding
\end_layout

\begin_layout Standard
Network embedding maps a network into a low-dimensional Euclidean space,
 and thus facilitate many network analysis tasks, such as node classification,
 link prediction and community detection etc, by utilizing machine learning
 methods.
 In social networks, we may pay special attention to user privacy, and would
 like to prevent some target nodes from being identified by such network
 analysis methods in certain cases.
 Inspired by successful adversarial attack on deep learning models, we propose
 a framework to generate adversarial networks based on the gradient information
 in Graph Convolutional Network (GCN).
 In particular, we extract the gradient of pairwise nodes based on the adversari
al network, and select the pair of nodes with maximum absolute gradient
 to realize the Fast Gradient Attack (FGA) and update the adversarial network.
\end_layout

\begin_layout Subsubsection

\color red
1812.00552: Universal Perturbation Attack Against Image Retrieval
\end_layout

\begin_layout Standard
In this paper, we make the first attempt for UAP attacking to deep feature
 based image retrieval.
 Concretely, attacking image retrieval is to make the retrieval system return
 more irrelevant images to the query at the top ranking list, whose key
 design is to corrupt the relationships among features.
 To this end, we propose a unified method to generate retrieval-based UAP
 to break the relationships between image features from point-wise, label-wise,
 and list- wise aspects.
\end_layout

\begin_layout Standard
This paper directly attacks (maximize) triplet ranking loss function but
 what if the triplet fell into the zero-gradient region? The optimization
 algorithm used in this paper is PGD plus momentum.
 This paper studies query attack.
\end_layout

\begin_layout Subsubsection

\color red
2019-ICMR: Who’s Afraid of Adversarial Queries? The Impact of Image Modification
s on Content-based Image Retrieval
\end_layout

\begin_layout Standard
An adversarial query is an image that has been modified to dis- rupt content-bas
ed image retrieval (CBIR), while appearing nearly untouched to the human
 eye.
 This paper presents an analysis of adversarial queries for CBIR based on
 neural, local, and global features.
 We introduce an innovative neural image perturbation approach, called Perturbat
ions for Image Retrieval Error (PIRE), that is capable of blocking neural-featur
e-based CBIR.
\end_layout

\begin_layout Standard
The basic innovation of PIRE is to modify the original image by pushing
 its feature representation away from the origninal position in feature
 space.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\max||f(x)-f(x+v)||_{2}^{2}\\
||v||_{\infty}\leq\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The optimization process is PGD, or say a variant of the basic iterative
 method.
\end_layout

\begin_layout Standard
This paper aims at image retrieval (T-PAMI: Fine-tuning CNN image retrieval
 with no human annotation), and didn't mention embedding learning.
\end_layout

\begin_layout Subsubsection
1901.01250: Learning Graph Embedding with Adversarial Training Methods
\end_layout

\begin_layout Standard
They have mostly overlooked the embedding distribution of the latent codes,
 which unfortunately may lead toinferior representation in many cases.
 In this paper, we present a novel adversarially regularized framework for
 graph embedding.
\end_layout

\begin_layout Subsubsection
1904.00923: Robustness of 3D Deep Learning in an Adversarial Setting
\end_layout

\begin_layout Standard
In thiswork, we develop an algorithm for analysis of pointwise ro-bustness
 of neural networks that operate on 3D data.
 Weshow that current approaches presented for understandingthe resilience
 of state-of-the-art models vastly overestimatetheir robustness.
\end_layout

\begin_layout Standard
Applies to point-could and volumetric representations.
\end_layout

\begin_layout Subsubsection
1904.04433: Efficient Decision-based Black-box Adversarial Attacks on Face
 Recognition
\end_layout

\begin_layout Standard
In this paper, we evaluatethe robustness of state-of-the-art face recognition
 models inthe decision-based black-box attack setting, where the at-tackers
 have no access to the model parameters and gradi-ents, but can only acquire
 hard-label predictions by sendingqueries to the target model.
 This attack setting is more prac-tical in real-world face recognition systems.
 To improve theefficiency of previous methods, we propose an evolutionaryattack
 algorithm, which can model the local geometries ofthe search directions
 and reduce the dimension of the searchspace.
\end_layout

\begin_layout Standard
They report the average distortion.
\end_layout

\begin_layout Subsubsection

\series bold
1904: Imperceptible, Robust, and TargetedAdversarial Examples for Automatic
 Speech Recognition (Ian ASR)
\end_layout

\begin_layout Standard
Early works in this space, such as 
\begin_inset Quotes eld
\end_inset

Crafting adversarial examplesfor speech paralinguistics applications.
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Fooling deep structured prediction models.
\begin_inset Quotes erd
\end_inset

 was successful when generating untargeted adversarial examples that produced
 incorrect, but arbitrary, transcriptions.
 A concurrent line of work succeed only when both (1) synthesizing completely
 new audio and (2) targeting older, traditional speech recognition systems.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "ad-ex-speech-0"
literal "false"

\end_inset

 showed that any given source audio sample can be perturbed slightly so
 that an automatic speed recognition (ASR) system would transcribe the audio
 as any different target sentence.
 This paper developed effectively imperceptible audio adversarial examples
 by leveraging the psychoacoustic principle of auditory masking, while retaining
 100% targeted success rate on arbitrary full-sentence targets.
 The system is able to attack the state-of-the-art Lingvo
\begin_inset CommandInset citation
LatexCommand cite
key "lingvo"
literal "false"

\end_inset

 ASR system.
\end_layout

\begin_layout Standard
Advserserial examples on ASR differ from adversarial examples on images
 in two key ways.
 First, adversarial exmaples on images are imperceptible to humans.
 It is possible to generate an adversarial example without changing the
 8-bit brightness representation 
\begin_inset CommandInset citation
LatexCommand cite
key "ad-ex-image-0"
literal "false"

\end_inset

.
 Conversely adversarial examples on ASR systems are often perceptible.
 While the perturbation introduced is often small in magnitude, upon listening
 it is obvious that the added perturbation is present 
\begin_inset CommandInset citation
LatexCommand cite
key "ad-ex-speech-1"
literal "false"

\end_inset

.
 Second, adversarial examples on images work in the physical world 
\begin_inset CommandInset citation
LatexCommand cite
key "ad-ex-image-1"
literal "false"

\end_inset

.
 In contrast, adversarial examples on ASR systems do not yet work in such
 an 
\begin_inset Quotes eld
\end_inset

over-the-air
\begin_inset Quotes erd
\end_inset

 setting where they are played by a speaker and recorded by a microphone.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $x$
\end_inset

 be the input audio waveform, 
\begin_inset Formula $y$
\end_inset

 a target transcription, 
\begin_inset Formula $f(\cdot)$
\end_inset

 an automatic speech recognition system which outputs a final transcription.
 The objective is to construct an imperceptible and targeted adversarial
 example 
\begin_inset Formula $x'$
\end_inset

 that can attack the ASR system when played over-the-air.
 We seek to find a small perturbation 
\begin_inset Formula $\sigma$
\end_inset

, which enables 
\begin_inset Formula $x'=x+\sigma$
\end_inset

 to meet three requirements: (1) targeted, i.e.
 
\begin_inset Formula $f(x')=y$
\end_inset

 and 
\begin_inset Formula $f(x)\ne y$
\end_inset

 .
 (2) Imperceptible, i.e.
 the sound similar and human cannot differentiate them.
 (3) robust.
 
\begin_inset Formula $x'$
\end_inset

 is still effective when played over-the-air.
 This paper considers the white box thread model where the adversary has
 full access to the model as well as its parameters.
 In particular, the adversary is allowed to compute gradients through the
 model in order to generate adversarial examples.
\end_layout

\begin_layout Standard
Adversarial examples are typically generated by performing gradient descent
 w.r.t the input on a loss function designed to be minimized when the input
 is adversarial.
 Typical adversarial example generation algorithm solves 
\begin_inset Formula $\min\{l(f(x+\sigma),y)+\alpha||\sigma||\}$
\end_inset

, 
\begin_inset Formula $s.t.||\sigma||<\epsilon$
\end_inset

.
\end_layout

\begin_layout Standard
Minimizing the 
\begin_inset Formula $l_{p}$
\end_inset

 distortion between an image and the nearest misclassified example yields
 a visually indistinguishable image.
\end_layout

\begin_layout Standard
This work demonstrates how one might go about constructing adversarial examples
 for non-
\begin_inset Formula $l_{p}$
\end_inset

-based metrics.
 Especially on images, nearly all adversarial example research has focused
 on this highly-limited distance measure.
 Devoting effort to identifying different methods that humans use to assess
 similarity, and generating adversarial examples exploiting those metrics,
 is an important research effort we hope future work will explore.
\end_layout

\begin_layout Subsubsection
1905.04016: Exact Adversarial Attack to Image Captioningvia Structured Output
 Learning with Latent Variables
\end_layout

\begin_layout Standard
In this work, we study the robustness of a CNN+RNNbased image captioning
 system being subjected to adversar-ial noises.
 We propose to fool an image captioning systemto generate some targeted
 partial captions for an image pol-luted by adversarial noises, even the
 targeted captions aretotally irrelevant to the image content.
 A partial caption in-dicates that the words at some locations in this caption
 areobserved, while words at other locations are not restricted.It is the
 first work to study exact adversarial attacks of tar-geted partial captions.
 Due to the sequential dependenciesamong words in a caption, we formulate
 the generation of ad-versarial noises for targeted partial captions as
 a structuredoutput learning problem with latent variables.
 Both the gen-eralized expectation maximization algorithm and structuralSVMs
 with latent variables are then adopted to optimize theproblem.
\end_layout

\begin_layout Section
Story: Embedding, Ranking, Metric, Hashing, Retrieval
\end_layout

\begin_layout Subsection
Pure Image Retrieval
\end_layout

\begin_layout Subsubsection
Attention-Aware Polarity Sensitive Embedding for Affective Image Retrieval
\end_layout

\begin_layout Standard
ICCV19.
\end_layout

\begin_layout Standard
Images play a crucial role for people to express theiropinions online due
 to the increasing popularity of socialnetworks.
 While an affective image retrieval system is use-ful for obtaining visual
 contents with desired emotions froma massive repository, the abstract and
 subjective charac-teristics make the task challenging.
 To address the prob-lem, this paper introduces an Attention-aware Polarity
 Sen-sitive Embedding (APSE) network to learn affective repre-sentations
 in an end-to-end manner.
\end_layout

\begin_layout Subsection
Sketch-Based Image Retrieval (SBIR)
\end_layout

\begin_layout Subsubsection
Generalising Fine-Grained Sketch-Based Image Retrieval
\end_layout

\begin_layout Standard
Fine-grained sketch-based image retrieval (FG-SBIR) addresses matching specific
 photo instance using free-hand sketch as a query modality.
 Existing models aim to learn an embedding space in which sketch and photo
 can be di- rectly compared.
 While successful, they require instance- level pairing within each coarse-grain
ed category as anno- tated training data.
 Since the learned embedding space is domain-specific, these models do not
 generalise well across categories.
 This limits the practical applicability of FG- SBIR.
 
\end_layout

\begin_layout Subsection
Visual-Semantic Embedding (VSE) or Image-Text Retrieval
\end_layout

\begin_layout Subsubsection
Visual Semantic Reasoning for Image-Text Matchin
\end_layout

\begin_layout Standard
ICCV19, slightly better than SCAN
\end_layout

\begin_layout Standard
To address this issue, we propose a simple and in-terpretable reasoning
 model to generate visual representa-tion that captures key objects and
 semantic concepts of ascene.
 Specifically, we first build up connections betweenimage regions and perform
 reasoning with Graph Convo-lutional Networks to generate features with
 semantic re-lationships.
 Then, we propose to use the gate and mem-ory mechanism to perform global
 semantic reasoning onthese relationship-enhanced features, select the discrimi-
native information and gradually generate the representa-tion for the whole
 scene.
 
\end_layout

\begin_layout Subsubsection
CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval
\end_layout

\begin_layout Standard
ICCV19.
 SCAN is still regarded as the strongest baseline model.
\end_layout

\begin_layout Subsubsection
Towards Unsupervised Image Captioning with Shared Multimodal Embeddings
\end_layout

\begin_layout Standard
ICCV19, weak/unsupervised caption generation that rely on embedding learning.
 To some extent resembles Kiros's 
\begin_inset Quotes eld
\end_inset

unifying...
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Subsubsection
Position Focused Attention NetworkforImage-Text Matching
\end_layout

\begin_layout Standard
SOTA on ms-coco, better than SCAN.
 https://arxiv.org/pdf/1907.09748.pdf
\end_layout

\begin_layout Standard
In this paper, we propose anovelposition focused attention network (PFAN)to
 investigate the relationbetween the visual and the textual views.
 In this work, we integrate the object position clue to enhance the visual-text
 joint-embedding learning.We first split the images into blocks,by which
 we infer the relative position of region in the image.
 Then, an attention mechanism is proposed to model the relations between
 the image region and blocks and generate the valuable position feature,
 which will be further utilized to enhance theregion expression and model
 amore reliable relationship between the visual imageand the textual sentence.
 
\end_layout

\begin_layout Subsubsection
Joint Wasserstein Autoencoders for Aligning Multimodal Embeddings
\end_layout

\begin_layout Standard
SOTA ms-coco.
 https://arxiv.org/pdf/1909.06635.pdf
\end_layout

\begin_layout Standard
We propose to address this through joint Gaus-sian regularization of the
 latent representations.
 Buildingon Wasserstein autoencoders (WAEs) to encode the inputin each domain,
 we enforce the latent embeddings to besimilar to a Gaussian prior that
 is shared across the twodomains, ensuring compatible continuity of the
 encoded se-mantic representations of images and texts.
 Semantic align-ment is achieved through supervision from matching image-text
 pairs.
\end_layout

\begin_layout Subsubsection
Learning Semantic Concepts and Order for Image and Sentence Matching
\end_layout

\begin_layout Standard
Image and sentence matching has made great progress recently, but it remains
 challenging due to the large visual- semantic discrepancy.
 This mainly arises from that the rep- resentation of pixel-level image
 usually lacks of high-level semantic information as in its matched sentence.
\end_layout

\begin_layout Subsubsection
Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval
\end_layout

\begin_layout Standard
Visual-semantic embedding aims to find a shared latent space where related
 visual and textual instances are close to each other.
 Most current methods learn injective embed- ding functions that map an
 instance to a single point in the shared space.
 Unfortunately, injective embedding cannot effectively handle polysemous
 instances with multiple pos- sible meanings; at best, it would find an
 average representa- tion of different meanings.
 This hinders its use in real-world scenarios where individual instances
 and their cross-modal associations are often ambiguous
\end_layout

\begin_layout Subsubsection
VSE++: Improving Visual-Semantic Embeddings with Hard Negatives
\end_layout

\begin_layout Subsubsection
Deep Visual Semantic Alignments for Generating Image Descriptions
\end_layout

\begin_layout Standard
Our alignment model is based on a novel combination of Convolutional Neural
 Networks over image regions, bidirectional Recurrent Neural Networks over
 sentecnes, and a structured objective that alignes the two modalities through
 a multimodal embedding.
\end_layout

\begin_layout Standard
The proposed network model infers the latent alignment between segments
 of sentences and the region of the image that they describe.
 This model assiciates the two modalities through a common, multimodal embedding
 space and a structured objective.
\end_layout

\begin_layout Standard
The model of Karpathy et al.
 interprets the dot product 
\begin_inset Formula $v_{i}^{T}s_{t}$
\end_inset

 between the 
\begin_inset Formula $i$
\end_inset

-th word as a measure of similarity and use it to define the score between
 image 
\begin_inset Formula $k$
\end_inset

 and sentence 
\begin_inset Formula $l$
\end_inset

 as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S_{kl}=\sum_{t\in g_{l}}\sum_{i\in g_{k}}\max(0,v_{i}^{T}s_{t})
\]

\end_inset


\end_layout

\begin_layout Standard
Karpathy found that the following reformulation simplifies the model and
 alleviates the need for additional obejctives and their hyperparameters:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S_{kl}=\sum_{t\in g_{l}}\max_{i\in g_{k}}v_{i}^{T}s_{t}
\]

\end_inset


\end_layout

\begin_layout Standard
Assume that 
\begin_inset Formula $k=l$
\end_inset

 denotes a corresponding image and sentence pair, the final max-margin,
 structured loss remains:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(\theta)=\sum_{k}\Big\{\sum_{l}([S_{kl}-S_{kk}+1]_{+}+[S_{lk}-S_{kk}+1]_{+}\Big\}
\]

\end_inset


\end_layout

\begin_layout Standard
Ref: Deep fragment em-beddings for bidirectional image sentence mapping.
\end_layout

\begin_layout Standard
RCNN for top 19 detected regions and the whole image.
 Each image is thus represented as a set of 
\begin_inset Formula $h$
\end_inset

-dimensional vectors 
\begin_inset Formula $\{v_{i}|i=1\ldots20\}$
\end_inset

 .
\end_layout

\begin_layout Standard
The final 
\begin_inset Formula $h$
\end_inset

-dimensional representation 
\begin_inset Formula $s_{t}$
\end_inset

 for the 
\begin_inset Formula $t$
\end_inset

-th word is a function of both the word at that location and also its surroundin
g context in the sentence.
 Technically, every 
\begin_inset Formula $s_{t}$
\end_inset

 is a function of all words in the entire sentecne, but our empirical finding
 is that the final word representations (
\begin_inset Formula $s_{t}$
\end_inset

) align most strongly to the visual concept of the word at that location.
\end_layout

\begin_layout Subsubsection

\color red
Stacked Cross Attention for Image-Text Matching (SCAN, ECCV18)
\end_layout

\begin_layout Standard
https://github.com/kuanghuei/SCAN
\end_layout

\begin_layout Standard
Prior work either simply aggregates the similarity of all possible pairs
 of regions and words without attending differentially to more and less
 important words or regions, or uses a multi-step attentional process to
 capture limited number of semantic alignments which is less interpretable.
\end_layout

\begin_layout Standard
Primary contribution is the novel Stacked Cross Atten- tion mechanism for
 discovering the full latent visual-semantic alignments.
\end_layout

\begin_layout Standard
SCAN accetps a pair of image features and word features as input, and yields
 similarity score.
 Let 
\begin_inset Formula $v=\{v_{1},\ldots,v_{k}\},v_{i}\in R^{D}$
\end_inset

 denote region feature vectors from an image 
\begin_inset Formula $I$
\end_inset

 , 
\begin_inset Formula $E=\{e_{1},\ldots,e_{n}\},e_{i}\in R^{D}$
\end_inset

 denote word features from a sentence 
\begin_inset Formula $T$
\end_inset

 .
\end_layout

\begin_layout Standard
(1) cosine similartiy matrix 
\begin_inset Formula $s_{ij}=cossim(v_{i},e_{j}),i\in[1,k],j\in[1,n]$
\end_inset

 .
 Empirically found normalizing the matrix beneficial 
\begin_inset Formula $\bar{s}_{ij}=[s_{ij}]_{+}/\sqrt{\sum_{i}^{k}[s_{ij}]_{+}^{2}}$
\end_inset

 .
\end_layout

\begin_layout Standard
(2) attend sentence representation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
a_{i}^{t}=\sum_{j=1}^{n}\alpha_{ij}e_{j},\alpha_{ij}=\text{softmax}_{j}(\lambda_{1}\bar{s}_{ij})
\]

\end_inset


\end_layout

\begin_layout Standard
(3) similarity between attended sentecne vector 
\begin_inset Formula $a_{i}^{t}$
\end_inset

 and region feature 
\begin_inset Formula $v_{i}$
\end_inset

 is defined as their cosine similarity 
\begin_inset Formula $R(v_{i},a_{i}^{t})=cossim(v_{i},a_{i}^{t})$
\end_inset

 .
\end_layout

\begin_layout Standard
(4) similarity between 
\begin_inset Formula $I$
\end_inset

 and 
\begin_inset Formula $T$
\end_inset

 can be summarized with average pooling, i.e.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S_{AVG}(I,T)=\frac{1}{k}\sum_{i=1}^{k}R(v_{i},a_{i}^{t})
\]

\end_inset


\end_layout

\begin_layout Standard
or alternatively LSE (LogSumExp) pooling.
\end_layout

\begin_layout Standard
(5) alignment criteria leverages hard negatives
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
l(I,T)=\max_{\hat{T}}[\alpha-S(I,T)+S(I,\hat{T})]_{+}+\max_{\hat{I}}[\alpha-S(I,T)+S(\hat{I},T)]_{+}
\]

\end_inset


\end_layout

\begin_layout Standard
(6) region features: Faster-RCNN
\begin_inset Formula $v_{i}=Wf_{i}+b$
\end_inset

 where 
\begin_inset Formula $f_{i}$
\end_inset

 is mean-pooled regional feature vector.
 word features: biGRU, 
\begin_inset Formula $e_{i}=\frac{1}{2}(\overrightarrow{h}_{i}+\overleftarrow{h}_{i})$
\end_inset

 .
\end_layout

\begin_layout Subsubsection
Person Search with Natural Language Description (aka.
 GNA-RNN, CVPR17)
\end_layout

\begin_layout Standard
Searching person in image dataseses with the query of natural language descripti
on has important applications.
 Existing methods mainly focused on searching persons with image-based or
 atrribute-based queries, which have major limitations for a practical usage.
 The algorithm of person search is required to rank all the samples in the
 person database then retrieve the most relevant sample corresponding to
 the query description.
\end_layout

\begin_layout Standard
Person search with image-based queries is known as person re-identification
 in computer vision.
\end_layout

\begin_layout Standard
At each step, the LSTM takes 
\begin_inset Formula $x_{t}=[x_{t}^{w},x^{v}]^{T}$
\end_inset

 as input, which is concatenation of the 
\begin_inset Formula $t$
\end_inset

-th word embedding 
\begin_inset Formula $x_{t}^{w}$
\end_inset

 and image features 
\begin_inset Formula $x^{v}$
\end_inset

.
 For generating the unit-level attentions at each word, the output hidden
 state 
\begin_inset Formula $h_{t}$
\end_inset

 is fed into a fully-connected layer with ReLU non-linearity function and
 a fully connected layer with softmax function to obtain the attention vector
 
\begin_inset Formula $A_{t}\in\mathcal{R}^{512}$
\end_inset

 , which has the same dimension as the visual units 
\begin_inset Formula $v$
\end_inset

.
 The affinity between the sentence and the person image at 
\begin_inset Formula $t$
\end_inset

-th word can then be obtained by
\begin_inset Formula 
\[
a_{t}=\sum_{n=1}^{512}A_{t}(n)v_{n}\text{ s.t. }\sum_{n=1}^{512}A_{t}(n)=1
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $A_{t}(n)$
\end_inset

 denotes the attention value for the 
\begin_inset Formula $n$
\end_inset

-th visual unit.
\end_layout

\begin_layout Subsubsection
2019-CVPR: Deep Metric Learning Beyond Binary Supervision
\end_layout

\begin_layout Standard
Metric Learning for visual similarity has mostly adopted binary supervision
 indicating whether a pair of images are of the same class or not.
 Such a binary indicator covers only a limited subset of image relations,
 and is not sufficient to represent semantic similarity between images described
 by continuous and/or structured labels such as object poses, image captions,
 and scene graphs.
 Motivated by this, we present a novel method for deep metric learning using
 con- tinuous labels.
 First, we propose a new triplet loss that al- lows distance ratios in the
 label space to be preserved in the learned metric space.
 The proposed loss thus enables our model to learn the degree of similarity
 rather than just the order.
 Furthermore, we design a triplet mining strategy adapted to metric learning
 with continuous labels.
 We ad- dress three different image retrieval tasks with continuous labels
 in terms of human poses, room layouts and image captions, and demonstrate
 the superior performance of our approach compared to previous methods.
\end_layout

\begin_layout Standard
Two contributions: (1) the log-ratio triplet loss function; (2) the dense
 triplet mining strategy.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
l_{\text{lr}}(a,i,j)=\Big\{\log\frac{D(f_{a},f_{i})}{D(f_{a},f_{j})}-\log\frac{D(y_{a},y_{i})}{D(y_{a},y_{j})}\Big\}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
First of all, we construct a minibatch B of training sam- ples with an anchor,
 k nearest neighbors of the anchor in terms of label distance, and other
 neighbors randomly sam- pled from the remaining ones.
 Note that including near- est neighbors helps speed up training.
 Given a minibatch, we aim to exploit all triplets sharing the anchor so
 that our embedding network can observe the greatest variety of triplets
 during training.
\end_layout

\begin_layout Subsubsection
2019-CVPR: Hardness-Aware Deep Metric Learning
\end_layout

\begin_layout Standard
This paper presents a hardness-aware deep metric learn- ing (HDML) framework.
 Most previous deep metric learn- ing methods employ the hard negative mining
 strategy to alleviate the lack of informative samples for training.
 How- ever, this mining strategy only utilizes a subset of training data,
 which may not be enough to characterize the global geometry of the embedding
 space comprehensively.
 To ad- dress this problem, we perform linear interpolation on em- beddings
 to adaptively manipulate their hard levels and generate corresponding label-pre
serving synthetics for re- cycled training, so that information buried in
 all samples can be fully exploited and the metric is always challenged
 with proper difficulty.
\end_layout

\begin_layout Standard
Regularization with off-manifold data samples (or say adversarial examples)?
\end_layout

\begin_layout Subsection
Metric Learning and Deep Ranking
\end_layout

\begin_layout Subsubsection
Learning with Average Precision: TrainingImage Retrieval with a Listwise
 Loss
\end_layout

\begin_layout Standard
ICCV19.
 Listwise loss.
 The idea somehow resembles ladder loss.
\end_layout

\begin_layout Subsubsection
SoftTriple Loss: Deep Metric Learning Without Triplet Sampling
\end_layout

\begin_layout Standard
ICCV19, On the contrary, optimizing SoftMax loss, which is a clas-sification
 loss, with DNN shows a superior performance incertain DML tasks.
 
\end_layout

\begin_layout Standard
Our analysis shows that SoftMax loss isequivalent to a smoothed triplet
 loss where each class hasa single center.
 In real-world data, one class can containseveral local clusters rather
 than a single one, e.g., birdsof different poses.
 Therefore, we propose the SoftTriple lossto extend the SoftMax loss with
 multiple centers for eachclass.
 Compared with conventional deep metric learningalgorithms, optimizing SoftTripl
e loss can learn the embed-dings without the sampling phase by mildly increasing
 thesize of the last fully connected layer.
 
\end_layout

\begin_layout Subsubsection
Deep Metric Learning with Hierarchical Triplet Loss
\end_layout

\begin_layout Standard
1810.06951
\end_layout

\begin_layout Standard
We present a novel hierarchical triplet loss (HTL) capableof automatically
 collecting informative training samples (triplets) via adefined hierarchical
 tree that encodes global context information.
 Thisallows us to cope with the main limitation of random sampling in train-ing
 a conventional triplet loss, which is a central issue for deep metriclearning.
 
\end_layout

\begin_layout Subsubsection
Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings
\end_layout

\begin_layout Standard
ICCV19.
 SOP is used.
\end_layout

\begin_layout Standard
In this paper, we tackle thisscattering problem with a distribution-aware
 regularizationnamed HORDE1.
\end_layout

\begin_layout Standard
Although the metric learning part is well addressed,this metric is usually
 computed over the average of the ex-tracted deep features.
 This representation is then trained tobe discriminative.
 However, these deep features tend to bescattered across the feature space.
 Consequently, the rep-resentations are not robust to outliers, object occlusion
s,background variations, etc.
\end_layout

\begin_layout Subsubsection
Relational Knowledge Distillation
\end_layout

\begin_layout Standard
Tag: Distillation + Metric
\end_layout

\begin_layout Standard
Knowledge distillation aims at transferring knowledge acquired in one model
 (a teacher) to another model (a stu- dent) that is typically smaller.
 Previous approaches can be expressed as a form of training the student
 to mimic output activations of individual data examples represented by
 the teacher.
\end_layout

\begin_layout Standard
In particular for metric learning, it allows students to outperform their
 teachers’ performance, achiev- ing the state of the arts on standard benchmark
 datasets.
\end_layout

\begin_layout Subsubsection

\color red
Deep Metric Learning Beyond Binary Supervision (CVPR19)
\end_layout

\begin_layout Standard
Metric Learning for visual similarity has mostly adopted binary supervision
 indicating whether a pair of images are of the same class or not.
 Such a binary indicator covers only a limited subset of image relations,
 and is not sufficient to represent semantic similarity between images described
 by continuous and/or structured labels such as object poses, image captions,
 and scene graphs.
\end_layout

\begin_layout Subsubsection
Deep Metric Learning to Rank
\end_layout

\begin_layout Standard
We propose a novel deep metric learning method by re- visiting the learning
 to rank approach.
 Our method, named FastAP, optimizes the rank-based Average Precision mea-
 sure, using an approximation derived from distance quan- tization.
\end_layout

\begin_layout Standard
novel deep metric learning method that optimizes average precision over
 ranked lists of examples.
 This solution avoids a high-order explosion of the training set.
\end_layout

\begin_layout Subsubsection
Divide and Conquer the Embedding Space for Metric Learning
\end_layout

\begin_layout Standard
Learning the embedding space, where semantically sim- ilar objects are located
 close together and dissimilar ob- jects far apart, is a cornerstone of
 many computer vision applications.
 Existing approaches usually learn a single metric in the embedding space
 for all available data points, which may have a very complex non-uniform
 distribution with different notions of similarity between objects, e.g.
 ap- pearance, shape, color or semantic meaning.
 Approaches for learning a single distance metric often struggle to en-
 code all different types of relationships and do not generalize well.
 
\end_layout

\begin_layout Subsection
Embedding
\end_layout

\begin_layout Subsubsection
Learning Metrics from Teachers: Compact Networks for Image Embedding
\end_layout

\begin_layout Standard
Tag: Embedding + Distillation
\end_layout

\begin_layout Standard
Metric learning networks are used to compute image em- beddings, which are
 widely used in many applications such as image retrieval and face recognition.
 In this paper, we propose to use network distillation to efficiently compute
 image embeddings with small networks.
 Network distilla- tion has been successfully applied to improve image classi-
 fication, but has hardly been explored for metric learning.
\end_layout

\begin_layout Subsubsection
On Learning Density Aware Embeddings
\end_layout

\begin_layout Standard
Deep metric learning algorithms have been utilized to learn discriminative
 and generalizable models which are effective for classifying unseen classes.
 In this paper, a novel noise tolerant deep metric learning algorithm is
 pro- posed.
 
\end_layout

\begin_layout Subsection
Hashing
\end_layout

\begin_layout Subsubsection
DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs
\end_layout

\begin_layout Standard
Due to the high storage and search efficiency, hashing has become prevalent
 for large-scale similarity search.
 Par- ticularly, deep hashing methods have greatly improved the search performan
ce under supervised scenarios.
 In con- trast, unsupervised deep hashing models can hardly achieve satisfactory
 performance due to the lack of reliable super- visory similarity signals.
 
\end_layout

\begin_layout Subsubsection
K-Nearest Neighbors Hashing
\end_layout

\begin_layout Standard
Hashing based approximate nearest neighbor search em- beds high dimensional
 data to compact binary codes, which enables efficient similarity search
 and storage.
 However, the non-isometry sign ( · ) function makes it hard to project
 the nearest neighbors in continuous data space into the closest codewords
 in discrete Hamming space.
 
\end_layout

\begin_layout Subsection
Representation
\end_layout

\begin_layout Subsubsection
On the Intrinsic Dimensionality of Image Representations
\end_layout

\begin_layout Standard
This paper addresses the following questions pertaining to the intrinsic
 dimensionality of any given image represen- tation: (i) estimate its intrinsic
 dimensionality, (ii) develop a deep neural network based non-linear mapping,
 dubbed DeepMDS, that transforms the ambient representation to the minimal
 intrinsic space, and (iii) validate the verac- ity of the mapping through
 image matching in the intrinsic space.
 
\end_layout

\begin_layout Subsection
Learning To Rank
\end_layout

\begin_layout Subsubsection
Gaussian Processes for Ordinal Regression
\end_layout

\begin_layout Standard
JMLR2005
\end_layout

\begin_layout Standard
We present a probabilistic kernel approach to ordinal regression based on
 Gaussian processes.
 Athreshold model that generalizes theprobitfunction is used as the likelihood
 function for ordinalvariables.
 Two inference techniques, based on the Laplace approximation and the expectatio
n prop-agation algorithm respectively, are derived for hyperparameter learning
 and model selection.
 Wecompare these two Gaussian process approaches with a previous ordinal
 regression method basedon support vector machines on some benchmark and
 real-worlddata sets, including applications ofordinal regression to collaborati
ve filtering and gene expression analysis.
 Experimental results onthese data sets verify the usefulness of our approach.
\end_layout

\begin_layout Subsubsection
Soft Labels for Ordinal Regression
\end_layout

\begin_layout Standard
Ordinal regression attempts to solve classification prob- lems in which
 categories are not independent, but rather follow a natural order.
 It is crucial to classify each class correctly while learning adequate
 interclass ordinal rela- tionships.
 We present a simple and effective method that constrains these relationships
 among categories by seam- lessly incorporating metric penalties into ground
 truth la- bel representations.
\end_layout

\begin_layout Section
Story: Model Compression & Quantization
\end_layout

\begin_layout Standard
Reducing precision of operations and operands, or reducing the number of
 operations and model size.
 Quantization, Pruning, Entropy Encoding, Distillation, Matrix Factorization/Tra
nsformation.
\end_layout

\begin_layout Subsubsection
Do Deep Nets Really Need to be Deep? (1312.6184)
\end_layout

\begin_layout Standard
We empirically demonstrate thatshallow feed-forward nets can learn the complex
 functions previously learned bydeep nets and achieve accuracies previously
 only achievable with deep models.
\end_layout

\begin_layout Subsection
Quantization
\end_layout

\begin_layout Subsubsection
Fully Quantized Network for Object Detection
\end_layout

\begin_layout Standard
OK
\end_layout

\begin_layout Section
Story: Image Classification & Networks
\end_layout

\begin_layout Subsection
Neural Architecture Search (NAS)
\end_layout

\begin_layout Subsubsection
Co-Occurrence Neural Network
\end_layout

\begin_layout Standard
Convolutional Neural Networks (CNNs) became a very popular tool for image
 analysis.
 Convolutions are fast to compute and easy to store, but they also have
 some limita- tions.
 First, they are shift-invariant and, as a result, they do not adapt to
 different regions of the image.
 Second, they have a fixed spatial layout, so small geometric deformations
 in the layout of a patch will completely change the filter re- sponse.
 For these reasons, we need multiple filters to handle the different parts
 and variations in the input.
\end_layout

\begin_layout Subsubsection
Adaptively Connected Neural Networks
\end_layout

\begin_layout Standard
This paper presents a novel adaptively connected neural network (ACNet)
 to improve the traditional convolutional neural networks (CNNs) in two
 aspects
\end_layout

\begin_layout Subsubsection
Selective Kernel Networks
\end_layout

\begin_layout Standard
In standard Convolutional Neural Networks (CNNs), the receptive fields of
 artificial neurons in each layer are de- signed to share the same size.
 It is well-known in the neu- roscience community that the receptive field
 size of visual cortical neurons are modulated by the stimulus, which has
 been rarely considered in constructing CNNs.
 
\end_layout

\begin_layout Subsubsection

\color green
1905.11946: EfficientNet: Rethinking Model Scaling for Convolutional Neural
 Networks
\end_layout

\begin_layout Standard
In this paper, we sys-tematically study model scaling and identify thatcarefully
 balancing network depth, width, and res-olution can lead to better performance.
 Basedon this observation, we propose a new scalingmethod that uniformly
 scales all dimensions ofdepth/width/resolution using a simple yet highlyeffecti
vecompound coefficient.
\end_layout

\begin_layout Standard
EfficientNet-B0 is searched by Automatic Machine Learning (Grid Search).
 EfficientNet-B1..7 are scaled from the B0 model with the method proposed
 by this paper.
\end_layout

\begin_layout Subsubsection
Rethinking the Inception Architecture for Computer Vision (Inception-v3)
\end_layout

\begin_layout Subsubsection
2019-CVPR: Searching for A Robust Neural Architecture in Four GPU Hours
\end_layout

\begin_layout Standard
Conventional neural architecture search (NAS) ap- proaches are based on
 reinforcement learning or evolution- ary strategy, which take more than
 3000 GPU hours to find a good model on CIFAR-10.
 We propose an efficient NAS approach learning to search by gradient descent.
 Our ap- proach represents the search space as a directed acyclic graph
 (DAG).
 This DAG contains billions of sub-graphs, each of which indicates a kind
 of neural architecture.
\end_layout

\begin_layout Subsection
Tricks: Initialization, etc.
\end_layout

\begin_layout Subsubsection
A Comprehensive Overhaul of Feature Distillation
\end_layout

\begin_layout Standard
ICCV19
\end_layout

\begin_layout Standard
We investigate the design aspects of feature distilla-tion methods achieving
 network compression and proposea novel feature distillation method in which
 the distilla-tion loss is designed to make a synergy among various as-pects:
 teacher transform, student transform, distillation fea-ture position and
 distance function.
\end_layout

\begin_layout Subsubsection
Be Your Own Teacher: Improve the Performance of Convolutional NeuralNetworks
 via Self Distillation
\end_layout

\begin_layout Standard
In this paper, we propose a general training frame-work named self distillation,
 which notably enhances theperformance (accuracy) of convolutional neural
 networksthrough shrinking the size of the network rather than ag-grandizing
 it.
 Different from traditional knowledge distil-lation - a knowledge transformation
 methodology amongnetworks, which forces student neural networks to approxi-mate
 the softmax layer outputs of pre-trained teacher neuralnetworks, the proposed
 self distillation framework distillsknowledge within network itself.
 
\end_layout

\begin_layout Subsubsection
Bag of Tricks for Image Classification with Convolutional Neural Networks
\end_layout

\begin_layout Standard
Much of the recent progress made in image classification research can be
 credited to training procedure refinements, such as changes in data augmentatio
ns and optimization methods.
 In the literature, however, most refinements are ei- ther briefly mentioned
 as implementation details or only vis- ible in source code.
 In this paper, we will examine a collec- tion of such refinements and empirical
ly evaluate their im- pact on the final model accuracy through ablation
 study.
 
\end_layout

\begin_layout Subsubsection
Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet
 Classification
\end_layout

\begin_layout Itemize
PReLU
\end_layout

\begin_layout Itemize
Kaiming Initialization
\end_layout

\begin_layout Standard
Rectifier networks are easier to train compared with traditional sigmoid-like
 activation networks.
 But a bad initialization can still hamper the learning of a highly non-linear
 system.
 A robust initialization method that removes an obstacle of training extremely
 deep rectifier networks is proposed in this paper.
\end_layout

\begin_layout Standard
Recent deep CNNs are mostly initialized by random weights drawn from Gaussian
 distributions.
 With fixed standard deviations, very deep models have difficulties to converge,
 as reported by the VGG team and also observed in our experiments.
\end_layout

\begin_layout Standard
Glorot and Bengio proposed to adopt a properly scaled uniform distribution
 for initialization.
 This is called 
\begin_inset Quotes eld
\end_inset

Xavier
\begin_inset Quotes erd
\end_inset

 initialization.
 Its derivation is based on the assumption that the activations are linear.
 This assumption is invalid for ReLU and PReLU.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y_{l}=W_{l}x_{l}+b_{l},x_{l}=f(y_{l-1})
\]

\end_inset


\end_layout

\begin_layout Standard
x.size(
\begin_inset Formula $k^{2}c,1$
\end_inset

) 
\begin_inset Formula $k\times k\times channels$
\end_inset

 , 
\begin_inset Formula $n=k^{2}c$
\end_inset

 is the number of connections.
 W.size(
\begin_inset Formula $d,n$
\end_inset

), d is the number of convolution filters.
 b is bias.
 let 
\begin_inset Formula $mean(w_{l})=0$
\end_inset

 , note that 
\begin_inset Formula $E[x_{l}^{2}]\ne Var[x_{l}]=E[x_{l}^{2}]-(E[x_{l}])^{2}$
\end_inset

 .
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var[y_{l}]=Var[\sum w_{i}x_{i}+b_{l}]=Var[\sum w_{i}x_{i}]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var(X+Y)=Var(X)+Var(Y)+Cov(X,Y)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Cov(X,Y)=E(XY)-E(X)E(Y)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var[w_{1}x_{1}+\sum w_{i}x_{i}]=Var(w_{1}x_{1})+Var(w_{2}x_{2})+\ldots=n_{l}Var(w_{l}x_{l})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Rightarrow Var[y_{l}]=n_{l}Var[w_{l}x_{l}]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var(XY)=[E(X)]^{2}Var(Y)+[E(Y)]^{2}Var(X)+Var(X)Var(Y)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E[X^{2}]=Var(X)+[E(X)]^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var[y_{l}]=n_{l}Var[w_{l}]E[x_{l}^{2}]
\]

\end_inset


\end_layout

\begin_layout Standard
For ReLU
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E[x_{l}^{2}]=\frac{1}{2}Var[y_{l-1}]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var[y_{l}]=\frac{1}{2}n_{l}Var[w_{l}]Var[y_{l-1}]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Var[y_{L}]=Var[y_{1}]\Big(\prod_{l=2}^{L}\frac{1}{2}n_{l}Var[w_{l}]\Big)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{2}n_{l}Var[w_{l}]=1\rightarrow\sigma(0,\sqrt{\frac{2}{n_{l}}})
\]

\end_inset


\end_layout

\begin_layout Subsection
Class Balance and Uncertainty
\end_layout

\begin_layout Subsubsection
Striking the Right Balance with Uncertainty
\end_layout

\begin_layout Standard
Learning unbiased models on imbalanced datasets is a significant challenge.
 Rare classes tend to get a concen- trated representation in the classification
 space which ham- pers the generalization of learned boundaries to new test
 examples.
\end_layout

\begin_layout Subsubsection
Learning Loss for Active Learning
\end_layout

\begin_layout Standard
The performance of deep neural networks improves with more annotated data.
 The problem is that the budget for annotation is limited.
 One solution to this is active learn- ing, where a model asks human to
 annotate data that it perceived as uncertain.
\end_layout

\begin_layout Subsubsection
Why ReLU networks yield high-confidence predictions far away from the training
 data and how to mitigate the problem
\end_layout

\begin_layout Standard
TAG: Adversarial example
\end_layout

\begin_layout Standard
Classifiers used in the wild, in particular for safety- critical systems,
 should not only have good generaliza- tion properties but also should know
 when they don’t know, in particular make low confidence predictions far
 away from the training data.
 
\end_layout

\begin_layout Section
Story: Semantic & Instance Segmentation 
\end_layout

\begin_layout Standard
Semantic segmentation – per-pixel classification.
 FCN.
 CRF is used to refine the segmentation result.
 Encoder-Decoder structured models include UNet, DeconvNet, SegNet, LRR,
 RefineNet, FRRN.
 Atrous (dilated) convolution, a new operation had been introduced to increase
 the receptive field (DeepLapV1, DillationNet).
 Neural Architecture Search.
 Attention mechanism.
 Hard negative mining.
\end_layout

\begin_layout Standard
Semantic segmentation – challenges: speed, per-pixel accuracy, boundary.
 Segmentation requires the model to maintain both receptive field (context)
 and spatial resolution.
 Context in backbone – BiSeNet (ECCV18).
 Large Kernel Matters (CVPR17) – context v.s.
 larger receptive field?.
 PSANet.
 OCNet.
 ParseNet.
\end_layout

\begin_layout Subsubsection
Object Region Mining with Adversarial Erasing: A Simple Classification to
 Semantic Segmentation Approach
\end_layout

\begin_layout Standard
This paper investigates a way to progressively mine discriminative object
 regions using classification networks to address the weakly-superfised
 semantic segmentation problem.
\end_layout

\begin_layout Standard
Classification networks are only responsive to small and sparse discriminative
 regions from the object of interest, which deviates from the requirement
 of the segmentation task that needs to localize dense, interior and integral
 regions from pixel-wise inference.
 To mitigate this gap, this paper proposes a new adversarial erasing approach
 for localizing and expanding object regions progressively.
 Starting with a single small object region, this proposed approach drives
 the classification network to sequentially discover new and complement
 object regions by erasing the current mined regions in an adversarial manner.
 These localized regions eventually constitute a dense and complete object
 region for learning semantic segmentation.
\end_layout

\begin_layout Subsection
Semantic Segmentation
\end_layout

\begin_layout Subsubsection
Structured Knowledge Distillation for Semantic Segmentation
\end_layout

\begin_layout Standard
In this paper, we investigate the knowledge distillation strategy for training
 small semantic segmentation networks by making use of large networks.
 
\end_layout

\begin_layout Subsection
Instance Segmentation
\end_layout

\begin_layout Subsubsection
Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations
\end_layout

\begin_layout Standard
This paper presents a novel approach for learning in- stance segmentation
 with image-level class labels as super- vision.
 Our approach generates pseudo instance segmenta- tion labels of training
 images, which are used to train a fully supervised model.
 
\end_layout

\begin_layout Section
Story: Object Detection
\end_layout

\begin_layout Subsubsection
A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection
\end_layout

\begin_layout Standard
How do we learn an object detector that is invariant to occlusions and deforemat
ions? Our current solution is to use a data-driven strategy – collect large-scal
e datasets which have object instances under different conditions.
 This paper argues that, like categories, occlusions and object deformations
 also follow a long-tail distribution.
 In this paper, an alternative solution is proposed, where an adversarial
 network that generates examples with occlusions and deformations is learned.
 The goal of the adversary is to generate exampoles that are difficult for
 the object detector to classify.
\end_layout

\begin_layout Standard
While collecting even larger datasets is one possible solution, it is not
 likely to scale due to the long-tail statistics.
\end_layout

\begin_layout Subsubsection
1508.02844: What is Holding Back Convnets for Detection?
\end_layout

\begin_layout Standard
In this paper wewant to better understand these choices by inspecting two
 key aspects“what did the network learn?”, and “what can the network learn?”.
 Weexploit new annotations (Pascal3D+), to enable a new empirical analysisof
 the R-CNN detector.
\end_layout

\begin_layout Subsection
Bounding Box Regression
\end_layout

\begin_layout Subsubsection
Generalized Intersection over Union: A Metric and A Loss for Bounding Box
 Regression
\end_layout

\begin_layout Standard
Intersection over Union (IoU) is the most popular evalu- ation metric used
 in the object detection benchmarks.
 How- ever, there is a gap between optimizing the commonly used distance
 losses for regressing the parameters of a bounding box and maximizing this
 metric value.
 The optimal objec- tive for a metric is the metric itself.
 In the case of axis- aligned 2D bounding boxes, it can be shown that IoU
 can be directly used as a regression loss.
 However, IoU has a plateau making it infeasible to optimize in the case
 of non- overlapping bounding boxes.
\end_layout

\begin_layout Subsection
Saliency Detection
\end_layout

\begin_layout Subsubsection
Pyramid Feature Attention Network for Saliency detection
\end_layout

\begin_layout Standard
Saliency detection is one of the basic challenges in com- puter vision.
 Recently, CNNs are the most widely used and powerful techniques for saliency
 detection, in which fea- ture maps from different layers are always integrated
 with- out distinction.
 However, instinctively, the different feature maps of CNNs and the different
 features in the same maps should play different roles in saliency detection.
 To address this problem, a novel CNN named pyramid feature attention network
 (PFAN) is proposed to enhance the high-level con- text features and the
 low-level spatial structural features.
\end_layout

\begin_layout Subsection
AutoPilot
\end_layout

\begin_layout Subsubsection
Learning Lightweight Lane Detection CNNs by Self Attention Distillatio.
\end_layout

\begin_layout Standard
In this paper, we present a novel knowl- edge distillation approach, i.e.,
 Self Attention Distillation (SAD), which allows a model to learn from itself
 and gains substantial improvement without any additional supervision or
 labels.
 
\end_layout

\begin_layout Section
Story: Transfer Learning & Domain Adaptation
\end_layout

\begin_layout Subsection
Transfer Learning
\end_layout

\begin_layout Subsubsection
Do Better ImageNet Models Transfer Better?
\end_layout

\begin_layout Standard
Transfer learning is a cornerstone of computer vision, yet little work has
 been done to evaluate the relationship between architecture and transfer.
 An implicit hypothesis in modern computer vision research is that models
 that per- form better on ImageNet necessarily perform better on other vision
 tasks.
 However, this hypothesis has never been sys- tematically tested.
 
\end_layout

\begin_layout Standard
Together, our results show that ImageNet architectures generalize well across
 datasets, but ImageNet features are less general than previously suggested
\end_layout

\begin_layout Section
Story: Actions
\end_layout

\begin_layout Subsection
Activity Localization
\end_layout

\begin_layout Subsubsection
Language-driven Temporal Activity Localization: A Semantic Matching Reinforcemen
t Learning Model
\end_layout

\begin_layout Standard
Current studies on action detection in untrimmed videos are mostly designed
 for action classes, where an action is described at word level such as
 jumping, tumbling, swing, etc.
 This paper focuses on a rarely investigated problem of localizing an activity
 via a sentence query which would be more challenging and practical
\end_layout

\begin_layout Subsection
Path Forecasting
\end_layout

\begin_layout Subsubsection
Which Way Are You Going? Imitative Decision Learning for Path Forecasting
 in Dynamic Scenes
\end_layout

\begin_layout Standard
Path forecasting is a pivotal step toward understanding dynamic scenes,
 and it is an emerging topic in the computer vision field.
 This task is challenging due to the multimodal nature of the future, namely,
 there is more than one plausi- ble prediction given histories.
 Yet, the state-of-the-art meth- ods do not seem to be adequately responsive
 to this innate variability.
 
\end_layout

\begin_layout Section
Story: Face & Person
\end_layout

\begin_layout Subsection
Age Estimation
\end_layout

\begin_layout Subsubsection
2019-CVPR: BridgeNet: A Continuity-Aware Probabilistic Network for Age Estimatio
n
\end_layout

\begin_layout Standard
Existing methods for age esti- mation usually apply a divide-and-conquer
 strategy to deal with heterogeneous data caused by the non-stationary ag-
 ing process.
 However, the facial aging process is also a continuous process, and the
 continuity relationship between different components has not been effectively
 exploited.
 In this paper, we propose BridgeNet for age estimation, which aims to mine
 the continuous relation between age labels ef- fectively.
\end_layout

\begin_layout Subsection
Person Search
\end_layout

\begin_layout Subsubsection
Query-guided End-to-End Person Search
\end_layout

\begin_layout Standard
We believe that i.
 person detection and re-identification should be pursued in a joint optimiza-
 tion framework and that ii.
 the person search should lever- age the query image extensively (e.g.
 emphasizing unique query patterns).
 However, so far, no prior art realizes this.
\end_layout

\begin_layout Subsection
Gait
\end_layout

\begin_layout Subsubsection
Learning Joint Gait Representation via Quintuplet Loss Minimization
\end_layout

\begin_layout Standard
Gait recognition is an important biometric technique rel- evant to video
 surveillance, where the task is to identify peo- ple at a distance by their
 walking patterns captured in the video.
 
\end_layout

\begin_layout Section
Story: Seq2Seq & Attention
\end_layout

\begin_layout Subsection
Linguistic Sequence Modeling
\end_layout

\begin_layout Standard
The first work of Sequence to Sequence Models 
\begin_inset CommandInset citation
LatexCommand cite
key "key-1"
literal "false"

\end_inset

 looks at how to map one sequence to another sequence.
 A deep LSTM is used to map the sequence into a high dimensional representation.
 By connecting two, you get a machine translation system, and it works well
\begin_inset CommandInset citation
LatexCommand cite
key "key-2,key-3"
literal "false"

\end_inset

.
 You can also get a chatbot or parser in a similar way
\begin_inset CommandInset citation
LatexCommand cite
key "key-4"
literal "false"

\end_inset

, or something that can learn graph algorithms
\begin_inset CommandInset citation
LatexCommand cite
key "key-5"
literal "false"

\end_inset

.
 Connect sequence and image models, you get a captioning system
\begin_inset CommandInset citation
LatexCommand cite
key "key-6"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Attention Is All You Need (aka.
 Transformer)
\end_layout

\begin_layout Standard
The dominant sequence transduction models are based on complex recurrent
 or convolutional neural networks that include an encoder and a decoder.
 The best performing models also connect the encoder and decoder through
 an attention mechanism.
 This paper proposes a new simple network architecture, the Transformer,
 based solely on attention mechanisms, dispensing with recurrence and convolutio
ns entirely.
 Experiments on two machine translation tasks show these models to be superior
 in quality while being more parallelizable and requiring significantly
 less time to train.
\end_layout

\begin_layout Standard
In these models, the number of operations required to relate signals from
 two arbitrary input or putput positions grows in the distance between positions
, linearly for ConvS2S and logarithmically for ByteNet.
 This makes it more difficult to learn dependencies between distant positions.
 In the Transformer this is reduced to a constant number of operations,
 albeit at the cost of reduced effective resolution due to averaging attention-w
eighted positions, an effect we counteract with Multi-Head Attention as
 described in section X.
\end_layout

\begin_layout Standard
Self-attention, sometimes called intra-attention is an attention mechanism
 relating different positions of a single sequence in order to compute a
 representation of the sequence.
\end_layout

\begin_layout Standard
The transformer is the first transduction model relying entirely on self-attenti
on to compute representations of its input and output without using sequence-ali
gned RNNs or convolution.
\end_layout

\begin_layout Standard
An attention function can be described as mapping a query and a set of key-value
 pairs to an output, where the query, keys, values, and output are all vectors.
 The output is computed as a weighted sum of the values, where weighte assigned
 to each value is computed by a compatibility function of the query with
 the corresponding key.
\end_layout

\begin_layout Standard
(1) Scaled Dot-Product Attention.
 We compute the dot products of the query with all keys, divide each by
 
\begin_inset Formula $\sqrt{d_{k}}$
\end_inset

 , and apply a softmax function to obtain the weights on the values.
\begin_inset Formula 
\[
\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^{T}}{\sqrt{d_{k}}})V
\]

\end_inset


\end_layout

\begin_layout Standard
The two most commonly used attention functions are additive attention (Neural
 machine translation by jointly learning to align and translate), and dot-produc
t attention.
 Additive attention computes the compatibility function using a feed-forward
 network with a single hidden layer.
 While the two are similar in theoretical complexity, dot-product attention
 is much faster and more space-efficient in practice, since it can be implemente
d using highly optimized matrix multiplication code.
\end_layout

\begin_layout Standard
(2) Multi-Head Attention.
 Instead of performing a single attention function with 
\begin_inset Formula $d_{model}$
\end_inset

-dimensional keys, values and queries, we found it beneficial to linearly
 project the queries, keys and values 
\begin_inset Formula $h$
\end_inset

 times with different, learned linear projections to 
\begin_inset Formula $d_{k},d_{k}$
\end_inset

 and 
\begin_inset Formula $d_{v}$
\end_inset

 dimensions, respectively...
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\text{MultiHead}(Q,K,V) & =\text{Concat}(\text{head}_{1},\ldots,\text{head}_{h})W^{O}\\
\text{where }\text{head}_{i} & =\text{Attention}(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $W_{i}^{Q}\in R^{d_{model}\times d_{k}},W_{i}^{K}\in R^{d_{model}\times d_{k}},W_{i}^{V}\in R^{d_{model}\times d_{v}},W^{O}\in R^{hd_{v}\times d_{model}}$
\end_inset

.
\end_layout

\begin_layout Standard
As side benefit, self-attention could yield more interpretable models.
\end_layout

\begin_layout Standard
Adam optimizer is used for learining.
 Two types of regularizations, residual dropout and label smoothing are
 employed during training.
\end_layout

\begin_layout Standard
Code: https://github.com/tensorflow/tensor2tensor
\end_layout

\begin_layout Subsubsection

\series bold
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
\end_layout

\begin_layout Subsubsection
Deep contextualized word representations (ELMo representations)
\end_layout

\begin_layout Standard
We introduce a new type of deep contexturalized word representation that
 models both (1) complex characteristics of word use (e.g.
 syntax and semantics), and (2) how these uses vary across linguistic contexts
 (i.e.
 to model polysemy).
\end_layout

\begin_layout Standard
We also present an analysis showing that exposing the deep internals of
 the pre-trained network is crucial, allowing downstream models to mix different
 types of semi-supervision signals.
\end_layout

\begin_layout Standard
Previous work has also shown that different layers of deep biRNNs encode
 different types of information.
 For example, introducing multi-task syntactic supervision (e.g.
 part-of-speech tags) at the lower levels of a deep LSTM can improve overall
 performance of higher level tasks such as dependency parsing or CCG super
 tagging.
\end_layout

\begin_layout Standard
In contrast, after pretraining the biLM with unlabeled data, we fix the
 weights and add additional task specific model capacity, allowing us to
 leverage large, rich and universal biLM representations for cases where
 downstream training data size dictates a smaller supervised model.
\end_layout

\begin_layout Standard
For each token 
\begin_inset Formula $t_{k}$
\end_inset

, a 
\begin_inset Formula $L$
\end_inset

-layer biLM computes a set of 
\begin_inset Formula $2L+1$
\end_inset

 representations
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
R_{k}=\{x_{k}^{LM},\overrightarrow{h_{k,j}^{LM}},\overleftarrow{h_{k,j}^{LM}}|j=1,\ldots,L\}=\{h_{k,j}^{LM}|j=0,\ldots,L\}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $h_{k,0}^{LM}$
\end_inset

 is the token layer and 
\begin_inset Formula $h_{k,j}^{LM}=[\overrightarrow{h},\overleftarrow{h}]$
\end_inset

 for each biLSTM layer.
 For includin in a downstream model, ELMo collapses all layers in R into
 a single vector,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
ELMo_{k}^{task}=E(R_{k};\Theta_{e})=\gamma^{task}\sum_{j=1}^{L}s_{j}^{task}h_{k,j}^{LM}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $s^{task}$
\end_inset

 are softmax-normalized weights and the scalar parameter 
\begin_inset Formula $\gamma^{task}$
\end_inset

 allows the task model to scale the entire ELMo vector.
 In the simplest case, ELMo just selects the top layer.
\end_layout

\begin_layout Standard
Given a pre-trained biLM and a supervised architecture for a target NLP
 task, it is a simple process to use the biLM to improve the task model.
 We simply run the biLM and record all of the layer representations for
 each word.
 Then, we let the end task model learn a linear combination of these representat
ions.
\end_layout

\begin_layout Standard
Once pretrained, the biLM can compute representations for any task.
 In some cases, fine tuinng the biLM on domain specific data leads to significan
t drops in perplexity and an increase in down stream task performance.
 This can be seen as a type of domain transfer for the biLM.
 As a result, in most cases we used a fine-tuned biLM in the odwn stream
 task.
\end_layout

\begin_layout Subsection
Image Caption Generation
\end_layout

\begin_layout Subsubsection
Hierarchy Parsing for Image Captioning
\end_layout

\begin_layout Standard
ICCV19.
 attractive idea, similar to our HM-LSTM
\end_layout

\begin_layout Standard
In this paper,we introduce a new design to model a hierarchy from in-stance
 level (segmentation), region level (detection) to thewhole image to delve
 into a thorough image understandingfor captioning.
 Specifically, we present a HIerarchy Pars-ing (HIP) architecture that novelly
 integrates hierarchicalstructure into image encoder.
 Technically, an image decom-poses into a set of regions and some of the
 regions are re-solved into finer ones.
 Each region then regresses to an in-stance, i.e., foreground of the region.
 Such process naturallybuilds a hierarchal tree.
 A tree-structured Long Short-TermMemory (Tree-LSTM) network is then employed
 to inter-pret the hierarchal structure and enhance all the instance-level,
 region-level and image-level features.
 Our HIP is ap-pealing in view that it is pluggable to any neural caption-ing
 models.
\end_layout

\begin_layout Subsubsection
Reflective Decoding Network for Image Captioning
\end_layout

\begin_layout Standard
ICCV19.
\end_layout

\begin_layout Standard
State-of-the-art image captioning methods mostly focuson improving visual
 features, less attention has been paid toutilizing the inherent properties
 of language to boost cap-tioning performance.
 In this paper, we show that vocab-ulary coherence between words and syntactic
 paradigm ofsentences are also important to generate high-quality im-age
 caption.
 Following the conventional encoder-decoderframework, we propose the Reflective
 Decoding Network(RDN) for image captioning, which enhances both the long-sequen
ce dependency and position perception of words ina caption decoder.
\end_layout

\begin_layout Subsubsection
Unpaired Image Captioning via Scene Graph Alignments
\end_layout

\begin_layout Standard
ICCV19.
 However, getting largescale image-caption paired data is labor-intensive
 andtime-consuming.
 In this paper, we present a scene graph-based approach for unpaired image
 captioning.
\end_layout

\begin_layout Subsubsection
Unsupervised Image Captioning
\end_layout

\begin_layout Standard
Tag: Distillation
\end_layout

\begin_layout Standard
Deep neural networks have achieved great successes on the image captioning
 task.
 However, most of the existing models depend heavily on paired image-sentence
 datasets, which are very expensive to acquire.
 In this paper, we make the first attempt to train an image captioning model
 in an unsupervised manner.
 Instead of relying on manually la- beled image-sentence pairs, our proposed
 model merely re- quires an image set, a sentence corpus, and an existing
 vi- sual concept detector.
 The sentence corpus is used to teach the captioning model how to generate
 plausible sentences.
 Meanwhile, the knowledge in the visual concept detector is distilled into
 the captioning model to guide the model to rec- ognize the visual concepts
 in an image.
\end_layout

\begin_layout Subsubsection
Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
 (Bengio, 2015)
\end_layout

\begin_layout Standard
Inspired by recent work in machine translation and object detection, we
 introduce an attention based model that automatically learns to describe
 the content of images.
\end_layout

\begin_layout Standard
Using representations (such as those from the top layer of a convnet) that
 distill information in image down to the most salient objects is one effective
 solution that has been widely adopted in previous work.
 Unfortunately, this has one potential drawback of losing information which
 could be useful for richer, more descriptive captions.
 Using more low-level representation can help preserve this information.
 However working with these features necessitates a powerful mechanism to
 steer the model to information important to the task at hand.
\end_layout

\begin_layout Standard
This paper presents two attention-based image caption generators under a
 common framework: (1) a 
\begin_inset Quotes eld
\end_inset

soft
\begin_inset Quotes erd
\end_inset

 deterministic attention mechanism trainable by standard back-propagation
 methods and (2) a 
\begin_inset Quotes eld
\end_inset

hard
\begin_inset Quotes erd
\end_inset

 stochastic attention mechanism trainable by maximizing an approximate variation
al lower bound or equivalently by REINFORCE.
\end_layout

\begin_layout Standard
One major reason image caption generation is well suited to the encoder-decoder
 frameowkr of machine translation is because it is analogous to 
\begin_inset Quotes eld
\end_inset

translating
\begin_inset Quotes erd
\end_inset

 an image to a sentence.
\end_layout

\begin_layout Standard
Prior to the use of neural networks for generating captions, two main approaches
 were dominant.
 The first involved genrating caption templates which were filled in based
 on the results of obje ct detections and attribute discovery.
 The second approach was based on first retrieving similar captioned images
 from a large database then modifying these retrieved captions to fit the
 query.
 These approaches typically involved an intermediate 
\begin_inset Quotes eld
\end_inset

generalization
\begin_inset Quotes erd
\end_inset

 step to remove the specifics of a captions that are only relevfant to the
 retrieved image, such as the name of a city.
 Both of these approaches have since fallen out of favour to the now dominant
 neural network methods.
\end_layout

\begin_layout Standard
There are two variants of the attention-based model, where the main difference
 is the difinition of the 
\begin_inset Formula $\phi$
\end_inset

 function.
\end_layout

\begin_layout Standard
Our model takes a single raw image and generates a caption 
\begin_inset Formula $y$
\end_inset

 encoded as a sequence of 1-of-K encoded words.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y=\{y_{1},\ldots,y_{C}\},y_{i}\in R^{K}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $K$
\end_inset

 is the size of the vocabulary and 
\begin_inset Formula $C$
\end_inset

 is the length of the caption.
\end_layout

\begin_layout Standard
A convolutional neural network is used to extract a set of feature vectors
 which we refer to as annotation vectors.
 The extractor produces L vectors, each of which is a 
\begin_inset Formula $D$
\end_inset

-dimentional representation corresponding to a part of the image.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
a=\{a_{1},\ldots,a_{L}\},a_{i}\in R^{D}
\]

\end_inset


\end_layout

\begin_layout Standard
In order to obtain a correspondence between the feature vectors and portions
 of the 2-D image, we extract features from a lower convolutional layer
 unlike previous work which instead used a fully connected layer.
 This allows the decoder to selectively focous on certain parts of an image
 by selecting a subset of all the features vectors.
\end_layout

\begin_layout Standard
Using 
\begin_inset Formula $T_{s,t}:R^{s}\mapsto R^{t}$
\end_inset

 to denote a simple affine transformation with parameters that are learned,
 the LSTM used in this paper would look like
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{pmatrix}i_{t}\\
f_{t}\\
o_{t}\\
g_{t}
\end{pmatrix}=\begin{pmatrix}\sigma\\
\sigma\\
\sigma\\
\text{tanh}
\end{pmatrix}T_{D+m+n,n}\begin{pmatrix}Ey_{t-1}\\
h_{t-1}\\
\hat{z_{t}}
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
c_{t}=f_{t}\odot c_{t-1}+i_{t}\odot g_{t}\text{ , }h_{t}=o_{t}\odot\text{tanh}(c_{t})
\]

\end_inset


\end_layout

\begin_layout Standard
The vector 
\begin_inset Formula $\hat{z_{t}}\in R^{D}$
\end_inset

 is the context vector, captureing the visual information associated with
 a particular input location.
\end_layout

\begin_layout Standard
For each location 
\begin_inset Formula $i$
\end_inset

, the mechanism generates a positive weight 
\begin_inset Formula $\alpha_{i}$
\end_inset

 which can be interpreted either as the probability that loation 
\begin_inset Formula $i$
\end_inset

 is the right place to focous for producing the next word, or as the relative
 importantce to give to location 
\begin_inset Formula $i$
\end_inset

 in blending the 
\begin_inset Formula $a_{i}$
\end_inset

's together.
\end_layout

\begin_layout Subsubsection
Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially
 Labeled Data (ECCV18)
\end_layout

\begin_layout Standard
This paper presents an image captioning framework with a self-retrieval
 module as training guidance, which encourages generating discriminative
 captions.
 Existing studies working on the aformentioned problems either used Generative
 Adversarial Networks (GAN) to generate human-like descriptions, or focused
 on enlarging the diversity of generated captions.
 Those methods improve the diversity of generated captions but sacrifice
 overall performance on standard evaluation criteria.
\end_layout

\begin_layout Standard
The discriminativeness of a caption can be evaluated by how ewell it can
 distinguish its corresponding image from other images.
 This criterion can be introduced as a guidance for training, and thus encourage
s discriminative captions.
 Image captioning and text-to-image retrieval can be viewed as dual tasks.
 Image captioning generates a description of a geiven image, while text-to-image
 retrieval retreives back the image based on the generated caption.
 Specifically, the model consists of a captioning module and a self-retrieval
 module.
\end_layout

\begin_layout Standard
Since generating each word of a caption contains non-differentiable operations,
 we take the negative retrieval lsos as self-retrieval reward and adopt
 reinforce algorithm to compute gradients.
\end_layout

\begin_layout Section
Story: Generative Adversarial Network
\end_layout

\begin_layout Subsection
DeepFake
\end_layout

\begin_layout Subsubsection
FaceForensics++: Learning to Detect Manipulated Facial Images
\end_layout

\begin_layout Standard
ICCV19
\end_layout

\begin_layout Standard
The rapid progress in synthetic image generation andmanipulation has now
 come to a point where it raises signif-icant concerns for the implications
 towards society.
 At best,this leads to a loss of trust in digital content, but could po-tentiall
y cause further harm by spreading false informationor fake news.
 
\end_layout

\begin_layout Subsection
Understanding
\end_layout

\begin_layout Subsubsection
Adversarial Feedback Loop
\end_layout

\begin_layout Standard
ICCV19
\end_layout

\begin_layout Standard
.
 In this paper we propose anovel method that makes an explicit use of the
 discriminatorin test-time, in a feedback manner in order to improve thegenerato
r results.
 To the best of our knowledge it is the firsttime a discriminator is involved
 in test-time.
 
\end_layout

\begin_layout Subsubsection
Learning Words by Drawing Images
\end_layout

\begin_layout Standard
We propose a framework for learning through draw- ing.
 Our goal is to learn the correspondence between spo- ken words and abstract
 visual attributes, from a dataset of spoken descriptions of images.
 Building upon recent find- ings that GAN representations can be manipulated
 to edit semantic concepts in the generated output, we propose a new method
 to use such GAN-generated images to train a model using a triplet loss.
 
\end_layout

\begin_layout Subsection
Generation
\end_layout

\begin_layout Subsubsection
SinGAN: Learning a Generative Model from a Single Natural Image
\end_layout

\begin_layout Standard
ICCV19 spotlight
\end_layout

\begin_layout Standard
We introduceSinGAN, an unconditional generativemodel that can be learned
 from a single natural image.Our model is trained to capture the internal
 distribution ofpatches within the image, and is then able to generate highquali
ty, diverse samples that carry the same visual contentas the image.
 SinGAN contains a pyramid of fully convolu-tional GANs, each responsible
 for learning the patch distri-bution at a different scale of the image.
 This allows generat-ing new samples of arbitrary size and aspect ratio,
 that havesignificant variability, yet maintain both the global struc-ture
 and the fine textures of the training image.
 In contrastto previous single image GAN schemes, our approach is notlimited
 to texture images, and is not conditional (i.e.
 it gen-erates samples from noise).
 User studies confirm that thegenerated samples are commonly confused to
 be real im-ages.
 We illustrate the utility of SinGAN in a wide range ofimage manipulation
 tasks.
\end_layout

\begin_layout Subsubsection
Adversarial Representation Learning for Text-to-Image Matching
\end_layout

\begin_layout Standard
GAN, CUHK-PEDES, flicker30k, not far better than VSE++.
\end_layout

\begin_layout Subsection
Loss Function
\end_layout

\begin_layout Subsubsection
A General and Adaptive Robust Loss Function
\end_layout

\begin_layout Standard
We present a generalization of the Cauchy/Lorentzian, Geman-McClure, Welsch/Lecl
erc, generalized Charbon- nier, Charbonnier/pseudo-Huber/L1-L2, and L2 loss
 func- tions.
 
\end_layout

\begin_layout Section
Story: 3D & PCL
\end_layout

\begin_layout Subsubsection
DeepVoxels: Learning Persistent 3D Feature Embeddings
\end_layout

\begin_layout Standard
In this work, we address the lack of 3D understanding of generative neural
 networks by introducing a persistent 3D feature embedding for view synthesis.
 To this end, we propose DeepVoxels, a learned representation that encodes
 the view-dependent appearance of a 3D scene without hav- ing to explicitly
 model its geometr
\end_layout

\begin_layout Subsubsection
Learning to Sample
\end_layout

\begin_layout Standard
Processing large point clouds is a challenging task.
 Therefore, the data is often sampled to a size that can be processed more
 easily.
 The question is how to sample the data? A popular sampling technique is
 Farthest Point Sam- pling (FPS).
 However, FPS is agnostic to a downstream ap- plication (classification,
 retrieval, etc.).
 The underlying as- sumption seems to be that minimizing the farthest point
 dis- tance, as done by FPS, is a good proxy to other objective functions.
\end_layout

\begin_layout Subsection
3D Object
\end_layout

\begin_layout Subsubsection
2019-CVPR: PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical
 Part-level 3D Object Understanding
\end_layout

\begin_layout Standard
We present PartNet: a consistent, large-scale dataset of 3D objects annotated
 with fine-grained, instance-level, and hierarchical 3D part information.
\end_layout

\begin_layout Subsubsection
PointRCNN: 3D Object Proposal Generation and Detection from Point Clou
\end_layout

\begin_layout Standard
In this paper, we propose PointRCNN for 3D object de- tection from raw point
 cloud.
\end_layout

\begin_layout Section
Story: Activation Functions
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
url{https://en.wikipedia.org/wiki/Activation_function}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Story: Loss Functions
\end_layout

\begin_layout Subsection
Efficient Optimization for Rank-based Loss Functions
\end_layout

\begin_layout Standard
The non-differentiability and non-decompoosability of those ranking based
 loss functions (e.g.
 AP and NDCG) do not allow for simple gradient based optimization algorithms.
 These loss functions are amendable to a quicksort based optimization algorithm
 proposed in this paper.
 In literature, such problem is usually circumvented by either optimizing
 a structured hinge-loss upper bound to the loss function or by by using
 asymptotic methods like the direct-loss minimization framework.
 Yet, the high computational compexity of loss-augmented inference, which
 is necessary for both the frameworks, prohibits its use in large training
 data sets.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section
Story: Meta Learning
\end_layout

\begin_layout Subsection
Learning to learn by gradient descent by gradient descent
\end_layout

\begin_layout Standard
In this paper we show how the sesign of an optimization algorithm can be
 cast as a learning problem, allowing the algorithm to learn to exploit
 structure in the problems of interest in an automatic way.
 Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed
 competitors on the tasks for which they are trained, and also generalize
 well to new taskes with similar structure.
\end_layout

\begin_layout Standard
Standard approach for differentiable functions is some form of gradient
 descent, resulting in a sequence of updates 
\begin_inset Formula 
\[
\theta_{t+1}=\theta_{t}-\alpha_{t}\nabla f(\theta_{t})
\]

\end_inset

 .
 The performance of vanilla gradient descent, however, is hampered by the
 fact that it only makes use of gradients and ignores second-order information.
 Classical optimization techniques correct this behavior by rescaling the
 gradient step using curvature information, typically via the Hessian matrix
 of second-order partial derivatives – although other choices such as the
 generalized Gauss-Newton matrix or Fisher information matrix are possible.
\end_layout

\begin_layout Standard
In this work we take a different tack and instead propose to replace hand-design
ed update rules with a learned update rule, which we call the optimizer
 
\begin_inset Formula $g$
\end_inset

 , specified by its own set of parameters 
\begin_inset Formula $\phi$
\end_inset

 .
 This results in updates to the optimizee 
\begin_inset Formula $f$
\end_inset

 of the form 
\begin_inset Formula 
\[
\theta_{t+1}=\theta_{t}+g_{t}(\nabla f(\theta_{t}),\phi)
\]

\end_inset


\end_layout

\begin_layout Standard
The use of recurrence allows the LSTM to learn dynamic update rules which
 integerate information forom the history of graidients, similar to momemtum.
 This is known to have many desirable properties in convex optimization,
 and in fact many recent learning procedures – such as Adam – use momemtum
 in their updates.
\end_layout

\begin_layout Standard
The design of optimization algorithms has been cast as a learning problem,
 which enables us to train optimizers that are specialized to particular
 classes of functions.
\end_layout

\begin_layout Subsection
Incremental Learning
\end_layout

\begin_layout Subsubsection
Large Scale Incremental Learning
\end_layout

\begin_layout Standard
Modern machine learning suffers from catastrophic for- getting when learning
 new classes incrementally.
 The per- formance dramatically degrades due to the missing data of old
 classes.
 Incremental learning methods have been pro- posed to retain the knowledge
 acquired from the old classes, by using knowledge distilling and keeping
 a few exemplars from the old classes.
 However, these methods struggle to scale up to a large number of classes
 .
 
\end_layout

\begin_layout Section
Story: DL & Industry
\end_layout

\begin_layout Standard
Success of deep learning stems from (1) big data (2) high-performance computing.
\end_layout

\begin_layout Standard
Limitations of deep learning: (1) structured understanding (2) effective
 algorithm on small dataset.
\end_layout

\begin_layout Standard
Recommendation system often occupies more than 80% of computation resources.
\end_layout

\begin_layout Standard
Avoid manual tweaking: AutoML.
 Effective AutoML.
\end_layout

\begin_layout Subsection
Parallelism in Deep Learning
\end_layout

\begin_layout Enumerate
Model Parallelism: Same layer is processed across different machines.
\end_layout

\begin_layout Enumerate
Data Parallelism: Batch split.
 Can be done either synchronously or asynchronously.
\end_layout

\begin_layout Subsection
Factorization Tricks for LSTM Networks (ICLRw 17)
\end_layout

\begin_layout Standard
This paper presents two simple ways of reducing the number of parameters
 and accelerating the training of large LSTM networks: (1) 
\begin_inset Quotes eld
\end_inset

matrix factorization by design
\begin_inset Quotes erd
\end_inset

 of LSTM matrix into the product of two smaller matrices; (2) partitioning
 of LSTM matrix, its inputs and states into the indenpendent groups.
\end_layout

\begin_layout Standard
To address the vanishing and exploding gradient problem observed in RNNs,
 the LSTM cell has been introduced with the following recurrent computations:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\text{LSTM}:(h_{t-1},c_{t-1},x_{t})\mapsto(h_{t},c_{t})
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $x_{t}$
\end_inset

 is input, 
\begin_inset Formula $h_{t}$
\end_inset

 is cell's state, and 
\begin_inset Formula $c_{t}$
\end_inset

 is cell's memory.
 We consider LSTM cell with projection of size 
\begin_inset Formula $p$
\end_inset

, LSTMP, where the above equation is computed as follows
\begin_inset Formula 
\[
\begin{pmatrix}i\\
f\\
o\\
g
\end{pmatrix}=\begin{pmatrix}sigm\\
sigm\\
sigm\\
tanh
\end{pmatrix}T\begin{pmatrix}x_{t}\\
h_{t-1}
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $x_{t}\in^{p}$
\end_inset

, 
\begin_inset Formula $h_{t}\in R^{p}$
\end_inset

 , and 
\begin_inset Formula $T:R^{2p}\mapsto R^{4n}$
\end_inset

 is an affine transform 
\begin_inset Formula $T=W*[x_{t},h_{t-1}]+b$
\end_inset

 .
 Next state 
\begin_inset Formula $h_{t}\in R^{p}$
\end_inset

 and memory 
\begin_inset Formula $c_{t}\in R^{n}$
\end_inset

 are computed using following equations:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
c_{t}=f\odot c_{t-1}+i\odot g
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{t}=P(o\odot tanh(c_{t}))
\]

\end_inset


\end_layout

\begin_layout Section
Story: How To Classify?
\end_layout

\begin_layout Subsubsection
NM-Net: Mining Reliable Neighbors for Robust Feature Correspondences
\end_layout

\begin_layout Standard
Feature correspondence selection is pivotal to many feature-matching based
 tasks in computer vision.
 Search- ing for spatially k -nearest neighbors is a common strategy for
 extracting local information in many previous works.
 However, there is no guarantee that the spatially k -nearest neighbors
 of correspondences are consistent because the spatial distribution of false
 correspondences is often irreg- ular.
\end_layout

\begin_layout Part
Memo
\end_layout

\begin_layout Section
Very Short Memo
\end_layout

\begin_layout Enumerate
Stub.
\end_layout

\begin_layout Enumerate
1805.03403: Cross Domain Regularization for Neural Ranking Models using Adversari
al Learning.
 Without any special supervision, these models learn relationships that
 may hold only in the domain from which the train- ing data is sampled,
 and generalize poorly to domains not observed during training.
 We study the effectiveness of adversarial learning as a cross domain regularize
r in the context of the ranking task.
 We use an adversarial discriminator and train our neural ranking model
 on a small set of domains.
 The discriminator provides a nega- tive feedback signal to discourage the
 model from learning domain specific representations.
\end_layout

\begin_layout Enumerate
2018-SIGIR: CAN: Enhancing Sentence Similarity Modeling with Collaborative
 and Adversarial Network.
 Most neural networks focus on the representation of each sentence, while
 the common features of a sentence pair are not well studied.
 In this paper, we propose a Collaborative and Adversarial Network (CAN),
 which explicitly models the common features between two sentences for enhancing
 sentence similarity modeling.
 To be specific, a common feature extractor is presented and embedded into
 our CAN model, which includes a generator and a discriminator playing a
 collaborative and adversarial game for common feature extraction.
\end_layout

\begin_layout Enumerate
1602.04567: Adversarial Top- K Ranking.
 We study the top- K ranking problem where the goal is to recover the set
 of top- K ranked items out of a large collection of items based on partially
 revealed prefe rences.
\end_layout

\begin_layout Enumerate
2017-MM: Adversarial Cross-Modal Retrieval.
 Cross-modal retrieval aims to enable flexible retrieval experience across
 different modalities ( e.g.
 , texts vs.
 images).
 The core of cross- modal retrieval research is to learn a common subspace
 where the items of different modalities can be directly compared to each
 other.
 In this paper, we present a novel Adversarial Cross-Modal Retrieval (ACMR)
 method, which seeks an effective common subspace based on adversarial learning.
 Adversarial learning is implemented as an interplay between two processes.
 The first process, a feature projector, tries to generate a modality-invariant
 representation in the common subspace and to confuse the other process,
 modality classifier, which tries to discriminate between different modalities
 based on the generated representation.
\end_layout

\begin_layout Enumerate
1708.04552: Improved Regularization of Convolutional Neural Networks with
 Cutout.
 In this paper, we show that the simple regularization technique of randomly
 masking out square regions of in- put during training, which we call cutout,
 can be used to improve the robustness and overall performance of con- volutiona
l neural networks.
 Not only is this method ex- tremely easy to implement, but we also demonstrate
 that it can be used in conjunction with existing forms of data augmentation
 and other regularizers to further improve model performance.
\end_layout

\begin_layout Enumerate
2006: Ranking Attack Graphs.
 A majority of attacks on computer systems result from a combination of
 vulnerabilities exploited by an intruder to break into the system.
 An Attack Graph is a general formalism used to model security vulnerabilities
 of a system and all possible sequences of exploits which an intruder can
 use to achieve a specific goal.
 Attack Graphs can be con- structed automatically using off-the-shelf model-chec
king tools.
 However, for real systems, the size and complexity of Attack Graphs greatly
 ex- ceeds human ability to visualize, understand and analyze.
 Therefore, it is useful to identify relevant portions of an Attack Graph.
\end_layout

\begin_layout Enumerate
1708.04150: Binary Generative Adversarial Networks for Image Retrieval.
 In this paper, we use binary generative adversarial networks (BGAN) to
 embed images to binary codes in an unsupervised way.
 By restricting the input noise variable of generative adversarial networks
 (GAN) to be binary and conditioned on the features of each input image,
 BGAN can simultaneously learn a binary representation per image, and generate
 an image plausibly similar to the original one.
\end_layout

\begin_layout Enumerate
1607.02748: Adversarial Training For Sketch Retrieval.
 In this paper, we show that the representations learned by GANs can indeed
 be used for retrieval.
 We consider heritage documents that contain unlabelled Merchant Marks,
 sketch-like symbols that are similar to hieroglyphs.
 We introduce a novel GAN architecture with design features that make it
 suitable for sketch retrieval.
\end_layout

\begin_layout Enumerate
1711.07838: Adversarial Network Embedding.
 In this paper, we aim to exploit the strengths of generative adversarial
 networks in capturing latent features, and investigate its contribution
 in learning stable and robust graph representations.
 Specifically, we propose an Adversar- ial Network Embedding (ANE) framework,
 which leverages the adversarial learning principle to regularize the represen-
 tation learning.
\end_layout

\begin_layout Enumerate
1804.04082: Ranking CGANs: Subjective Control over Semantic Image Attributes.
 In this paper, we investigate the use of generative adversarial networks
 in the task of image generation according to subjective measures of semantic
 attributes.
 Unlike the standard (CGAN) that generates images from discrete categorical
 labels, our architecture handles both continuous and discrete scales.
\end_layout

\begin_layout Enumerate
2018-SIGIR: Cross Domain Regularization for Neural Ranking Models using
 Adversarial Learning.
 Without any special supervision, these models learn relationships that
 may hold only in the domain from which the training data is sampled, and
 generalize poorly to domains not observed during training.
 We study the effectiveness of adversarial learning as a cross domain regularize
r in the context of the ranking task.
 We use an adversarial discriminator and train our neural rank- ing model
 on a small set of domains.
 The discriminator provides a negative feedback signal to discourage the
 model from learning do- main specific representations.
\end_layout

\begin_layout Enumerate
Robust Large Margin Deep Neural Networks.
 The generalization error of deep neural networks viatheir classification
 margin is studied in this paper.
 Our analysis leads to theconclusion that a bounded spectral norm of the
 network’s Jacobianmatrix in the neighbourhood of the training samples is
 crucial fora deep neural network of arbitrary depth and width to generalizewell.
 This is a significant improvement over the current bounds inthe literature,
 which imply that the generalization error grows witheither the width or
 the depth of the network.
\end_layout

\begin_layout Enumerate
1905.06517: Additive Adversarial Learning for Unbiased Authentication.
 The recently-emerging data-driven authenti-cation process may encounter
 undesired biases, i.e., themodels are often trained in one domain (e.g., for
 peoplewearing spring outfits) while required to apply in otherdomains (e.g.,
 they change the clothes to summer out-fits).
 To address this issue, we propose a novel two-stagemethod that disentangles
 the class/identity from domain-differences, and we consider multiple types
 of domain-difference.In the first stage, we learn disentangledrepresentations
 by a one-versus-rest disentangle learning(OVRDL) mechanism.
 In the second stage, we improve thedisentanglement by an additive adversarial
 learning (AAL)mechanism.
\end_layout

\begin_layout Enumerate
1905.01273: Learning Cross-Modal Embeddings with Adversarial Networks for
 Cooking Recipes and Food Images.
 In this paper, we investigate anopen research task of cross-modal retrieval
 between cookingrecipes and food images, and propose a novel frameworkAdversaria
l Cross-Modal Embedding (ACME) to resolve thecross-modal retrieval task
 in food domains.
 Specifically, thegoal is to learn a common embedding feature space betweenthe
 two modalities, in which our approach consists of severalnovel ideas: (i)
 learning by using a new triplet loss schemetogether with an effective sampling
 strategy, (ii) imposingmodality alignment using an adversarial learning
 strategy,and (iii) imposing cross-modal translation consistency suchthat
 the embedding of one modality is able to recover someimportant information
 of corresponding instances in theother modality.
\end_layout

\begin_layout Enumerate
1503.03832: FaceNet: A Unified Embedding for Face Recognition and Clustering.
 In this paper we present asystem, called FaceNet, that directly learns
 a mapping fromface images to a compact Euclidean space where distancesdirectly
 correspond to a measure of face similarity.
 Oncethis space has been produced, tasks such as face recogni-tion, verification
 and clustering can be easily implementedusing standard techniques with
 FaceNet embeddings as fea-ture vectors.
\end_layout

\begin_layout Enumerate
1904.04663: Domain-Symmetric Networks for Adversarial Domain Adaptation.
 Unsupervised domain adaptation aims to learn a modelof classifier for unlabeled
 samples on the target domain,given training data of labeled samples on
 the source do-main.
 Impressive progress is made recently by learninginvariant features via
 domain-adversarial training of deepnetworks.
 In spite of the recent progress, domain adaptationis still limited in achieving
 the invariance of feature distri-butions at a finer category level.
 To this end, we propose inthis paper a new domain adaptation method called
 Domain-Symmetric Networks (SymNets).
\end_layout

\begin_layout Enumerate
1904.05050: Heavy Rain Image Restoration: Integrating Physics Model and Condition
al Adversarial Learning.
 Inheavy rain, streaks are strongly visible, dense rain accu-mulation or
 rain veiling effect significantly washes out theimage, further scenes are
 relatively more blurry, etc.
 In thispaper, we propose a novel method to address these prob-lems.
 We put forth a 2-stage network: a physics-based back-bone followed by a
 depth-guided GAN refinement.
\end_layout

\begin_layout Enumerate
Graph Convolutional Tracking (CVPR19).
 To comprehensive-ly leverage the spatial-temporal structure of historical
 tar-get exemplars and get benefit from the context informa-tion, in this
 work, we present a novel Graph ConvolutionalTracking (GCT) method for high-perf
ormance visual track-ing.
 Specifically, the GCT jointly incorporates two typesof Graph Convolutional
 Networks (GCNs) into a siameseframework for target appearance modeling.
 Here, we adopta spatial-temporal GCN to model the structured representa-tion
 of historical target exemplars.
 Furthermore, a contextGCN is designed to utilize the context of the current
 frameto learn adaptive features for target localization.
\end_layout

\begin_layout Enumerate
Beyond Weight Tying: Learning Joint Input-Output Embeddings for Neural Machine
 Translation.
 Tying the weights of the target word em-beddings with the target word classifie
rs ofneural machine translation models leads tofaster training and often
 to better translationquality.
 Given the success of this parametersharing, we investigate other forms
 of shar-ing in between no sharing and hard equal-ity of parameters.In particular
, we pro-pose astructure-awareoutput layer whichcaptures the semantic structure
 of the outputspace of words within a joint input-output em-bedding.
\end_layout

\begin_layout Enumerate
SphereGAN-CVPR19: Sphere Generative Adversarial Network Based on Geometric
 Moment Matching.
 We propose sphere generative adversarial network(GAN), a novel integral
 probability metric (IPM)-basedGAN.
 Sphere GAN uses the hypersphere to bound IPMsin the objective function.
 Thus, it can be trained sta-bly.
 On the hypersphere, sphere GAN exploits the in-formation of higher-order
 statistics of data using geomet-ric moment matching, thereby providing
 more accurate re-sults.
 In the paper, we mathematically prove the goodproperties of sphere GAN.
\end_layout

\begin_layout Enumerate
1904.01310: DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Im
age Synthesis.
 In this paper, we pro-pose the Dynamic Memory Generative Adversarial Network(DM
-GAN) to generate high-quality images.
 The proposedmethod introduces a dynamic memory module to refine fuzzyimage
 contents, when the initial images are not well gener-ated.
 A memory writing gate is designed to select the im-portant text information
 based on the initial image content,which enables our method to accurately
 generate imagesfrom the text description.
\end_layout

\begin_layout Enumerate
1902.10740: Object-driven Text-to-Image Synthesis via Adversarial Training.
 In this paper, we propose Object-driven Attentive Gen-erative Adversarial
 Newtorks (Obj-GANs) that allowobject-centered text-to-image synthesis for
 complex scenes.Following the two-step (layout-image) generation process,a
 novel object-driven attentive image generator is pro-posed to synthesize
 salient objects by paying attention tothe most relevant words in the text
 description and thepre-generated semantic layout.
 In addition, a new FastR-CNN based object-wise discriminator is proposed
 toprovide rich object-wise discrimination signals on whetherthe synthesized
 object matches the text description and thepre-generated layout.
\end_layout

\begin_layout Enumerate
1412.2309: Visual Causal Feature Learning.
 We provide a rigorous definition of thevisualcauseof a behavior that is
 broadly applicableto the visually driven behavior in humans, ani-mals,
 neurons, robots and other perceiving sys-tems.
 Our framework generalizes standard ac-counts of causal learning to settings
 in whichthe causal variables need to be constructed frommicro-variables.
 We prove the Causal Coars-ening Theorem, which allows us to gain causalknowledg
e from observational data with minimalexperimental effort.
 The theorem provides a con-nection to standard inference techniques in
 ma-chine learning that identify features of an imagethatcorrelatewith,
 but may notcause, the targetbehavior.
 Finally, we propose an active learningscheme to learn a manipulator function
 that per-forms optimal manipulations on the image to au-tomatically identify
 the visual cause of a targetbehavior.
\end_layout

\begin_layout Enumerate
1707.07413: EXPLORING NEURAL TRANSDUCERS FOR END-TO-END SPEECH RECOGNITION.
 This is an overview about state-of-the-art ASR systems.
\end_layout

\begin_layout Enumerate
Listen, Attend and Spell (LAS).
 This model is based on the Seq2Seq pattern.
 The encoder part is a mixture of Bi-LSTM and Uni-LSTM (Pyramid LSTM).
 The decoder part is a multi-layer LSTM with Attention mechanism.
 Problem formulation is similar to DeepSpeech.
\end_layout

\begin_layout Enumerate
Deep Speech 2: End-to-End Speech Recognition inEnglish and Mandarin.
 We show that an end-to-end deep learning approach can be used to recognizeeithe
r English or Mandarin Chinese speech—two vastly different languages.
 The model is similar to the DS1.
 The input spectrogram is fed into 3 layers of Conv (1d or 2d), followed
 by 7 layers of Bi-RNN or Bi-GRU.
 At the end of the network there's a fully connected layer.
\end_layout

\begin_layout Enumerate
Deep Speech: Scaling up end-to-endspeech recognition.
 Every input is a piece of spectrogram plus it's left and right 
\begin_inset Formula $C$
\end_inset

 neighboring pieces.
 The frame of spectrogram is fed into a 3-layer MLP, followed by a bi-RNN
 (not LSTM).
 By summing up the bi-RNN output and fed the result into affine transformation
 layer and softmax activation, the network output, i.e.
 the probability distribution over 26 alphabets is obtained.
 Loss function is CTC.
 Before producing the actual transcript, an auxiliary n-gram language model
 is used to refine the DeepSpeech output.
 Classical ASR systems involve complicated pipelines, but by leveraging
 deep learining the end-to-end ASR solution is possible.
\end_layout

\begin_layout Enumerate
Triplet Loss Based Cosine Similarity Metric Learning for Text-independent
 Speaker Recognition.
 The problem we addressed in the paper is choosing a dnn basedspeaker embedding
 backend solution for the speaker verifica-tion scoring.
\end_layout

\begin_layout Enumerate
ON THE ACCURACY AND ROBUSTNESS OF DEEP TRIPLET EMBEDDING FOR FINGERPRINT
 LIVENESS DETECTION.
 In this paper, theclassical binary classification formulation (live/fake)
 is sub-stituted by a deep metric learning framework that can gener-ate
 a representation of real and artificial fingerprints and ex-plicitly models
 the underlying factors that explain their inter-and intra-class variations.
 The framework is based on a deeptriplet network architecture and consists
 of a variation of theoriginal triplet loss function.
\end_layout

\begin_layout Enumerate
Face Recognition on Consumer Devices: Reflections on Replay Attacks.
 This paper proposes an approach to counter replay attacks forface recognition
 on smart consumer devices using a noninvasivechallenge and response technique.
\end_layout

\begin_layout Enumerate
GANE: A Generative Adversarial Network Embedding.
 We propose to adapt the Generative Adversar-ial model to perform network
 embedding, in which the generatoris trying to generate vertex pairs, while
 the discriminator triesto distinguish the generated vertex pairs from real
 connections(edges) in the network.
\end_layout

\begin_layout Enumerate
1705.11001: Adversarial Ranking for Language Generation.
 In this paper, wepropose a novel generative adversarial network, RankGAN,
 for generating high-quality language descriptions.
 Rather than training the discriminator to learnand assign absolute binary
 predicate for individual data sample, the proposedRankGAN is able to analyze
 and rank a collection of human-written and machine-written sentences by
 giving a reference group.
\end_layout

\begin_layout Enumerate
(ICLR19 Best Paper) The lottery ticket hypothesis: finding sparse, trainable
 neural networks.
 The authors articulate the lottery ticket hypotheses: dense, randomly-initializ
ed, feed-forward networks contain subnetworks (wininig tickets) that – when
 trainined in isolation – reach test acceracy comparable to the original
 networks in a similar number of iterations.
\end_layout

\begin_layout Enumerate
(ICLR19 Best Paper) Ordered neurons: integrating tree structures into recurrent
 neural networks.
 Natural language is hierarchically structured: smaller units (e.g., phrases)
 arenested within larger units (e.g., clauses).
 When a larger constituent ends, all ofthe smaller constituents that are
 nested within it must also be closed.
 While thestandard LSTM architecture allows different neurons to track informati
on at dif-ferent time scales, it does not have an explicit bias towards
 modeling a hierarchyof constituents.
\end_layout

\begin_layout Enumerate
A Low-Rank Approximation Approach to Learning Joint Embeddings of News Stories
 and Images for Timeline Summarization: A key challenge for timeline summarizati
on isto generate a concise, yet complete storylinefrom large collections
 of news stories.
 Pre-vious studies in extractive timeline generationare limited in two ways:
 first, most prior workfocuses on fully-observable ranking models orclustering
 models with hand-designed featuresthat may not generalize well.
 Second, mostsummarization corpora are text-only, whichmeans that text is
 the sole source of infor-mation considered in timeline summarization,and
 thus, the rich visual content from newsimages is ignored.
 To solve these issues, weleverage the success of matrix factorizationtechniques
 from recommender systems, andcast the problem as a sentence recommenda-tion
 task, using a representation learning ap-proach.
\end_layout

\begin_layout Enumerate
IMAGE ENHANCEMENT NETWORK TRAINED BY USING HDR IMAGES.
 In this paper, a novel image enhancement network is proposed, where HDR
 images are used for generating training data for our network.
\end_layout

\begin_layout Enumerate
HYPERBOLIC DISCOUNTING AND LEARNING OVER MULTIPLE HORIZONS (Bengio).
 Reinforcement Learning (RL) typically defines a discount factor (
\begin_inset Formula $\gamma$
\end_inset

) as part of the Markov Decision Process.
 The discount factor values future rewards by an exponential scheme that
 leads to theoretical convergence guarantees of the Bellman equation.
 However, evidence from psychology, economics and neuroscience suggestes
 that humans and animals instead have huperbolic time-preferences.
\end_layout

\begin_layout Enumerate
A lattice-based approach: to the expressivity of deep ReLU neural networks.
 We present new families of continuous piecewisee linear (CPWL) functions
 in 
\begin_inset Formula $R^{n}$
\end_inset

 having a number of affine pieces growing exponentially in 
\begin_inset Formula $n$
\end_inset

 .
\end_layout

\begin_layout Enumerate
Insertion-based Decoding with automaticallyInferred Generation Order.
 Conventional neural autoregressive decoding commonly assumes a fixed left-to-ri
ght generation order, which may be sub-optimal.
\end_layout

\begin_layout Enumerate
Joint Face Detection and Facial Motion Retargeting for Multiple Faces.
 Facial motion retargeting is an important problem in both computer graphics
 and vision, which involves capturing the performance of a human face and
 transferring it to another 3D character.
 Learning 3D morphable model (3DMM) parameters from 2D face images using
 convolutional neural networks is common in 2D face alignment, 3D face reconstru
ction etc.
 However, existing methods either require an additional face detection step
 before retartetting or use a cascade of separate networks to perform detection
 followed by retargeting in a sequence.
 In this paper, we present a single end-to-end network to jointly predict
 the bounding box locations and 3DMM parameters for multiple faces.
\end_layout

\begin_layout Enumerate
Stochastically Rank-Regularized Tensor Regression Networks.
 Over-parameterization of deep neural networks has recently been shown to
 be key to their successful training.
 However, it also renders them prone to overfitting and makes them expensive
 to store and train.
 Tensor regression networks significantly reduce the number of effective
 parameters in deep neural networks while retaining accuracy and the easy
 of training.
 They replace the flattening and fully-connected layers with a tensor regression
 layer, where the regression weights are expressed through the factors of
 a low-rank tensor decomposition.
 In this paper, to further improve tensor regression networks, we propose
 a novel stochastic rank-regularization.
\end_layout

\begin_layout Enumerate
Deep learning generalizes because the parameter-function map is biased towards
 simple functions.
 Deep neural networks (DNNs) generalize remarkably well without explicit
 regularization even in the strongly over-parameterized regime where classical
 learning theory would instead predict that they would severly overfit.
 By applying a very general probability-complexity bound recently derived
 from algorithmic information theory (AIT), we argue that the parameter-function
 map of many DNNs should be exponentially biased towards simple functions.
\end_layout

\begin_layout Enumerate
FINANCIAL SERIES PREDICTION USINGATTENTIONLSTM.
 Many researchers have used deep learning methods to predict financial time
 series with various models in recent years.
 This paper compares various deep learning models for financial time series
 prediction.
\end_layout

\begin_layout Enumerate
Towards Robust ResNet: A Small Stepbut A Giant Leap.
 This paper presents a simple yet principled approach to boosting the robustness
 of the residual network that is motivated by the dynamical system perspective.
 Namely, a deep neural network can be interpreted using a partial differential
 equation, which naturally inspires us to characterize ResNet by an explicit
 Euler method.
\end_layout

\begin_layout Enumerate
Associatively Segmenting Instances and Semantics in Point clouds.
 In this paper, we first introduce a simple and flexible framework to segment
 instances and semantics in point clouds simultaneously.
\end_layout

\begin_layout Enumerate
Discovery of netural language concepts in individual units of CNNs.
 In an attempt to understand the representations of deep convolutional networks
 trained on language tasks, we show that individual units are selectively
 responsive to specific morphemes, words, and phrases, rather than responding
 to arbitrary and uninterpretable patterns.
\end_layout

\begin_layout Enumerate
Context-aware Dynamic Block.
 Existing methods usually choose to execute or skip an entire specific layer
 through a switch structure, which can obly alter the depth of the network.
 In this paper, we propose a dynamic inference method called Context-aware
 Dynamic Block (CDB), which provides more path selection choices in terms
 of network width and depth during inference.
\end_layout

\begin_layout Enumerate
Learning partially ranked data based on graph regularization.
 There often exhibits a situation in which data are partially ranked.
 Partially ranked data is thought of as mising data.
\end_layout

\begin_layout Enumerate
Controllable neural story plot generation via reward shaping.
 Language-modeling-based approaches to story plot generation attempt to
 construct a plot by sampling from a language model (LM) to predict the
 next character, word, or sentence to add to the story.
 LM techniques lack the ability to receive guidance from the user to achieve
 a specific goal, resulting in stories that don't have a clear sense of
 progression and lack coherence.
\end_layout

\begin_layout Enumerate
MassFace: an efficient implementation using triplet loss for face recognition.
 This paper presents an efficient implementation using triplet loss for
 face recognition.
 We conduct the practical experiement to analyze the factors that influence
 the training of triplet loss.
\end_layout

\begin_layout Enumerate
Dual Attention Network for Scene Segmentation.
 In this paper, we address the scene segmentation task by captureing rich
 contextual dependencies based on the self-attention mechanism.
 Unlike previous works that capture contexts by multi-scale features fusion,
 we propose a dual attention networks (DANet) to adaptly integrate local
 features with their global dependencies.
\end_layout

\begin_layout Enumerate
DPOD: Dense 6D Pose Object Detector in RGB images.
 In this work we propose a new method for simultaneous object detection
 and 6D0F pose estimation.
 Unlike most recent techniques for CNN-based object detection and pose estimatio
n, we do not base our approach on the common 2D counterparts, i.e.
 SSD and YOLO, but propose a new scheme.
 Instead of regression 2D or 3D bounding boxes, we output full-sized 2D
 images containing multiclass object masks and dense 2D-3D correspondences.
\end_layout

\begin_layout Enumerate
A hybrid machine-learning algorithm for designing quantum experiments.
 We introduce a hybrid machine-learning algorithm for designing quantum
 optics experiments to produce specific quantum states.
\end_layout

\begin_layout Enumerate
Image captioning with weakly-supervised attention penalty.
 No work has been done to align implicitly learned attention maps with intrinsic
 visual attentions.
\end_layout

\begin_layout Enumerate
A Kernelized Manifold Mapping to Diminish the Effect ofAdversarial Perturbations.
 The linear and non-flexible nature of deep convolutional models makes them
 vulnerable to carefully crafted adversarial perturbations.
\end_layout

\begin_layout Enumerate
MFAS: Multimodal Fusion Architecture Search
\end_layout

\begin_layout Enumerate
SimulCap : Single-View Human Performance Capture with Cloth Simulation.
 This paper proposes a new method for live free-viewpoint human performance
 capture with dynamic detailes using a single RGBD camera.
\end_layout

\begin_layout Enumerate
SceneCode: Monocular Dense Semantic Reconstruction using Learned EncodedScene
 Representations.
\end_layout

\begin_layout Enumerate
Inserting Videos into Videos.
 In this paper, we introduce a new problem of manipulating a given video
 by inserting other videos into it.
\end_layout

\begin_layout Enumerate
Selective Kernel Networks.
 It is well-known in the neuralscience community that the receptive field
 size of visual cortical neurons are modulated by the stimulus, which has
 been rarely considered in constructing CNNs.
 We propose a dynamic selection mechanism in CNNs that allows each neuron
 to adaptively adjust its receptive field size based on mutiple scales of
 input information.
\end_layout

\begin_layout Enumerate
Domain Generalization by Solving Jigsaw Puzzles.
 This paper proposes to apply an approach to the task of object recognition
 across domains: our model learns the semantic labels in a supervised fasion,
 and broadens its udnerstanding of the data by learning from self-supervised
 signals how to solve a jigsaw puzzle on the same images.
\end_layout

\begin_layout Enumerate
Fast Interactive Object Annotation with Curve-GCN.
 Manually labeling objects by tracing their boundaries is a laborious process.
 In some previous works, the authors proposed Polygon-RNN that produces
 polygonal annotations in a recurrent manner using a CNN-RNN architecutre,
 allowing interactive correction via humans-in-the-loop.
 We propose a new framework that alleviates the sequential nature of Polygon-RNN
, by predicting all vertices simutaneously using a Graph Convolutional Network.
\end_layout

\begin_layout Enumerate
A Cross-Season Correspondence Dataset for Robust Semantic Segmentation.
 This paper presents a method to utilize 2D-2D point matches between images
 taken during different image conditions to train a convolutional neural
 network for semantic segmanetation.
\end_layout

\begin_layout Enumerate
Unsupervised Part-Based Disentangling of Object Shape and Appearance.
 Learning to disentangle and represent these different characteristics poses
 a great challenge, especially in the unsupervised case.
\end_layout

\begin_layout Enumerate
AdaGraph: Unifying Predictive and ContinuousDomain Adaptation through Graphs.
 Within the context of domain adaptation and generalization, this paper
 focuses on the predictive domain adaptation scenario, namely the save where
 no target data are available and the system has to learn to generalize
 from annotated source images plus unlabeled samples with associated metadata
 from auxiliary domains.
\end_layout

\begin_layout Enumerate
QATM: Quality-Aware Template Matching For Deep Learning.
 This paper proposes a novel quality-aware template matching method.
 QATM, which is not only used as a standalone template matching algorithm,
 but also a trainable layer that can be easily embedded into any deep neural
 network.
\end_layout

\begin_layout Enumerate
Graph Convolutional Label Noise Cleaner:Train a Plug-and-play Action Classifier
 for Anomaly Detection.
 Video anomaly detection under weak labels is formulated as a typical multiple-i
nstance learning problem in previous works.
\end_layout

\begin_layout Enumerate
Semantic Image Synthesis with Spatially-Adaptive Normalization.
 We propose spatially-adaptive normalization, a simple but effective layer
 for synthesizing photorealistic images given an input semantic layout.
 Previous methods directly feed the semantic layout as input to the deep
 network, which is then processed through stacks of convolution, normalization,
 and nonlinearity layers.
 We show that this is suboptimal as the normalization layers tend to 
\begin_inset Quotes eld
\end_inset

wash away
\begin_inset Quotes erd
\end_inset

 semantic information.
\end_layout

\begin_layout Enumerate
Self-calibrating Deep Photometric Stereo Networks.
 This paper proposes an uncalibrated photometric stereomethod for non-Lambertian
 scenes based on deep learning.
\end_layout

\begin_layout Enumerate
Understanding the Limitations of CNN-based Absolute Camera Pose Regression.
 Visual localization is the task of accurate camera pose estimation in a
 known scene.
 Recently, end-to-end approaches based on convolutional neural networks
 have become popular.
 These methods learn to directly regress the camera pose from an input image.
 However, they do not achieve the same level of pose accurady as 3D streucture-b
ased methods.
 To understand this behavior, we develop a theoretical model for camera
 pose regression.
\end_layout

\begin_layout Enumerate
Learning Correspondence from the Cycle-consistency of Time.
 We introduce a self-supervised method for learning visual correspondense
 from unlabeled video.
\end_layout

\begin_layout Enumerate
Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis.
 Most conditional generation tasks expect diverse outputs given a single
 conditional context.
 However, conditional generative adversarial networks (cGANs) often focus
 on the prior conditional information and ignore the input noise vectors,
 which contribute to the output variantions.
 Recent attetmpts to resolve the mode collapse issue for cGANs are ustually
 tasks-specific and computationally expensive.
\end_layout

\begin_layout Enumerate
Learning Parallax Attention for Stereo Image Super-Resolution.
 Stereo image pairs can be used to improve the perofmrance of super-resolution
 (SR) since additional information is provided from a second viewpoint.
 However, it is challenging to incorporate this information for SR since
 disparities between stereo images vary significantly.
\end_layout

\begin_layout Enumerate
A Skeleton-bridged Deep Learning Approach for Generating Meshesof Complex
 Topologies from Single RGB Images.
 This paper focuses on the challenging task of learning 3D object surface
 reconstruction from single RGB images.
 Existing methods achieve varying degrees of success by using different
 geometric representations.
 However, they all have their own drawbacks, and cannot well reconstruct
 those surfaces of complex topologies.
\end_layout

\begin_layout Enumerate
Dense Classification and Implanting for Few-Shot Learning.
 This paper targets at knowledge transfer from a set with abundant data
 to other sets with few available examples.
\end_layout

\begin_layout Enumerate
All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networksf
or Image Classification.
 Shift operation is an efficient alternative over depthwise separable convolutio
n.
 However, it is still bottlenecked by its implementation manner, namely
 memory movement.
 To put this direction forward, a new and novel basic component named Sparse
 Shift Layer is introduced in this paper to construct efficient convolutional
 neural networks.
\end_layout

\begin_layout Enumerate
Depth Coefficients for Depth Completion.
 Depth completion involves estimating a dense depth image from sparse depth
 measurements, often guided by a color image.
 While linear upsampling is straght forward, it results in artifacts including
 depth pixels begin interpolated in empty space accross discontinuities
 between objects.
\end_layout

\begin_layout Enumerate
Defense Against Adversarial Images using Web-Scale Nearest-Neighbor Search.
 A plethora of recent work has shown that convolutional networks are not
 robust to adversarial images: images that are created by purturbing a sample
 from the data distribution as to maximize the loss on the perturbed example.
 In this work, we hypothesize that adversarial perturbations move the image
 away from the image manifold in the sense that there exists no physical
 process that could have produced the adversarial image.
 This hypothesis suggests that a successful defense mechanism against adversaria
l images should aim to project the images back onto the image manifold.
\end_layout

\begin_layout Enumerate
Unsupervised Domain-Specific Deblurring via Disentangled Representations.
 Image deblurring aims to restore the latent sharp images from the corresponding
 blurred ones.
 This paper presents an unsupervised method for domain-specific single-image
 deblurring based on disentangled representations.
\end_layout

\begin_layout Enumerate
Joint Face Detection and Facial Motion Retargeting for Multiple Faces.
 Facial motion retargeting involves capturing the performance of a human
 face and transferring it to another 3D character.
 Existing methods either require an additional face detection step before
 retargeting or use a cascade of separate networks to perform detection
 followed by retargeting in a sequence.
 This paper presents a single end-to-end network to jointly predict the
 bounding box locations and 3DMM parameters for multiple faces.
\end_layout

\begin_layout Enumerate
End-to-End Efficient Representation Learning via Cascading Combinatorial
 Optimization.
 We develop hierarchically quantized efficient embedding representations
 for similarity-based seasrch and show that this representation provides
 not only the state of the art performance on the search accuracy but also
 provides several orders of speed up during inference.
\end_layout

\begin_layout Enumerate
Mask Scoring R-CNN.
 In the task of instance segmentation, the confidence of instance classification
 is used as mask quality score in most instance segmentation frameworks.
 However, the mask quality, quantified as the IoU between the instance mask
 and its ground trouth, is uscally not well correlated with classification
 score.
 In this paper, we study this problem and propose mask scoring r-cnn which
 contains a network block to learn the quality of the predicted instance
 masks.
\end_layout

\begin_layout Enumerate
RGBD Based Dimensional Decomposition Residual Network for 3D SemanticScene
 Completion.
 RGB images differentiate from depth images as they carry more details about
 the color and texture information, which can be utilized as a vital complementa
ry to depth for boosting the performance of 3D semantic scene completion.
 Most of the existing methods use depth as the sole input which causes the
 performance bottleneck.
 Moreover, the state-of-the-art methods emply 3D CNNs which have cumbersome
 networks and tremendous parameters.
\end_layout

\begin_layout Enumerate
Knowledge-Embedded Routing Network for Scene Graph Generation.
 To understand a scene in depth not only involves locating and recognizing
 indivisual objects, but also requires to infer the relationships and interactio
ns among them.
 However, since the distribution of real-world relationships is seriously
 unbalanced, existing methods perform quite poorly for the less frequent
 relationships.
 In this paper, we find that the statistical correlations between object
 pairs and their relationships can effectively regularize semantic space
 and make prediction less ambiguous.
\end_layout

\begin_layout Enumerate
Partial Order Pruning: for Best Speed/Accuracy Trade-off inNeural Architecture
 Search.
 Most existing automatic architecture search approaches only pursue high
 performance but ignores the speed and accuracy trade-off on target platform.
\end_layout

\begin_layout Enumerate
Fast Single Image Reflection Suppression via Convex Optimization.
 Removing undesired reflections from images taken through the glass is of
 great importance in computer vision.
 We propose a convex model to suppress the reflection from a single input
 image.
 Our model implies a partial differential equation with gradient thresholding,
 which is solved efficiently using DCT.
\end_layout

\begin_layout Enumerate
Group-wise Correlation Stereo Network.
 Stereo matching estimates the disparity between a rectified image pair,
 which is of great importance to depth sensing, autonomous driving, and
 other related tasks.
 Previous works built cost volumes with cross-correlation or contatenation
 of left and right features across all disparity levels, and then a 2D or
 3D convolutional neural network is utilized to regress the disparity maps.
\end_layout

\begin_layout Enumerate
HetConv: Heterogeneous Kernel-Based Convolutions for Deep CNNs.
 This paper presents a novel deep learning architecture in which the convolution
 operation leverages heterogeneous kernels.
 The proposed HetConv reduces the computation and the number of parameters
 as compared to standard convolution operation while still maintaining represent
ational efficiency.
\end_layout

\begin_layout Enumerate
Structured Knowledge Distillation for Semantic Segmentation.
 This paper investigates the knowledge distillation strategy for training
 small semantic segmentation networks by making use of large networks.
\end_layout

\begin_layout Enumerate
Refine and Distill: Exploiting Cycle-Inconsistency and KnowledgeDistillation
 for Unsupervised Monocular Depth Estimation.
 The majority of state-of-the-art monocular depth estimation techniques
 are based on supervised deep learning models, However, collecting RGB images
 with associated depth matps is a very time consuming procedure.
 There for, recent works have proposed deep architerctures for addressing
 the monocular depth prediction task as a reconstruction problem, thus avoiding
 the need of collecting ground-truth depth.
\end_layout

\begin_layout Enumerate
Video Generation from Single Semantic Label Map.
 This paper focuses on the task of video generation conditioned on a single
 semantic label map, which provides a good balance between flexibility and
 quality in the generation process.
 Different from typical end-to-end approaches, which model both scene content
 and dynamics in a single step, we propose to decompose this difficult task
 into two sub-problems.
\end_layout

\begin_layout Enumerate
Weakly Supervised Complementary Parts Models for Fine-Grained ImageClassificatio
n from the Bottom Up.
 Deep CNNs trained with image level labels only tend to focus on the most
 discriminative parts while missing other object parts, which could provide
 complementary information.
 In this paper, we approach this problem from a different perspective.
 We build complementary parts models in a weakly supervised manner to retrieve
 information suppressed by dominant object parts detected by convolutional
 neural networks.
\end_layout

\begin_layout Enumerate
COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis.
 Most existing datasets for instructional video analysis have the limitations
 in diversity and scale, which makes them far from many real-word applications
 where more diverse activities occur.
 To address this problem, this paper introduced a large-scale dataset called
 COIN, organized with a hierarchical structure.
\end_layout

\begin_layout Enumerate
MUTAN: Multimodal Tucker Fusion for Visual Question Answering.
 Bilinear models provide an appealing framework for mixing and merging informati
on in VQA tasks.
 They help to learn high level associations between question meaning and
 visual concepts in the image, but they suffer from huge dimensionality
 issues.
 This paper introduced a multimodel tensor-based Tucker decomposition to
 efficiently parametrize bilinear interactions between visual and textual
 representations.
\end_layout

\begin_layout Enumerate
Deep High-Resolution Representation Learning for Human Pose Estimation.
 This paper focuses on learning reliable high-resolution representations
 for human pose estimation problem.
 Most existing methods recover high-resolution representations from low-resoluti
on representations produced by a high-to-low resolution network.
 Instead, the network proposed in this paper maintains high-resolution represent
ations through the whole process.
\end_layout

\begin_layout Enumerate
CIRCCONV: A STRUCTURED CONVOLUTION WITH LOW COMPLEXITY.
 However, the largemodel sizes of DNNs yield high demands on computation
 resource and weight storage, therebylimiting the practical deployment of
 DNNs.
\end_layout

\begin_layout Enumerate
Efficient Contextual Representation Learning Without Softmax Layer.
 Contextual representation models haveachieved great success in improving
 var-ious downstream tasks.
 However, theselanguage-model-based encoders are diffi-cult to train due
 to the large parameter sizesand high computational complexity
\end_layout

\begin_layout Enumerate
Efficient Parameter-free Clustering Using First Neighbor Relations.
 n contrast to mostexisting clustering algorithms our method does not requireany
 hyper-parameters, distance thresholds and/or the needto specify the number
 of clusters.
 The proposed algorithmbelongs to the family of hierarchical agglomerative
 methods.
\end_layout

\begin_layout Enumerate
Generalized Intersection over Union: A Metric and A Loss for Bounding BoxRegress
ion (GIoU).
 The optimal objec-tive for a metric is the metric itself.
 In the case of axis-aligned 2D bounding boxes, it can be shown thatIoUcanbe
 directly used as a regression loss.
 However,IoUhas aplateau making it infeasible to optimize in the case of
 non-overlapping bounding boxes.
 In this paper, we address theweaknesses ofIoUby introducing a generalized
 version asboth a new loss and a new metric.
\end_layout

\begin_layout Enumerate
Learning a Deep ConvNet for Multi-label Classification with Partial Labels.
 Modified BCE loss for partial labels, Graph Neural Network for label correlatio
ns, curriculum-based learning approach.
\end_layout

\begin_layout Enumerate
An Attention Enhanced Graph Convolutional LSTM Network forSkeleton-Based
 Action Recognition.
\end_layout

\begin_layout Enumerate
Data augmentation using learned transformsfor one-shot medical image segmentatio
n.
\end_layout

\begin_layout Enumerate
MUREL: Multimodal Relational Reasoning for Visual Question Answering.
 Multimodal attentional networks are currently state-of-the-art models for
 Visual Question Answering (VQA) tasksinvolving real images.
 Multiplemultimodal fusion strategies have been recently proposed to model
 the relevant interactions be-tween two modalities.
 One of the most efficient techniqueis the one proposed by [8], based on
 the Tucker decomposi-tion of third-order tensors
\end_layout

\begin_layout Enumerate
Context Encoding for Semantic Segmentation.
 Even humans find the task challenging.
 However, narrow-ing the list of probable categories based on scene contextmakes
 labeling much easier.
\end_layout

\begin_layout Enumerate
DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion.
 A key technical challenge in performing 6D object poseestimation from RGB-D
 image is to fully leverage the twocomplementary data sources.
 Prior works either extract in-formation from the RGB image and depth separately
 or usecostly post-processing steps, limiting their performances inhighly
 cluttered scenes and real-time applications.
 In thiswork, we present DenseFusion, a generic framework forestimating
 6D pose of a set of known objects from RGB-D images.
 DenseFusion is a heterogeneous architecturethat processes the two data
 sources individually and uses anovel dense fusion network to extract pixel-wise
 dense fea-ture embedding, from which the pose is estimated.
\end_layout

\begin_layout Enumerate
Gradient Acceleration in Activation Functions.
 Dropout has been one of standard approaches to train deep neural networks,
 andit is known to regularize large models to avoid overfitting.
 The effect of dropouthas been explained by avoiding co-adaptation.
 In this paper, however, we proposea new explanation of why dropout works
 and propose a new technique to designbetter activation functions.
\end_layout

\begin_layout Enumerate
A Performance Comparison of Loss Functions for Deep Face Recognition.
 Cross-Entropy Loss, Angular-Softmax Loss, Additive Margin Softmax Loss,
 ArcFace Loss, Marginal Loss
\end_layout

\begin_layout Enumerate
A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING.
 The methods to obtain representations of phrases and sentecnes fall into
 two categories.
 The first consists of universal sentence embeddings usually trained by
 unsupervised learning.
 The other category consists of models trained specifically for a certain
 task.
 We propose a self-attentionmechanism for these sequential models to replace
 the max pooling or averaging step.
 Different fromprevious approaches, the proposed self-attention mechanism
 allows extracting different aspects ofthe sentence into multiple vector
 representations.
 It is performed on top of an LSTM in our sentenceembedding model.
\end_layout

\begin_layout Enumerate
Depthwise Convolution is All You Need for Learning Multiple Visual Domains.
 If there exists auniversal structure in different visual domains that can
 becaptured via a common parameterization, then we can use asingle model
 for all domains rather than one model per do-main.
\end_layout

\begin_layout Enumerate
A SPELLING CORRECTION MODEL FOR END-TO-END SPEECH RECOGNITION.
 the language model component ofthe end-to-end model is only trained on
 transcribed audio-text pairs,which leads to performance degradation especially
 on rare words.
 In this paper, we propose a novelapproach to utilizing text-only data,
 by training a spelling correction(SC) model to explicitly correct those
 errors.
 ...
 training a supervised “spelling correction” model to explic-itly correct
 the errors made by the LAS (Listen, Attend and Spell) recognizer.
\end_layout

\begin_layout Enumerate
Going Deeper in Spiking Neural Networks:VGG and Residual Architectures.
 Over the past few years, Spiking Neural Networks (SNNs) have become popular
 as a possiblepathway to enable low-power event-driven neuromorphic hardware.
 However, their application inmachine learning have largely been limited
 to very shallow neural network architectures for simpleproblems.
\end_layout

\begin_layout Enumerate
Siamese Neural Networks for One-shot Image Recognition.
 Classification under the restriction that we may only observe a single
 example of each possible class before making a prediction about a test
 instance is called one-shot learning.
 This should be distinguished from zero-shot learning, in which the model
 cannot look at any examples from the target classes.
 To develop a model for one-shot image classification, we aim to first learn
 a neural network that can discriminate between the class-identity of image
 pairs, which is the standard verification task for image recognition.
 The goal of HBPL (Hierarchical Bayesian Program Learning) is to determine
 a structural explanation for the observed pixels.
 However, inference under HBPL is difficult since the joint parameter space
 is very large, leading to an intractable integration problem.
\end_layout

\begin_layout Enumerate
Hardness-Aware Deep Metric Learning.
 This paper presents a hardness-aware deep metric learning (HDML) framework.
 Most previous deep metric learning methods employ the hard negative mining
 strategy to alleviate the lack of informative samples for training.
 However, this mining strategy only utilized a subset of training data,
 which may not be enough to characterize the global geometry of the embedding
 space comprehensively.
\end_layout

\begin_layout Enumerate
Dense Relational Captioning: Triple-Stream Networks for Relationship-Based
 Captioning.
 Our goal in this work is to train an image captioning model that generates
 more dense and informative captions.
\end_layout

\begin_layout Enumerate
MirrorGAN: Learning Text-to-image Generation by Redescription.
 Generating an image from a given text discription has two goals: visual
 relism and semantic consistency.
 Although significant progress has been made in generating high-quality
 and visually realizstic images using generative adversarial networks, guarantee
ing semantic consistency betwen the text description and visual content
 remains very challenging.
\end_layout

\begin_layout Enumerate
Unsupervised Person Re-identification by Soft Multilabel Learning.
 The idea is to learn a soft multilabel for each unlabeled person by comparing
 the unlabeled person with a set of known reference persons from an auxiliary
 domain.
\end_layout

\begin_layout Enumerate
Less is More: Learning Highlight Detection from Video Duration.
 Highlight detection has the potential to significantly ease video browsing,
 but existing methods often suffer from expensive supervision requirements,
 where human viewers must manually identify hightlights in training videos.
 We propose a scalable unsupervised solution that exploits video duration
 as an implicit supervision signal.
 Our key insight is that video segments from shorter user-generated videos
 are more likely to be highlights than those from longer videos, since users
 tend to be more selective about the content when captureing shorter videos.
 Leveraging this insight, we introduce a novel ranking framework that prefers
 segments from shorter videos, while properly accounting for the inherent
 noise in the training data.
\end_layout

\begin_layout Enumerate
UNSUPERVISEDDISCOVERY OF PARTS, STRUCTURE, AND DYNAMICS.
 Humans easily recognize object parts and their hierarchical structure by
 watching how they move.
 They can them predict how each part moves in the future.
 This paper proposes a novel formulation that simutaneously learns a hierarchica
l, disentangled object representation and a dynamics model for object parts
 from unlabeled videos.
\end_layout

\begin_layout Enumerate
Building Machines That Learn and Think Like People.
 Recent progress in artificial intelligence has renewed interest in building
 systems that learn and think like people.
 Many advances have come from using deep neural networks trained end-to-end
 in tasks such as object recognition, video games, and board games, achieving
 performance that equals or even beats bumans in some respects.
 Despite their biological inspiration and performance achievements, these
 systems differ from human intelligence in crucial ways.
 We review progress in cognitive science suggesting that truly human-like
 learning and thinking machines will have to reach beyond current enginerring
 trends in both what they learn, and how they learn it.
\end_layout

\begin_layout Enumerate
Preventing Failures Due to Dataset Shift:Learning Predictive Models That
 Transport.
 Classical supervised learning produces unreliable models when training
 and target distributions differ, with most existing solutions requires
 samples from the target domain.
 We propose a proactive approach which learns a relationship in the training
 domain that will generalize to the target domain by incorporating prior
 knowledge of aspects of the data genreating process that are expected to
 differ as expressed in a casual selection diagram.
\end_layout

\begin_layout Enumerate
A Structured Model For Action Detection.
 A dominant paradigm for learning-bsaed approaches in computer vision is
 training generic models, such as ResNet for image recognition, or I3D for
 video understanding, on large datasets and allowing them to discover the
 optimal representation for the problem at hand.
 While this is an obviously attractive approach, it is not applicable in
 all scenarios.
 We claim that action detection is one such challenging problem - the models
 that need to be trained are large, and the labeled data is expensive to
 obtain.
 To address this limitation, we propose to incorporate domain knowledge
 into the structure of the model to simplify optimization.
 In particylar, we augment a standard I3D network with a tracking module
 to aggregate long term motion patterns, and use a graph convolutional network
 to reason about interfactions between actors and objects.
\end_layout

\begin_layout Enumerate
No Padding Please: Efficient neural handwriting recognition.
 In this work we develop methods to create efficient MDLSTM-based models
 for NHR, particularly a method aimed at eliminating computation waste that
 results from padding.
\end_layout

\begin_layout Enumerate
Jointly optimizing diversity and relevance in neural response generation.
 Although recent neural conversation models have shown great potential,
 they often generate bland and generic responses.
 While various approaches have been explored to diversify the output of
 the conversation model, the improvement often comes at the cost of decreased
 relevance.
 In this paper, we propose a method to jointly optimize diversity and relevance
 that essentially fuses the latent space of a sequence-to-sequence model
 and that of an autoencoder model by leveraging novel regularization terms.
 As a result, our approach incudes a latent space in which the distance
 and direction from the predicted response vector roughly match the relevance
 and diversity, respectively.
 This property also lends itself well to an intuitive visualization of the
 latent space.
\end_layout

\begin_layout Enumerate
Active exploration in markov decision processes.
 We introduce the active exploration problem in Markov decision processes
 (MDPs).
\end_layout

\begin_layout Enumerate
Deep Neural Network Approximation for Custom Hardware:Where We’ve Been,
 Where We’re Going.
 Research has shown that custom hardware-based neural network accelerators
 can surpass their general-purpose processor equivalents in terns of both
 thoroughput and energy efficiency.
 Application-tailored accelerators, when co-designed with approximation-based
 network training methods, transform large, desnse and computationally expensive
 networks into small, sparse and hardware-efficient alternatives, increasing
 the feasibility of network deployment.
 In this article, we provide a comprehensive evaluation of approximation
 methods for high-performance network inference along with in-depth discussion
 of their effectiveness for custom hardware implementation.
\end_layout

\begin_layout Enumerate
RNN-based Generative Model for Fine-Grained Sketching.
 Deep generative models have shown great promise when itcomes to synthesising
 novel images.
 While they can generate images thatlook convincing on a higher-level, generatin
g fine-grained details is stilla challenge.
 In order to foster research on more powerful generative ap-proaches, this
 paper proposes a novel task: generative modelling of 2Dtree skeletons.
 Trees are an interesting shape class because they exhibitcomplexity and
 variations that are well-suited to measure the ability ofa generative model
 to generated detailed structures.
\end_layout

\begin_layout Enumerate
An Underwater Image Enhancement BenchmarkDataset and Beyond.
 Underwater image enhancement has been attractingmuch attention due to its
 significance in marine engineeringand aquatic robot.
 Numerous underwater image enhancementalgorithms have been proposed in the
 last few years.
 However,these algorithms are mainly evaluated using either syntheticdatasets
 or few selected real-world images.
 It is thus unclearhow these algorithms would perform on images acquired
 inthe wild and how we could gauge the progress in the field.
\end_layout

\begin_layout Enumerate
Unsupervised Graph-based Rank Aggregation forImproved Retrieval.
 This paper presents a robust and comprehensive graph-based rank aggregationappr
oach, used to combine results of isolated ranker models in retrieval tasks.
\end_layout

\begin_layout Enumerate
DLS@CU: Sentence Similarity from Word Alignment and Semantic VectorComposition.
 We describe a set of top-performing systemsat the SemEval 2015 English
 Semantic TextualSimilarity (STS) task.
 Given two English sen-tences, each system outputs the degree of theirsemantic
 similarity.
 Our unsupervised system,which is based on word alignments across thetwo
 input sentences, ranked 5th among 73 sub-mitted system runs with a mean
 correlation of79.19% with human annotations.
 We also sub-mitted two runs of a supervised system whichuses word alignments
 and similarities betweencompositional sentence vectors as its features.Our
 best supervised run ranked 1st with a meancorrelation of 80.15%.
\end_layout

\begin_layout Enumerate
How Well Sentence Embeddings Capture Meaning.
 Several approaches for embedding a sentence into a vectorspace have been
 developed.
 However, it is unclear to whatextent the sentence’s position in the vector
 space reflects itssemantic meaning, rather than other factors such as syntac-ti
c structure.
 Depending on the model used for the embed-dings this will vary – different
 models are suited for differentdown-stream applications.
\end_layout

\begin_layout Enumerate
Multi-Perspective Sentence Similarity Modelingwith Convolutional Neural
 Networks.
 Modeling sentence similarity is compli-cated by the ambiguity and variability
 oflinguistic expression.
 To cope with thesechallenges, we propose a model for com-paring sentences
 that uses a multiplicity ofperspectives.
\end_layout

\begin_layout Enumerate
SPLATNet: Sparse Lattice Networks for Point Cloud Processing.
 We present a network architecture for processing pointclouds that directly
 operates on a collection of points rep-resented as a sparse set of samples
 in a high-dimensionallattice.
 Na ̈ıvely applying convolutions on this lattice scalespoorly, both in terms
 of memory and computational cost, asthe size of the lattice increases.
\end_layout

\begin_layout Enumerate
CodeSLAM — Learning a Compact, Optimisable Representation for DenseVisual
 SLAM.
 The representation of geometry in real-time 3D per-ception systems continues
 to be a critical research issue.Dense maps capture complete surface shape
 and can beaugmented with semantic labels, but their high dimension-ality
 makes them computationally costly to store and pro-cess, and unsuitable
 for rigorous probabilistic inference.Sparse feature-based representations
 avoid these problems,but capture only partial scene information and are
 mainlyuseful for localisation only.
\end_layout

\begin_layout Enumerate
Meta-Learning with Memory-Augmented Neural Networks.
 Architec-tures with augmented memory capacities, such asNeural Turing Machines
 (NTMs), offer the abil-ity to quickly encode and retrieve new informa-tion,
 and hence can potentially obviate the down-sides of conventional models.
 Here, we demon-strate the ability of a memory-augmented neu-ral network
 to rapidly assimilate new data, andleverage this data to make accurate
 predictionsafter only a few samples.
\end_layout

\begin_layout Enumerate
Multimodal Neural Language Models.
 We introduce two multimodal neural language models: models of natural lan-guage
 that can be conditioned on other modalities.
 A multimodal neural languagemodel can be used to retrieve images given
 complex description queries, retrievephrase descriptions given image queries,
 as well as generate text conditioned onimages.
\end_layout

\begin_layout Enumerate
Deep Fragment Embeddings for Bidirectional ImageSentence Mapping (DeFrag).
 We introduce a model for bidirectional retrieval of images and sentences
 througha deep, multi-modal embedding of visual and natural language data.
 Unlike pre-vious models that directly map images or sentences into a common
 embeddingspace, our model works on a finer level and embeds fragments of
 images (ob-jects) and fragments of sentences (typed dependency tree relations)
 into a com-mon space.
\end_layout

\begin_layout Enumerate
Learning Semantic Concepts and Order for Image and Sentence Matching.
 Image and sentence matching has made great progressrecently, but it remains
 challenging due to the large visual-semantic discrepancy.
 This mainly arises from that the rep-resentation of pixel-level image usually
 lacks of high-levelsemantic information as in its matched sentence.
 In thiswork, we propose a semantic-enhanced image and sentencematching
 model, which can improve the image represen-tation by learning semantic
 concepts and then organizingthem in a correct semantic order.
\end_layout

\begin_layout Enumerate
Re-ranking Person Re-identification with k-reciprocal Encoding.
 When considering person re-identification (re-ID) as aretrieval process,
 re-ranking is a critical step to improveits accuracy.
 Yet in the re-ID community, limited efforthas been devoted to re-ranking,
 especially those fully au-tomatic, unsupervised solutions.
\end_layout

\begin_layout Enumerate
ORDER-EMBEDDINGS OFIMAGES ANDLANGUAGE.
 Hypernymy, textual entailment, and image captioning can be seen as special
 casesof a single visual-semantic hierarchy over words, sentences, and images.
 In thispaper we advocate for explicitly modeling the partial order structure
 of this hierar-chy.
\end_layout

\begin_layout Enumerate
Dual Attention Networks for Multimodal Reasoning and Matching.
 We propose Dual Attention Networks (DANs) whichjointly leverage visual
 and textual attention mechanismsto capture fine-grained interplay between
 vision and lan-guage.
 DANs attend to specific regions in images and wordsin text through multiple
 steps and gather essential informa-tion from both modalities.
 Based on this framework, weintroduce two types of DANs for multimodal reasoning
 andmatching, respectively.
\end_layout

\begin_layout Enumerate
TRANSFORMER-XL: ATTENTIVE LANGUAGE MODELS BEYOND AFIXED-LENGTH CONTEXT.
 Transformer networks have a potential of learning longer-term dependency,
 butare limited by a fixed-length context in the setting of language modeling.
 As asolution, we propose a novel neural architecture,Transformer-XL, that
 enablesTransformer to learn dependency beyond a fixed length without disrupting
 tem-poral coherence.
\end_layout

\begin_layout Enumerate
Objectretrieval and localization with spatially-constrained similarity measurean
dk-NN re-ranking.
 One fundamental problem in object retrieval with thebag-of-visual words
 (BoW) model is its lack of spatial in-formation.
 Although various approaches are proposed toincorporate spatial constraints
 into the BoW model, mostof them are either too strict or too loose so that
 they areonly effective in limited cases.
 We propose a new spatially-constrained similarity measure (SCSM) to handle
 object ro-tation, scaling, view point change and appearance deforma-tion.
 The similarity measure can be efficiently calculated bya voting-based method
 using inverted files.
 Object retrievaland localization are then simultaneously achieved withoutpost-p
rocessing.
 Furthermore, we introduce a novel and ro-bust re-ranking method with thek-neare
st neighbors of thequery for automatically refining the initial search results.
\end_layout

\begin_layout Enumerate
Person Re-Identification Ranking Optimisation byDiscriminant Context Information
 Analysis.
 These methods hardlyever pay attention to the problem of visual ambiguitiesshar
ed between the first ranks.
 In this paper, we focus onsuch a problem and introduce an unsupervised
 ranking op-timization approach based on discriminant context informa-tion
 analysis.
\end_layout

\begin_layout Enumerate
Divide and Fuse: A Re-ranking Approach forPerson Re-identification.
 In this paper, we propose a “Divide and Fuse” re-ranking framework forperson
 re-ID.
 It exploits the diversity from different parts of a high-dimensional featurevec
tor for fusion-based re-ranking, while no other features are accessible.
\end_layout

\begin_layout Enumerate
Learning a Recurrent Residual Fusion Network for Multimodal Matching.
 A major challenge in matching between vision andlanguage is that they typically
 have completely differentfeatures and representations.
 In this work, we introduce anovel bridge between the modality-specific
 representationsby creating a co-embedding space based on a recurrentresidual
 fusion (RRF) block.
\end_layout

\begin_layout Enumerate
A Constrained Deep Neural Network for Ordinal Regression.
 Ordinal regression is a supervised learning problemaiming to classify instances
 into ordinal categories.
 It ischallenging to automatically extract high-level features forrepresenting
 intraclass information and interclass ordinalrelationship simultaneously.
 This paper proposes a con-strained optimization formulation for the ordinal
 regres-sion problem which minimizes the negative loglikelihoodfor multiple
 categories constrained by the order relation-ship between instances.
 Mathematically, it is equivalent toan unconstrained formulation with a
 pairwise regularizer.
\end_layout

\begin_layout Enumerate
UAN: Unified Attention Network for Convolutional Neural Networks.
 We propose a new architecture that learns to attend todifferent Convolutional
 Neural Networks (CNN) layers (i.e.,different levels of abstraction) and different
 spatial loca-tions (i.e., specific layers within a given feature map) ina
 sequential manner to perform the task at hand.
 Specifi-cally, at each Recurrent Neural Network (RNN) timestep, aCNN layer
 is selected and its output is processed by a spa-tial soft-attention mechanism.
 We refer to this architectureas the Unified Attention Network (UAN), since
 it combinesthe “what” and “where” aspects of attention, i.e., “what”level
 of abstraction to attend to, and “where” should thenetwork look at.
\end_layout

\begin_layout Enumerate
Leveraging Visual Question Answeringfor Image-Caption Ranking.
 In this work we view VQA asa “feature extraction” module to extract image
 and caption representa-tions.
 We employ these representations for the task of image-captionranking.
 Each feature dimension captures (imagines) whether a fact(question-answer
 pair) could plausibly be true for the image and cap-tion.
 This allows the model to interpret images and captions from a widevariety
 of perspectives.
\end_layout

\begin_layout Enumerate
A Functional Representation for Graph Matching.
 Graph matching is an important and persistent problem in computer vision
 and pattern recognitionfor finding node-to-node correspondence between
 graph-structured data.
 However, as widely used, graphmatching that incorporates pairwise constraints
 can be formulated as a quadratic assignment problem(QAP), which is NP-complete
 and results in intrinsic computational difficulties.
 In this paper, we present afunctional representation for graph matching
 (FRGM) that aims to provide more geometric insights on theproblem and reduce
 the space and time complexities of corresponding algorithms.
\end_layout

\begin_layout Enumerate
Listen, Attend and Spell (LAS).
 We present Listen, Attend and Spell (LAS), a neural network that learns
 to tran-scribe speech utterances to characters.
 Unlike traditional DNN-HMM models, thismodel learns all the components
 of a speech recognizer jointly.
 Our system hastwo components: a listener and a speller.
 The listener is a pyramidal recurrent net-work encoder that accepts filter
 bank spectra as inputs.
 The speller is an attention-based recurrent network decoder that emits
 characters as outputs.
\end_layout

\begin_layout Enumerate
Interactive Image Segmentation with Latent Diversity.
 Interactive image segmentation is characterized by mul-timodality.
 When the user clicks on a door, do they intendto select the door or the
 whole house? We present an end-to-end learning approach to interactive
 segmentation thattackles this ambiguity.
 Our architecture couples two con-volutional networks.
 The first is trained to synthesize adiverse set of plausible segmentations
 that conform to theuser’s input.
 The second is trained to select among these.By selecting a single solution,
 our approach retains com-patibility with existing interactive segmentation
 interfaces.
\end_layout

\begin_layout Enumerate
Deep Feature Interpolation for Image Content Changes.
 We proposeDeep Feature Interpolation (DFI), a new data-driven baseline
 for automatic high-resolution image trans-formation.
 As the name suggests, DFI relies only on sim-ple linear interpolation of
 deep convolutional features frompre-trained convnets.
 We show that despite its simplicity,DFI can perform high-level semantic
 transformations like“make older/younger”, “make bespectacled”, “add smile”,amon
g others, surprisingly well—sometimes even matchingor outperforming the
 state-of-the-art.
\end_layout

\begin_layout Enumerate
Reversible Recurrent Neural Networks.
 Recurrent neural networks (RNNs) provide state-of-the-art performance in
 pro-cessing sequential data but are memory intensive to train, limiting
 the flexibilityof RNN models which can be trained.
 Reversible RNNs—RNNs for which thehidden-to-hidden transition can be reversed—o
ffer a path to reduce the memoryrequirements of training, as hidden states
 need not be stored and instead can berecomputed during backpropagation.
\end_layout

\begin_layout Enumerate
Deep Convolutional Neural Network for ImageDeconvolution.
 Many fundamental image-related problems involve deconvolution operators.
 Realblur degradation seldom complies with an ideal linear convolution model
 due tocamera noise, saturation, image compression, to name a few.Instead
 of perfectlymodeling outliers, which is rather challenging from a generative
 model perspec-tive, we develop a deep convolutional neural network to capture
 the characteristicsof degradation.
\end_layout

\begin_layout Enumerate
A Discriminatively Trained, Multiscale, Deformable Part Model.
 This paper describes a discriminatively trained, multi-scale, deformable
 part model for object detection.
\end_layout

\begin_layout Enumerate
Deep Fusion Network for Image Completion.
 Deep image completion usually fails to harmonically blend the restored
 image into existing content, especially in the boundary area.
 DF-Net is based on U-Net.
 https://github.com/hughplay/DFNet
\end_layout

\begin_layout Section
Short Memo
\end_layout

\begin_layout Subsection

\color red
Ranked List Loss for Deep Metric Learning
\end_layout

\begin_layout Standard
https://arxiv.org/pdf/1903.03238.pdf
\end_layout

\begin_layout Standard
The objective of deep metric learning (DML) is to learn embeddings that
 can capture semantic similarity information among data points.
 Existing pairwise of tripletwise loss functions used in DML are known to
 suffer from slow convergence due to a large proportion of trivial pairs
 or triplets as the model improves.
 To improve this, ranking-motivated structured losses are proposed recently
 to incorporate multiple examples and sxploit the structured information
 among them.
 They converge faster and achieve state-of-the-art performance.
\end_layout

\begin_layout Standard
TODO
\end_layout

\begin_layout Subsection
Object retrieval and localization with spatially-constrained similarity
 measure and k -NN re-ranking (CVPR)
\end_layout

\begin_layout Standard
We observe that, a database image is similar to the query image if it is
 also similar to the nearest neighbors of the query.
\end_layout

\begin_layout Standard
Therefore, we propose a re-ranking method with the k - nearest neighbors
 ( k -NN) of the query.
 After the initial search, localized objects in the top- k retrieved images
 are also used as queries to perform search.
 A database im- age will have different ranks when using those neighbors
 as queries.
 Accordingly a new score of each database image is collaboratively determined
 by those ranks, and re-ranking is performed using the new scores.
 Unlike previous query ex- pansion and re-ranking methods, our method is
 rank-order based, which discards the features and their distances when
 measuring the score.
 Therefore, it can successfully retrieve the objects with large variations,
 while avoiding degradation when there are irrelevant objects in the k -nearest
 neighbors.
 Experimental results show it achieves higher and more ro- bust performance
 than query expansion.
\end_layout

\begin_layout Subsection
Image Super-Resolution Using Deep Convolutional Networks
\end_layout

\begin_layout Standard
This paper proposed a deep learning method for single image super-resolution
 (SISR), which directly learns an end-to-end mapping between the low- and
 high-resolution images.
 Traditional sparse-coding-based SR methods can also be viewed as a deep
 neural network, but they handle each component separately.
 In contrast, the proposed CNN has a lightweight structure, yet demonstrages
 good restoration quality, and runs fast for practical online usage.
\end_layout

\begin_layout Standard
Consider a single low-resolution image, this paper first upscale it to the
 desired size using bicubic interpolation, and the interpolated image is
 denoted as Y.
 The goal of SR is to recover an image F(Y) from Y, and F(Y) is as similar
 as possible to the ground truth high-resolution image X.
 The neural network used in this paper is a shallow convolutional neural
 network, which is trained with MSE loss function.
\end_layout

\begin_layout Standard
More Related Works: Enhanced Deep Residual Networks for Single Image Super-Resol
ution, Photo-Realistic Single Image Super-Resolution Using a Generative
 Adversarial Network, Deep Learning for Single Image Super-Resolution: A
 Brief Review.
\end_layout

\begin_layout Subsection
Certainty-Driven Consistency loss for semi-supervised learning
\end_layout

\begin_layout Standard
The recently proposed semi-supervised learning meth-ods exploit consistency
 loss between different predictionsunder random perturbations.
 Typically, a student modelis trained to predict consistently with the targets
 gener-ated by a noisy teacher.
 However, they ignore the fact thatnot all training data provide meaningful
 and reliable in-formation in terms of consistency.
 For misclassified data,blindly minimizing the consistency loss around them
 canhinder learning.
 In this paper, we propose a novel certainty-driven consistency loss (CCL)
 to dynamically select datasamples that have relatively low uncertainty.
 Specifically,we measure the variance or entropy of multiple predictionsunder
 random augmentations and dropout as an estima-tion of uncertainty.
 Then, we introduce two approaches,i.e.
 Filtering CCL and Temperature CCL to guide the stu-dent learn more meaningful
 and certain/reliable targets,and hence improve the quality of the gradients
 backprop-agated to the student.
 Experiments demonstrate the ad-vantages of the proposed method over the
 state-of-the-artsemi-supervised deep learning methods on three benchmarkdataset
s: SVHN, CIFAR10, and CIFAR100.
 Our methodalso shows robustness to noisy labels.
\end_layout

\begin_layout Subsection
Look, Imagine and Match:Improving Textual-Visual Cross-Modal Retrieval with
 Generative Models
\end_layout

\begin_layout Standard
Textual-visual cross-modal retrieval has been a hot re-search topic in both
 computer vision and natural languageprocessing communities.
 Learning appropriate representa-tions for multi-modal data is crucial for
 the cross-modalretrieval performance.
 Unlike existing image-text retrievalapproaches that embed image-text pairs
 as single featurevectors in a common representational space, we propose
 toincorporate generative processes into the cross-modal fea-ture embedding,
 through which we are able to learn not onlythe global abstract features
 but also the local grounded fea-tures.
 Extensive experiments show that our framework canwell match images and
 sentences with complex content, andachieve the state-of-the-art cross-modal
 retrieval results onMSCOCO dataset.
\end_layout

\begin_layout Subsection
FRACTAL NET: ULTRA-DEEP NEURAL NETWORKS WITHOUT RESIDUALS
\end_layout

\begin_layout Standard
We introduce a design strategy for neural network macro-architecture based
 on self-similarity.
 Repeated application of a simple expansion rule generates deep networkswhose
 structural layouts are precisely truncated fractals.
 These networks containinteracting subpaths of different lengths, but do
 not include any pass-through orresidual connections; every internal signal
 is transformed by a filter and nonlinearitybefore being seen by subsequent
 layers.
 In experiments, fractal networks matchthe excellent performance of standard
 residual networks on both CIFAR andImageNet classification tasks, thereby
 demonstrating that residual representationsmay not be fundamental to the
 success of extremely deep convolutional neuralnetworks.
 Rather, the key may be the ability to transition, during training, fromeffectiv
ely shallow to deep.
 We note similarities with student-teacher behavior anddevelop drop-path,
 a natural extension of dropout, to regularize co-adaptation ofsubpaths
 in fractal architectures.
 Such regularization allows extraction of high-performance fixed-depth subnetwor
ks.
 Additionally, fractal networks exhibit ananytime property: shallow subnetworks
 provide a quick answer, while deepersubnetworks, with higher latency, provide
 a more accurate answer.
\end_layout

\begin_layout Subsection
REACHING HUMAN-LEVEL PERFORMANCE IN AUTOMATIC GRAMMATICAL ERROR CORRECTION:
 AN EMPIRICAL STUDY
\end_layout

\begin_layout Standard
Neural sequence-to-sequence (seq2seq) approaches have proven to be successfulin
 grammatical error correction (GEC).
 Based on the seq2seq framework, we pro-pose a novel fluency boost learning
 and inference mechanism.
 Fluency boostinglearning generates diverse error-corrected sentence pairs
 during training, enablingthe error correction model to learn how to improve
 a sentence’s fluency from moreinstances, while fluency boosting inference
 allows the model to correct a sentenceincrementally with multiple inference
 steps.
\end_layout

\begin_layout Subsection
Learning Shared Semantic Space with CorrelationAlignment for Cross-modal
 Event Retrieval
\end_layout

\begin_layout Standard
In this paper, we propose to learn shared semantic space with correlation
 alignment(S3CA) for multimodal data representations, which aligns nonlinear
 correlations of mul-timodal data distributions in deep neural networks
 designed for heterogeneous data.
 Inthe context of cross-modal (event) retrieval, we design a neural network
 with convolu-tional layers and fully-connected layers to extract features
 for images, including images onFlickr-like social media.
 Simultaneously, we exploit a fully-connected neural network toextract semantic
 features for texts, including news articles from news media.
 In particu-lar, nonlinear correlations of layer activations in the two
 neural networks are aligned withcorrelation alignment during the joint
 training of the networks.
 Furthermore, we projectthe multimodal data into a shared semantic space
 for cross-modal (event) retrieval, wherethe distances between heterogeneous
 data samples can be measured directly.
\end_layout

\begin_layout Subsection
Distributed Representations of Sentences and Documents (paragraph vector)
\end_layout

\begin_layout Standard
Many machine learning algorithms require theinput to be represented as a
 fixed-length featurevector.
 When it comes to texts, one of the mostcommon fixed-length features is
 bag-of-words.Despite their popularity, bag-of-words featureshave two major
 weaknesses: they lose the order-ing of the words and they also ignore semantics
of the words.
 For example, “powerful,” “strong”and “Paris” are equally distant.
 In this paper, weproposeParagraph Vector, an unsupervised algo-rithm that
 learns fixed-length feature representa-tions from variable-length pieces
 of texts, such assentences, paragraphs, and documents.
 Our algo-rithm represents each document by a dense vec-tor which is trained
 to predict words in the doc-ument.
 Its construction gives our algorithm thepotential to overcome the weaknesses
 of bag-of-words models.
\end_layout

\begin_layout Subsection
Taskonomy: Disentangling Task Transfer Learning
\end_layout

\begin_layout Standard
Do visual tasks have a relationship, or are they unre-lated? For instance,
 could having surface normals sim-plify estimating the depth of an image?
 Intuition answersthese questions positively, implying existence of astructuream
ong visual tasks.
 Knowing this structure has notable val-ues; it is the concept underlying
 transfer learning and pro-vides a principled way for identifying redundancies
 acrosstasks, e.g., to seamlessly reuse supervision among relatedtasks or
 solve many tasks in one system without piling upthe complexity.
 We proposes a fully computational approach for model-ing the structure
 of space of visual tasks.
 This is done viafinding (first and higher-order) transfer learning dependen-cie
s across a dictionary of twenty six 2D, 2.5D, 3D, andsemantic tasks in a
 latent space.
\end_layout

\begin_layout Subsection
Deep Learning of Graph Matching
\end_layout

\begin_layout Standard
The problem of graph matching under node and pair-wise constraints is fundamenta
l in areas as diverse as com-binatorial optimization, machine learning or
 computer vi-sion, where representing both the relations between nodesand
 their neighborhood structure is essential.
 We present anend-to-end model that makes it possible to learn all param-eters
 of the graph matching process, including the unaryand pairwise node neighborhoo
ds, represented as deep fea-ture extraction hierarchies.
\end_layout

\begin_layout Subsection
One shot learning of simple visual concepts
\end_layout

\begin_layout Standard
People can learn visual concepts from just one example, butit remains a
 mystery how this is accomplished.
 Many authorshave proposed that transferred knowledge from more familiarconcepts
 is a route to one shot learning, but what is the formof this abstract knowledge
? One hypothesis is that the shar-ing of parts is core to one shot learning,
 and we evaluate thisidea in the domain of handwritten characters, using
 a massivenew dataset.
 These simple visual concepts have a rich inter-nal part structure, yet
 they are particularly tractable for com-putational models.
 We introduce a generative model of howcharacters are composed from strokes,
 where knowledge fromprevious characters helps to infer the latent strokes
 in novelcharacters.
 The stroke model outperforms a competing state-of-the-art character model
 on a challenging one shot learningtask, and it provides a good fit to human
 perceptual data.
\end_layout

\begin_layout Subsection
Concept learning as motor program induction: A large-scale empirical study
\end_layout

\begin_layout Standard
Human concept learning is particularly impressive in two re-spects: the
 internal structure of concepts can be representation-ally rich, and yet
 the very same concepts can also be learnedfrom just a few examples.
 Several decades of research havedramatically advanced our understanding
 of these two aspectsof concepts.
 While the richness and speed of concept learn-ing are most often studied
 in isolation, the power of humanconcepts may be best explained through
 their synthesis.
 Thispaper presents a large-scale empirical study of one-shot con-cept learning,
 suggesting that rich generative knowledge in theform of a motor program
 can be induced from just a singleexample of a novel concept.
\end_layout

\begin_layout Subsection
Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement
 Learning (Learn RL)
\end_layout

\begin_layout Standard
TODO
\end_layout

\begin_layout Subsection
PIXELCNN++: IMPROVING THE PIXEL CNN WITH DISCRETIZED LOGISTIC MIXTURE LIKELIHOOD
 AND OTHER MODIFICATIONS
\end_layout

\begin_layout Standard
PixelCNNs are a recently proposed class of powerful generative models withtracta
ble likelihood.
 Ourimplementation contains a number of modifications to the original model
 that bothsimplify its structure and improve its performance.
 1) We use a discretized logisticmixture likelihood on the pixels, rather
 than a 256-way softmax, which we find tospeed up training.
 2) We condition on whole pixels, rather than R/G/B sub-pixels,simplifying
 the model structure.
 3) We use downsampling to efficiently capturestructure at multiple resolutions.
 4) We introduce additional short-cut connec-tions to further speed up optimizat
ion.
 5) We regularize the model using dropout.Finally, we present state-of-the-art
 log likelihood results on CIFAR-10 to demon-strate the usefulness of these
 modifications.
\end_layout

\begin_layout Subsection
Convolutional Sequence to Sequence Learning
\end_layout

\begin_layout Standard
The prevalent approach to sequence to sequencelearning maps an input sequence
 to a variablelength output sequence via recurrent neural net-works.
 We introduce an architecture based en-tirely on convolutional neural networks.1C
om-pared to recurrent models, computations over allelements can be fully
 parallelized during trainingto better exploit the GPU hardware and optimiza-tio
n is easier since the number of non-linearitiesis fixed and independent
 of the input length.
 Ouruse of gated linear units eases gradient propaga-tion and we equip each
 decoder layer with a sep-arate attention module.
\end_layout

\begin_layout Subsection
Neural Machine Translation in Linear Time
\end_layout

\begin_layout Standard
We present a novel neural network for process-ing sequences.
 The ByteNet is a one-dimensionalconvolutional neural network that is composed
 oftwo parts, one to encode the source sequence andthe other to decode the
 target sequence.
 The twonetwork parts are connected by stacking the de-coder on top of the
 encoder and preserving thetemporal resolution of the sequences.
 To ad-dress the differing lengths of the source and thetarget, we introduce
 an efficient mechanism bywhich the decoder is dynamically unfolded overthe
 representation of the encoder.
 The ByteNetuses dilation in the convolutional layers to in-crease its receptive
 field.
 The resulting networkhas two core properties: it runs in time thatis linear
 in the length of the sequences and itsidesteps the need for excessive memorizat
ion.
\end_layout

\begin_layout Subsection
Conditional Image-Text Embedding Networks
\end_layout

\begin_layout Standard
This paper presents an approach for grounding phrases inimages which jointly
 learns multiple text-conditioned embeddings in asingle end-to-end model.
 In order to differentiate text phrasesinto seman-tically distinct subspaces,
 we propose a concept weight branch that auto-matically assigns phrases
 to embeddings, whereas prior works predefinesuch assignments.
\end_layout

\begin_layout Subsection
Conditional Image Generation withPixelCNN Decoders
\end_layout

\begin_layout Standard
This work explores conditional image generation with a new image density
 modelbased on the PixelCNN architecture.
 The model can be conditioned on any vector,including descriptive labels
 or tags, or latent embeddings created by other networks.
\end_layout

\begin_layout Subsection
Stacked Attention Networks for Image Question Answering
\end_layout

\begin_layout Standard
This paper presents stacked attention networks (SANs)that learn to answer
 natural language questions from im-ages.
 SANs use semantic representation of a question asquery to search for the
 regions in an image that are relatedto the answer.
 We argue that image question answering(QA) often requires multiple steps
 of reasoning.
 Thus, wedevelop a multiple-layer SAN in which we query an imagemultiple
 times to infer the answer progressively.
\end_layout

\begin_layout Subsection
MAttNet: Modular Attention Network for Referring Expression Comprehension
\end_layout

\begin_layout Standard
In this paper, we address referring expression compre-hension: localizing
 an image region described by a natu-ral language expression.
 While most recent work treats ex-pressions as a single unit, we propose
 to decompose theminto three modular components related to subject appear-ance,
 location, and relationship to other objects.
 This al-lows us to flexibly adapt to expressions containing differ-ent
 types of information in an end-to-end framework.
\end_layout

\begin_layout Subsection
Parallel Attention: A Unified Framework for Visual Object Discovery through
 Dialogs and Queries
\end_layout

\begin_layout Standard
Recognising objects according to a pre-defined fixed setof class labels
 has been well studied in the Computer Vision.There are a great many practical
 applications where thesubjects that may be of interest are not known beforehand
,or so easily delineated, however.
 In many of these cases nat-ural language dialog is a natural way to specify
 the subjectof interest, and the task achieving this capability (a.k.a, Re-ferring
 Expression Comprehension) has recently attractedattention.
 To this end we propose a unified framework, theParalleL AttentioN (PLAN)
 network, to discover the objectin an image that is being referred to in
 variable length nat-ural expression descriptions, from short phrases query
 tolong multi-round dialogs.
\end_layout

\begin_layout Subsection
Dual-Path Convolutional Image-Text Embeddings with Instance Loss
\end_layout

\begin_layout Standard
Matching images and sentences demands a fineunderstanding of both modalities.
 In this paper, we propose anew system to discriminatively embed the image
 and text toa shared visual-textual space.
 In this field, most existing worksapply the ranking loss to pull the positive
 image / text pairs closeand push the negative pairs apart from each other.
 However,directly deploying the ranking loss is hard for network learning,since
 it starts from the two heterogeneous features to buildinter-modal relationship.
 To address this problem, we proposethe instance loss which explicitly considers
 the intra-modal datadistribution.
 It is based on an unsupervised assumption that eachimage / text group can
 be viewed as a class.
 So the networkcan learn the fine granularity from every image/text group.
 Theexperiment shows that the instance loss offers better weightinitialization
 for the ranking loss, so that more discriminativeembeddings can be learned.
 Besides, existing works usually applythe off-the-shelf features,i.e., word2vec
 and fixed visual feature.So in a minor contribution, this paper constructs
 an end-to-end dual-path convolutional network to learn the image andtext
 representations.
\end_layout

\begin_layout Subsection
Look, Imagine and Match:Improving Textual-Visual Cross-Modal Retrieval with
 Generative Models
\end_layout

\begin_layout Standard
Unlike existing image-text retrievalapproaches that embed image-text pairs
 as single featurevectors in a common representational space, we propose
 toincorporate generative processes into the cross-modal fea-ture embedding,
 through which we are able to learn not onlythe global abstract features
 but also the local grounded fea-tures.
\end_layout

\begin_layout Subsection
Error-Correcting Output Codes (ECOC)
\end_layout

\begin_layout Standard
http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/lecture_notes/ecoc/ecoc.pd
f
\end_layout

\begin_layout Standard
Error-CorrectingOutputCodingforTextClassification: http://www.cs.cmu.edu/~aberger/p
df/ecoc.pdf
\end_layout

\begin_layout Standard
WhyErrorCorrectingOutputCodingWorks: http://web.engr.oregonstate.edu/~tgd/publicati
ons/ecc-why-draft-1994.pdf
\end_layout

\begin_layout Standard
Learning ECOC Code Matrix for Multiclass Classification with Application
 to Glaucoma Diagnosis: https://link.springer.com/article/10.1007/s10916-016-0436-2
\end_layout

\begin_layout Subsection
How to Choose an Activation Function (NIPS)
\end_layout

\begin_layout Standard
Our general theorem shows that the smoother the activation function, the
 better the rate of approximation.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-1"

\end_inset

 Jeff Dean.
 Large-Scale Deep Learning for Intelligent Computer Systems (Slides).
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-2"

\end_inset

 sequence to sequence learning with neural networks
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-3"

\end_inset

 addressing rare world problems in neural translation models
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-4"

\end_inset

 grammar as a foreign language
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-5"

\end_inset

 pointer networks
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-6"

\end_inset

 show and tell
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ad-ex-speech-0"
literal "false"

\end_inset

 Audio Adversarial Examples: Targeted Attacks on Speech-to-Text
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ad-ex-image-0"
literal "false"

\end_inset

 Intriguing properties of neural networks
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ad-ex-image-1"
literal "false"

\end_inset

 Adversar-ial examples in the physical world.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ad-ex-speech-1"
literal "false"

\end_inset

 Adversarial attacks against automatic speech recogni-tion systems via psychoaco
ustic hiding.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "lingvo"
literal "false"

\end_inset

 Lingvo: a modular and scalable framework for sequence-to-sequence modeling.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ad-ex-0"
literal "false"

\end_inset

 Evasion attacksagainst machine learning at test time.
\end_layout

\end_body
\end_document
