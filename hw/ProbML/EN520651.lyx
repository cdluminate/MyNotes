#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage[margin=1in]{geometry}
%\usepackage{indentfirst}
%\setlength{\parindent}{0pt}
\usepackage{bm}
\usepackage{times}
\newcommand{\pperp}{\perp\kern-5pt\perp}
\usepackage{tikz}
\usetikzlibrary[arrows,shapes,snakes,backgrounds,bayesnet]
\usepackage{accents}
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}
\end_preamble
\options a4
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "newtxmath" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype true
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard

\series bold
EN 520.651 Probablistic Machine Learning
\end_layout

\begin_layout Section
Probability Review
\end_layout

\begin_layout Subsection
Probablistic Models
\end_layout

\begin_layout Standard
\begin_inset Formula $\Omega$
\end_inset

: sample space;
\end_layout

\begin_layout Standard
\begin_inset Formula $A$
\end_inset

: event;
\end_layout

\begin_layout Standard
\begin_inset Formula $P(A)$
\end_inset

: probability measure, non-negative;
\end_layout

\begin_layout Subsection
Sample Space
\end_layout

\begin_layout Standard
EX: single roll of dice 
\begin_inset Formula $\Omega=\{1,2,3,4,5,6\}$
\end_inset

.
\end_layout

\begin_layout Subsection
Events
\end_layout

\begin_layout Standard
An event 
\begin_inset Formula $A$
\end_inset

 is a set of outcomes.
\end_layout

\begin_layout Standard
The boundary case is 
\begin_inset Formula $\Omega$
\end_inset

 (certain set) and 
\begin_inset Formula $\phi$
\end_inset

 (null set).
\end_layout

\begin_layout Standard

\bar under
Venn Diagrams to visualize basic set operations.
\end_layout

\begin_layout Standard
(1) Union 
\begin_inset Formula $A\cup B$
\end_inset


\end_layout

\begin_layout Standard
(2) Intersection: 
\begin_inset Formula $A\cap B$
\end_inset


\end_layout

\begin_layout Standard
(3) Complement: 
\begin_inset Formula $A^{C}$
\end_inset


\end_layout

\begin_layout Standard
(4) Disjoint: 
\begin_inset Formula $A\cap B=\phi$
\end_inset


\end_layout

\begin_layout Standard

\bar under
Set Algebra
\end_layout

\begin_layout Standard
(1) 
\begin_inset Formula $(A\cup B)^{C}=A^{C}\cap B^{C}$
\end_inset


\end_layout

\begin_layout Standard
(2) 
\begin_inset Formula $(A\cap B)^{C}=A^{C}\cup B^{C}$
\end_inset


\end_layout

\begin_layout Standard
(3) 
\begin_inset Formula $A\cup(B\cup C)=(A\cup B)\cup C$
\end_inset


\end_layout

\begin_layout Standard
(4) 
\begin_inset Formula $A\cup(B\cap C)=(A\cup B)\cap(A\cup C)$
\end_inset


\end_layout

\begin_layout Subsection
Sigma Fields
\end_layout

\begin_layout Standard
Given a sample space 
\begin_inset Formula $\Omega$
\end_inset

 and events 
\begin_inset Formula $E,F$
\end_inset

, the colection of subsets of 
\begin_inset Formula $\Omega$
\end_inset

, defined as 
\begin_inset Formula $M$
\end_inset

, forms a field if (1) 
\begin_inset Formula $\phi\in M$
\end_inset

, 
\begin_inset Formula $\Omega\in M$
\end_inset

; (2) If 
\begin_inset Formula $E,F\in M$
\end_inset

, then 
\begin_inset Formula $E\cup F\in M$
\end_inset

 and 
\begin_inset Formula $E\cap F\in M$
\end_inset

; (3) If 
\begin_inset Formula $E\in M$
\end_inset

, then 
\begin_inset Formula $E^{C}\in M$
\end_inset

.
\end_layout

\begin_layout Standard
A sigma field is closed under a countable number of unions, intersections,
 and complements.
\end_layout

\begin_layout Standard
We care about fields and sigma fields because of consistency.
 When 
\begin_inset Formula $P(E)$
\end_inset

 and 
\begin_inset Formula $P(F)$
\end_inset

 are defined, but not 
\begin_inset Formula $P(E\cap F)$
\end_inset

, then the rule will be broken.
\end_layout

\begin_layout Standard

\bar under
EX: Toss a coin once, find 
\begin_inset Formula $\Omega$
\end_inset

 and 
\begin_inset Formula $\mathcal{F}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\Omega=\{H,T\}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\mathcal{F}=\{\phi,\Omega,H,T\}$
\end_inset


\end_layout

\begin_layout Standard

\bar under
Strategy for the smallest 
\begin_inset Formula $\sigma$
\end_inset

-field
\end_layout

\begin_layout Standard
(1) Include 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\Omega$
\end_inset


\end_layout

\begin_layout Standard
(2) Include disjoint parts
\end_layout

\begin_layout Standard
(3) Include all pairs, triplets, quadruplets, etc
\end_layout

\begin_layout Standard
Alternative strategy: use a binary mask, and the size of the set would be
 
\begin_inset Formula $2^{N}$
\end_inset

.
\end_layout

\begin_layout Subsection
Axioms of Probability
\end_layout

\begin_layout Standard
Set function 
\begin_inset Formula $P:E\in\mathcal{F}\mapsto P(E)\in\mathbb{R}^{+}$
\end_inset

.
\end_layout

\begin_layout Standard
(1) 
\begin_inset Formula $P(E)\geq0$
\end_inset


\end_layout

\begin_layout Standard
(2) 
\begin_inset Formula $P(\Omega)=1$
\end_inset

 – normalization
\end_layout

\begin_layout Standard
(3) 
\begin_inset Formula $P(E\cup F)=P(E)+P(F),\forall E,F\in\Omega,s.t.E\cap F=\phi$
\end_inset


\end_layout

\begin_layout Standard
Then we can establish
\end_layout

\begin_layout Standard
(4) 
\begin_inset Formula $P(\phi)=0$
\end_inset


\end_layout

\begin_layout Standard
(5) 
\begin_inset Formula $P(E)=1-P(E^{C})$
\end_inset


\end_layout

\begin_layout Standard
(6) 
\begin_inset Formula $P(E\cup F)=P(E)+P(F)-P(E\cap F)$
\end_inset


\end_layout

\begin_layout Standard
(7) 
\begin_inset Formula $P(\cap_{i=1}^{n}E_{i})\leq\sum_{i=1}^{n}P(E_{i})$
\end_inset


\end_layout

\begin_layout Subsection
Relationship Between Events
\end_layout

\begin_layout Standard
Joint probability 
\begin_inset Formula $P(A\cap B)$
\end_inset


\end_layout

\begin_layout Standard
Conditional probability 
\begin_inset Formula $P(B|A)=P(A\cap B)/P(A)$
\end_inset


\end_layout

\begin_layout Standard
– 
\begin_inset Formula $P(B|A)P(A)=P(A|B)P(B)$
\end_inset


\end_layout

\begin_layout Standard
Two events 
\begin_inset Formula $A\in\mathcal{F}$
\end_inset

and 
\begin_inset Formula $B\in\mathcal{F}$
\end_inset

are 
\bar under
independent
\bar default
 if 
\begin_inset Formula $P(A\cap B)=P(A)P(B)$
\end_inset

 for 
\begin_inset Formula $P(A)>0$
\end_inset

 and 
\begin_inset Formula $P(B)>0$
\end_inset

.
\end_layout

\begin_layout Standard
Three events 
\begin_inset Formula $A,B,C$
\end_inset

 (non-zero probability) are 
\bar under
jointly independent
\bar default
 if
\end_layout

\begin_layout Standard
(1) 
\begin_inset Formula $P(A\cap B)=P(A)P(B)$
\end_inset

 – all pairwise combinations alike
\end_layout

\begin_layout Standard
(2) 
\begin_inset Formula $P(A\cap B\cap C)=P(A)P(B)P(C)$
\end_inset

 – mutual
\end_layout

\begin_layout Standard

\bar under
Independent Experiments
\bar default
: the outcome of one experiment is not affected by the past, present, or
 future values of the other experiment.
\end_layout

\begin_layout Subsection
Bayes Rule
\end_layout

\begin_layout Standard
Total Probability: Let 
\begin_inset Formula $A_{i}$
\end_inset

(
\begin_inset Formula $i=1,\ldots,n)$
\end_inset

 be mutually exclusive and exhaustive w/ nonzero probability, for all 
\begin_inset Formula $B\in\Omega$
\end_inset

, we can write
\begin_inset Formula 
\[
P(B)=\sum_{i=1}^{n}P(A_{i})P(B|A_{i})
\]

\end_inset


\end_layout

\begin_layout Standard
Bayes Rule: Given the above setup and 
\begin_inset Formula $P(B)>0$
\end_inset


\begin_inset Formula 
\[
P(A_{j}|B)=\frac{P(A_{j}\cap B)}{P(B)}=\frac{P(A_{j})P(B|A_{j})}{\sum_{i=1}^{n}P(A_{i})P(B|A_{i})}
\]

\end_inset

where 
\begin_inset Formula $P(A_{i})$
\end_inset

 is 
\begin_inset Quotes eld
\end_inset

prior
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Formula $P(B|A_{i})$
\end_inset

 is 
\begin_inset Quotes eld
\end_inset

likelihood
\begin_inset Quotes erd
\end_inset

, and 
\begin_inset Formula $P(A_{i}|B)$
\end_inset

 is posterior.
\end_layout

\begin_layout Section
Random Variables
\end_layout

\begin_layout Standard
A random variable 
\begin_inset Formula $X(\cdot)$
\end_inset

 is a function that maps every outcome 
\begin_inset Formula $\omega\in\Omega$
\end_inset

 onto the real number line 
\begin_inset Formula $X(\omega)\in\mathbb{R}$
\end_inset

.
 Namely 
\begin_inset Formula $X:\Omega\mapsto\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Subsection
Cumulative Distribution Function
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
F_{X}(x)=P(\omega\in\Omega|X(\omega)\leq x)\triangleq P(X\leq x)
\]

\end_inset


\end_layout

\begin_layout Standard
(1) 
\begin_inset Formula $F_{X}(-\infty)=P(\phi)=0$
\end_inset

, 
\begin_inset Formula $F_{X}(+\infty)=P(\phi)=1$
\end_inset


\end_layout

\begin_layout Standard
(2) 
\begin_inset Formula $x_{1}\leq x_{2}$
\end_inset

, 
\begin_inset Formula $F_{X}(x_{1})<F_{X}(x_{2})$
\end_inset


\end_layout

\begin_layout Standard
(3) 
\begin_inset Formula $F_{X}(x)=\lim_{\epsilon\rightarrow0^{+}}F_{X}(x+\epsilon)$
\end_inset


\end_layout

\begin_layout Standard
Implication: 
\begin_inset Formula $P(a<X\leq b)=F_{X}(b)-F_{X}(a)$
\end_inset


\end_layout

\begin_layout Subsection
Probability Density Function
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f_{X}(x)=\frac{d}{dx}F_{X}(x)
\]

\end_inset


\end_layout

\begin_layout Standard
(1) 
\begin_inset Formula $f_{X}(x)\geq0$
\end_inset


\end_layout

\begin_layout Standard
(2) 
\begin_inset Formula $\int_{-\infty}^{\infty}f_{X}(\xi)d\xi=F_{X}(\infty)-F_{X}(-\infty)=1$
\end_inset


\end_layout

\begin_layout Standard
(3) 
\begin_inset Formula $F_{X}(x)=\int_{-\infty}^{x}f_{X}(\xi)d\xi=P(X\leq x)$
\end_inset


\end_layout

\begin_layout Standard
(4) 
\begin_inset Formula $\int_{x_{1}}^{x_{2}}f_{X}(\xi)d\xi=F_{X}(x_{2})-F_{X}(x_{1})=P(x_{1}<X\leq x_{2})$
\end_inset


\end_layout

\begin_layout Subsection
Useful Distributions
\end_layout

\begin_layout Standard
(1) Normal 
\begin_inset Formula $X\sim\mathcal{N}(x;\mu,\sigma^{2})$
\end_inset

 (Continuous RV)
\begin_inset Formula 
\[
f_{X}(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\{-\frac{1}{2\sigma^{2}}(x-\mu)^{2}\}
\]

\end_inset


\end_layout

\begin_layout Standard
(2) Uniform 
\begin_inset Formula $X\sim Unf(x;[a,b])$
\end_inset

 (Continuous)
\begin_inset Formula 
\[
f_{X}(x)=\frac{1}{b-a}\mathbb{I}\{x\in[a,b]\}+0\mathbb{I}\{x\notin[a,b]\}
\]

\end_inset


\end_layout

\begin_layout Standard
(3) Exponential 
\begin_inset Formula $X\sim Exp(x;\lambda)$
\end_inset

 (Continuous, Sometimes use 
\begin_inset Formula $\lambda=1/\mu$
\end_inset

)
\begin_inset Formula 
\[
f_{X}(x)=\lambda e^{-\lambda x}u(x)
\]

\end_inset


\end_layout

\begin_layout Standard
(4) Bernoulli 
\begin_inset Formula $X\sim B(x;p)$
\end_inset

 (discrete RV)
\begin_inset Formula 
\[
f_{X}(x)=p^{x}(1-p)^{1-x}
\]

\end_inset


\end_layout

\begin_layout Standard
(5) Poisson 
\begin_inset Formula $X\sim Poisson(x;\mu)$
\end_inset

 (discrete)
\begin_inset Formula 
\[
f_{X}(x)=\frac{\mu^{x}}{x!}e^{-\mu},x=0,1,2,\ldots
\]

\end_inset


\end_layout

\begin_layout Subsection
Mixed Random Variables
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(X=x)=\lim_{e\rightarrow0^{+}}\int_{x}^{x+e}f_{X}(\xi)d\xi
\]

\end_inset

 The above value is generally zero for continuous RV.
 When we need nonzero mass at 
\begin_inset Formula $x=x_{0}$
\end_inset

, we can use a Dirac delta 
\begin_inset Formula $\delta(x-x_{0})$
\end_inset

.
\end_layout

\begin_layout Section
Functions of Random Variables
\end_layout

\begin_layout Section
Moment Generating Functions
\end_layout

\begin_layout Section
Random Vectors
\end_layout

\begin_layout Section
Bayesian Hypothesis Testing
\end_layout

\begin_layout Section
NonBayesian Hypothesis Testing
\end_layout

\begin_layout Section
Minmax Decision Theory
\end_layout

\begin_layout Section
Bayesian Parameter Estimation
\end_layout

\begin_layout Subsection
Problem Setting
\end_layout

\begin_layout Itemize
Hidden parameter 
\begin_inset Formula $X\in\mathcal{X}$
\end_inset

 is continuous (random variable);
\end_layout

\begin_layout Itemize
Noisy observation 
\begin_inset Formula $Y\in\mathcal{Y}$
\end_inset

 can be either continuous or discrete;
\end_layout

\begin_layout Itemize
Prior belief 
\begin_inset Formula $P_{X}(x)$
\end_inset

;
\end_layout

\begin_layout Itemize
Likelihood (observation model) 
\begin_inset Formula $P_{Y|X}(y|x)$
\end_inset

;
\end_layout

\begin_layout Standard
The goal is to construct an estimator 
\begin_inset Formula $\hat{x}(\cdot)$
\end_inset

 that produces an estimate of 
\begin_inset Formula $x$
\end_inset

 given the observation 
\begin_inset Formula $Y=y$
\end_inset

.
 Similar to Bayesian HY, an objective criterion 
\begin_inset Formula $C(a,\hat{a)}$
\end_inset

 is required to build and evaluate this estimator, so
\begin_inset Formula 
\begin{align*}
\hat{x}(\cdot) & =\arg\min_{f(\cdot)}E_{XY}[\tilde{C}(X,f(Y))]\\
 & =\arg\min_{a}\int_{-\infty}^{\infty}C(x,a)P_{X|Y}(x|y)dx\\
 & =\arg\min_{a}E_{X|Y}[C(X,a)|Y=y]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The posterior belief summarizes everything we need to know to construct
 any estimator, because 
\begin_inset Formula $P_{X|Y}(x|y)=[P_{X}P_{Y|X}/P_{Y}]$
\end_inset

.
\end_layout

\begin_layout Subsection
Minimum Absolute Error (MAE)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(a,\hat{a})=|a-\hat{a}|
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{x}_{MAE}(y)=\arg\min_{a}\int_{-\infty}^{\infty}|x-a|P_{X|Y}(x|y)dx
\]

\end_inset


\end_layout

\begin_layout Standard
After expanding the integral, we let the derivative of the internal part
 be zero.
 Then we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Rightarrow\int_{-\infty}^{a}P_{X|Y}(x|y)dx-\int_{a}^{\infty}P_{X|Y}(x|y)dx=0
\]

\end_inset


\end_layout

\begin_layout Standard
This means 
\begin_inset Formula $\hat{x}_{MAE}(y)$
\end_inset

 is the MEDIAN of 
\begin_inset Formula $P_{X|Y}$
\end_inset

.
 The solution is not always unique.
\end_layout

\begin_layout Subsection
Minimum Uniform Cost
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(a,\hat{a})=\mathbf{1}\{|a-\hat{a}|>\epsilon\}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{x}_{MUC}(y)=\arg\max_{a}\int_{a-\epsilon}^{a+\epsilon}P_{X|Y}(x|y)dx
\]

\end_inset


\end_layout

\begin_layout Standard
The 
\begin_inset Formula $\hat{x}_{MUC}(y)$
\end_inset

 is the center of the 
\begin_inset Formula $2\epsilon$
\end_inset

 interval with the most mass of 
\begin_inset Formula $P_{X|Y}$
\end_inset

.
 When 
\begin_inset Formula $\epsilon$
\end_inset

 tends to zero, MUC is defined as the MAP estimator,
\begin_inset Formula 
\[
\lim_{\epsilon\rightarrow0}\hat{x}_{MUC}(y)=\arg\max_{a}P_{X|Y}(x|y)\triangleq\hat{x}_{MAP}(y)
\]

\end_inset


\end_layout

\begin_layout Subsection
Bayes Least Squares
\end_layout

\begin_layout Standard
This is the most commonly used estinator.
 We use the vector version here:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(\hm{a},\hat{\hm{a}})=\|\hm{a}-\hat{\hm{a}}\|=(a-\hat{a})^{T}(a-\hat{a})
\]

\end_inset


\end_layout

\begin_layout Standard
We plug the cost into the optimization problem, the derive the internal
 part and letting the derivative be zero, and obtain
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\hm{x}}_{BLS}(\hm{y})=\int_{-\infty}^{\infty}xP_{X|Y}dx=E[\hm{X}|\bm{y}]
\]

\end_inset


\end_layout

\begin_layout Subsection
Performance Characeteristics
\end_layout

\begin_layout Standard
In this subsection we use vector by default.
\end_layout

\begin_layout Itemize
Error.
 Given an instance 
\begin_inset Formula $x$
\end_inset

,
\begin_inset Formula 
\[
e(x,y)=\hat{x}(y)-x
\]

\end_inset


\end_layout

\begin_layout Itemize
Bias
\begin_inset Formula 
\[
b=E_{XY}[e(x,y)]=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e(x,y)P_{x,y}dxdy
\]

\end_inset


\end_layout

\begin_layout Itemize
Variance
\begin_inset Formula 
\[
\Lambda_{e}=E_{xy}\{[e(x,y)-b][e(x,y)-b]^{T}\}
\]

\end_inset


\begin_inset Formula 
\[
MSE=E_{xy}[e(x,y)e(x,y)^{T}]=\Lambda_{e}+bb^{T}
\]

\end_inset


\end_layout

\begin_layout Section
Linear Least Squares Estimation
\end_layout

\begin_layout Section
NonBayesian Parameter Estimation
\end_layout

\begin_layout Subsection
Maximum Likelihood Estimation
\end_layout

\begin_layout Standard
Convenient proxy for efficient estimator with nice properties.
\begin_inset Formula 
\[
\hat{x}_{ML}(y)=\arg\max_{x\in\mathcal{X}}P_{Y}(y;x)
\]

\end_inset


\end_layout

\begin_layout Standard
The ML estimator is simpler to compute or numerically approximate.
 Meanwhile, it is intuitive because picking 
\begin_inset Formula $x$
\end_inset

 that gives you the largest chance of observing the data 
\begin_inset Formula $Y=y$
\end_inset

.
\end_layout

\begin_layout Subsection
Vector Parameters
\end_layout

\begin_layout Subsection
Exponential Families
\end_layout

\begin_layout Subsection
Directed Graphical Models
\end_layout

\begin_layout Standard
Defines a family of joint probability distributions over set of RVs.
 The setup if Directed Acyclic Graph 
\begin_inset Formula $\mathcal{G}(\mathcal{V},\mathcal{E})$
\end_inset

 with nodes (RVs) and edges.
 For each node 
\begin_inset Formula $i\in\mathcal{V}$
\end_inset

, let 
\begin_inset Formula $\pi_{i}$
\end_inset

 be the set of parent nodes.
 Then the family of distributions satisfy 
\begin_inset Formula $P_{X}(x_{1},\ldots,x_{n})=\prod_{i=1}^{n}P_{X}(x_{i}|x_{\pi_{i}})$
\end_inset

.
 In this graph, absenceof edge means conditional independence.
\end_layout

\begin_layout Standard

\series bold
Bayes' Ball Algorithm.

\series default
 It determines conditional independence given obserations.
 Examine whether 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 are marginally independent 
\begin_inset Formula $p(x,z)=p(x)p(z)$
\end_inset

, or conditionally independent 
\begin_inset Formula $p(x,z|y)=p(x|y)p(z|y)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of X] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Y] (Z) {$Z$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (Y) -- (Z);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Can pass through $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[obs,right=of X] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Y] (Z) {$Z$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (Y) -- (Z);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Blocked at $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of X,yshift=0.2cm] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Y,yshift=-0.2cm] (Z) {$Z$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (Y) -- (Z);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Can pass through $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[obs,right=of X,yshift=0.2cm] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Y,yshift=-0.2cm] (Z) {$Z$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (Y) -- (Z);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Blocked at $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of X,yshift=-0.2cm] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Y,yshift=0.2cm] (Z) {$Z$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (Y) -- (Z);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Blocked at $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[obs,right=of X,yshift=-0.2cm] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Y,yshift=0.2cm] (Z) {$Z$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[->] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (Y) -- (Z);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Can pass through $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (Z) {?};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Z] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of X] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[<->] (Z) -- (X);
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (Y) -- (X);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Ball stops at leaf $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (Z) {?};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of Z] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[obs,right=of X] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[<->] (Z) -- (X);
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (Y) -- (X);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Ball bounces back at $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[latent,right=of X] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Ball bounces back at root $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (X) {$X$};
\end_layout

\begin_layout Plain Layout


\backslash
node[obs,right=of X] (Y) {$Y$};
\end_layout

\begin_layout Plain Layout


\backslash
draw[<-] (X) -- (Y);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

~ Ball stops at root $Y$.
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Plate Notation.
 
\series default
See 
\begin_inset CommandInset href
LatexCommand href
name "wikipedia."
target "https://en.wikipedia.org/wiki/Plate_notation"
literal "false"

\end_inset

 Circles: random variable; Squares: non-random parameters.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[thick]
\end_layout

\begin_layout Plain Layout


\backslash
node[latent] (Xk) {$X_k$};
\end_layout

\begin_layout Plain Layout


\backslash
node[obs,below=of Xk] (Ynk) {$Y_{nk}$};
\end_layout

\begin_layout Plain Layout


\backslash
node[const,right=of Xk] (tx) {$
\backslash
theta_x$};
\end_layout

\begin_layout Plain Layout


\backslash
node[const,right=of Ynk] (ty) {$
\backslash
theta_y$};
\end_layout

\begin_layout Plain Layout


\backslash
plate {p1} {(Ynk)} {N};
\end_layout

\begin_layout Plain Layout


\backslash
plate {p2} {(Xk)(p1)} {K};
\end_layout

\begin_layout Plain Layout


\backslash
draw[->,>=latex] (Xk) -- (Ynk);
\end_layout

\begin_layout Plain Layout


\backslash
draw[->,>=latex] (tx) -- (Xk);
\end_layout

\begin_layout Plain Layout


\backslash
draw[->,>=latex] (ty) -- (Ynk);
\end_layout

\begin_layout Plain Layout


\backslash
node[right=of tx,align=left] (a1) {$p(x_
\backslash
cdot,y_
\backslash
cdot)$
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

$=
\backslash
prod_k [p_X(x_k;
\backslash
theta_k)$
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

$
\backslash
prod_n p_{Y|X}(y_{nk}|x_k;
\backslash
theta_y)]$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}%
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Mixture Models
\end_layout

\begin_layout Standard

\series bold
K-Means.

\series default
 Centroid of 
\begin_inset Formula $k$
\end_inset

-th cluster 
\begin_inset Formula $\mu_{k}$
\end_inset

.
 Cluster assignment of the 
\begin_inset Formula $n$
\end_inset

-th point 
\begin_inset Formula $Z_{n}\in\{1,\ldots,K\}$
\end_inset

.
 We define 
\begin_inset Formula $\ubar{Z}_{n}=[Z_{n}^{1},\ldots,Z_{n}^{k}]$
\end_inset

 as binary indicator vector.
 (1) Given centroids, we can assign clusters as 
\begin_inset Formula $Z_{n}^{k}=\bm{1}\{k=\arg\min_{k'}\|y_{n}-\mu_{k'}\|\}$
\end_inset

.
 (2) Given assignments, we compute the centroids as 
\begin_inset Formula $\mu_{k}=(\sum_{n}Z_{n}^{k}y_{n})/\sum_{n}Z_{n}^{k}$
\end_inset

.
 In this algorithm, we are actually doing coordinate descent to minimize
 the L2 objective 
\begin_inset Formula $J=\sum_{n}\sum_{k}Z_{n}^{k}\|y_{n}-\mu_{k}\|^{2}$
\end_inset

.
 This leads to solution to a Gaussian mixture model w/ equal variances.
\end_layout

\begin_layout Standard
Mixture Model.
 Observe i.i.d.
 scalars 
\begin_inset Formula $Y_{1},\ldots,Y_{N}$
\end_inset

.
 Then 
\begin_inset Formula $P_{Y}(Y_{1},\ldots,Y_{N}|\theta)=\prod_{n}\sum_{k}\pi_{k}p_{k}(y_{n};\theta_{k})$
\end_inset

.
 Goal is to find ML parameter estimates for 
\begin_inset Formula $\pi_{k}$
\end_inset

 and 
\begin_inset Formula $\theta_{k}$
\end_inset

.
 The log likelihood is 
\begin_inset Formula $\ell(\ubar Y,\theta)=\sum_{n}\log(\sum_{k}\pi_{k}p_{k}(y_{n};\theta_{k}))$
\end_inset

.
 This is not easy to optimize.
 We introduce auxilliary one-hot RV 
\begin_inset Formula $Z_{n}$
\end_inset

,
\begin_inset Formula 
\[
P(Y_{1},\ldots,Y_{N},Z_{1},\ldots,Z_{N};\theta)=\prod_{n}\prod_{k}[\pi_{k}p_{k}(y_{n};\theta_{k})]^{Z_{n}^{k}}
\]

\end_inset

and the corresponding 
\begin_inset Formula $\ell(\ubar Y,\ubar Z;\theta)$
\end_inset

 is easier to optimize as the summation inside log has been eliminated.
\end_layout

\begin_layout Subsection
K-Means
\end_layout

\begin_layout Subsection
Mixture Model
\end_layout

\begin_layout Section
EM Algorithm
\end_layout

\begin_layout Section
Deterministic Approximations
\end_layout

\begin_layout Standard
The goal of 
\begin_inset Quotes eld
\end_inset

belief approximation
\begin_inset Quotes erd
\end_inset

 is to find a simpler distribution 
\begin_inset Formula $q(\cdot)$
\end_inset

 that is sufficiently 
\begin_inset Quotes eld
\end_inset

close
\begin_inset Quotes erd
\end_inset

 to 
\begin_inset Formula $P_{X|Y}(\cdot|y)$
\end_inset

.
\end_layout

\begin_layout Subsection
DL Divergence
\end_layout

\begin_layout Standard
Given a true distribution 
\begin_inset Formula $p(\cdot)$
\end_inset

, and an approximating distribution 
\begin_inset Formula $q(\cdot)$
\end_inset

,
\begin_inset Formula 
\[
D(p\|q)=E_{p}[\log\frac{p(x)}{q(x)}]=\sum_{x\in\mathcal{X}}p(x)\log\frac{p(x)}{q(x)}
\]

\end_inset


\end_layout

\begin_layout Standard
According to Gibb's inequality, we have 
\begin_inset Formula $D(p\|q)=E_{p}[\log p(x)]-E_{p}[\log q(x)]\geq0$
\end_inset

.
 Only when 
\begin_inset Formula $p=q$
\end_inset

, 
\begin_inset Formula $D(p\|q)=0$
\end_inset

.
\end_layout

\begin_layout Subsection
Laplace's Method
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P_{X|Y}(x|y)\approx\mathcal{N}(x;\hat{x}_{MAP}(y),\hat{\sigma}^{2}(y))
\]

\end_inset


\begin_inset Formula 
\[
\hat{\sigma}^{2}(y)=[-\frac{\partial^{2}}{\partial x^{2}}\log P_{X}(x)|_{\hat{x}_{MAP}}-\frac{\partial^{2}}{\partial x^{2}}\log P_{Y|X}(y|x)|_{\hat{x}_{MAP}}]^{-1}
\]

\end_inset


\end_layout

\begin_layout Subsection
Variational Methods
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\hat{p}(x) & =\arg\min_{q\in Q}D(q\|p_{X|Y})\\
\hat{p}(x) & =\arg\min_{q\in Q}D(q\|p_{X,Y})
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Stochastic Approximations
\end_layout

\begin_layout Standard
Goal: approximate 
\begin_inset Formula $E_{p}[f(x)]$
\end_inset

 for general 
\begin_inset Formula $f(\cdot)$
\end_inset

.
\end_layout

\begin_layout Standard
Approach: suppose we had samples of 
\begin_inset Formula $x_{1},\ldots,x_{n}\sim iid\,p(x)$
\end_inset

.
\begin_inset Formula 
\begin{align*}
E_{p}[f(x)] & \approx\hat{f}=\frac{1}{n}\sum_{i=1}^{n}f(x_{i})\\
E_{p}[\hat{f}] & =\frac{1}{n}\sum_{i=1}^{n}E_{p}[f(x_{i})]=E_{p}[f(x)]\\
Var[\hat{f}] & =\frac{1}{n^{2}}\sum_{i=1}^{n}Var[f(x_{i})]=\frac{Var[f(x)]}{n}\rightarrow_{n\rightarrow\infty}0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We obtain samples from 
\begin_inset Formula $q(\cdot)$
\end_inset

, which is easy to handle, and transform them into samples of 
\begin_inset Formula $p(\cdot)$
\end_inset

.
\begin_inset Formula 
\[
q(x)>0\ \forall\ x\in\mathcal{X}\ s.t.\ p(x)>0
\]

\end_inset


\end_layout

\begin_layout Subsection
Importance Sampling
\end_layout

\begin_layout Standard
We call 
\begin_inset Formula $q(\cdot)$
\end_inset

 as 
\begin_inset Quotes eld
\end_inset

proposal
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

sampling
\begin_inset Quotes erd
\end_inset

 distribution.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
q(x)=\frac{q_{0}(x)}{Z_{q}}=\frac{q_{0}(x)}{\int_{x\in\mathcal{X}}q_{0}(x)dx}
\]

\end_inset


\end_layout

\begin_layout Standard
The importance weights
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w(x_{i})=\frac{p_{0}(x_{i})}{q_{0}(x_{i})}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{f}\triangleq\sum_{i=1}^{n}\frac{w(x_{i})}{\sum_{j=1}^{n}w(x_{j})}f(x_{i})
\]

\end_inset


\end_layout

\begin_layout Subsection
Rejection Sampling
\end_layout

\begin_layout Subsection
Markov-Chain Monte Carlo (MCMC)
\end_layout

\begin_layout Section
Approximations Continued
\end_layout

\begin_layout Section
Markov Chains and HMMs
\end_layout

\begin_layout Section
HMMs Continued
\end_layout

\begin_layout Subsection
Graphical Model
\end_layout

\begin_layout Standard
Parametrization for Homogeneous HMM; doesw not depend on time.
\end_layout

\begin_layout Standard
Binary indicator vector
\begin_inset Formula 
\[
q_{t}=[q_{t}^{1},\ldots,q_{t}^{M}]^{T}\qquad
\]

\end_inset


\end_layout

\begin_layout Standard
Initial state probabilities
\begin_inset Formula 
\[
\pi=[\pi^{1},\ldots,\pi^{M}]^{T}\qquad p(q_{0}^{i}=1)=\pi^{i}
\]

\end_inset


\end_layout

\begin_layout Standard
We augment the prior 
\begin_inset Formula $\pi$
\end_inset

 w/ 
\begin_inset Formula $M\times M$
\end_inset

 transition probability matrix 
\begin_inset Formula $\mathbb{\mathbf{A}}$
\end_inset

, where 
\begin_inset Formula 
\[
a_{ij}=p(q_{t+1}=j|q_{t}=i)
\]

\end_inset


\end_layout

\begin_layout Standard
Likelihood
\begin_inset Formula 
\[
p(y_{t}|q_{t};\eta)
\]

\end_inset


\end_layout

\begin_layout Standard
So the joint density of HMM is
\begin_inset Formula 
\[
p(\bm{q},\bm{y})=p(q_{0})\prod_{t=0}^{T-1}p(q_{t+1}|q_{t})\prod_{t=0}^{T}p(y_{t}|q_{t};\eta)
\]

\end_inset


\end_layout

\begin_layout Section
Kalman Filtering
\end_layout

\begin_layout Standard
Graphical Models -> (Discrete states from ML perspective) -> HMMs; Graphical
 Models -> (Continuous states from SP perspective) -> Kalman Filter.
\end_layout

\begin_layout Section
Conjugate Priors
\end_layout

\begin_layout Section
Dirichlet Process Priors
\end_layout

\begin_layout Section
Gaussian Processes
\end_layout

\begin_layout Section
References
\end_layout

\end_body
\end_document
