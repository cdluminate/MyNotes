#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{microtype}
\usepackage{times}
\usepackage[margin=1in]{geometry}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
EN 520.650 Machine Intelligence Final
\end_layout

\begin_layout Author
Mo Zhou
\begin_inset Newline newline
\end_inset

mzhou32@jhu.edu
\end_layout

\begin_layout Section
Q1
\end_layout

\begin_layout Standard
OK before answering any question, let's first build the formuations.
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="1" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
36
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
We have an MDP, with 4 states: 
\begin_inset Formula $s_{1},s_{2},s_{3},s_{4}$
\end_inset

.
 There are two actions: left (L) and right (R) and stay (N).
 Action N has 1 transition probability to the current state.
 Action L is invalid for 
\begin_inset Formula $s_{1}$
\end_inset

.
 Action R is invalid for 
\begin_inset Formula $s_{4}$
\end_inset

.
 Rewards will only be given when action N happens.
 Namely, there are only two non-zero rewards: 
\begin_inset Formula $R(s_{1},N,s_{1})=4$
\end_inset

, and 
\begin_inset Formula $R(s_{4},N,s_{4})=36$
\end_inset

.
 All other case will lead to zero reward.
 This means the reward depends on how the agent reached a state.
\end_layout

\begin_layout Subsection
value iteration step 1
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $U\triangleq V$
\end_inset

.
 The rewards depends on how the agent reached a state.
 So it's likely that we cannot directly copy the equations from slides.
 First we have
\begin_inset Formula 
\begin{align*}
U(s^{k}) & =E[\sum_{i=0}^{\infty}\gamma^{i}R(s^{k+i},a,s^{k})]\\
 & =E[R(s^{k},a,s^{k})+\sum_{i=1}^{\infty}\gamma^{i}R(s^{k+i},a,s^{k})]\\
 & =E[R(s^{k},a,s^{k})+\gamma\sum_{i=1}^{\infty}\gamma^{i-1}R(s^{k+i},a,s^{k})]\\
 & =R(s^{k},a,s^{k})+\gamma E[\sum_{i=1}^{\infty}\gamma^{i-1}R(s^{k+i},a,s^{k})]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So our formuation for finding the utility is
\begin_inset Formula 
\[
U(s)=R(s^{k},a,s^{k})+\gamma\max_{a\in\{L,R,N\}}\sum_{s'}P(s'|s,a)U(s')
\]

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $U^{(0)}(s)=0$
\end_inset

 for any state, and discount 
\begin_inset Formula $\gamma=0.5$
\end_inset

, we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
U^{(1)}(s_{1}) & =R(s_{1},a,s_{1})+\gamma\max(0_{\{a=N\}},0_{\{a=R\}})=4\\
U^{(1)}(s_{2}) & =R(s_{2},a,s_{2})+\gamma\max(0_{\{a=L\}},0_{\{a=R\}},0_{\{a=N\}})=0\\
U^{(1)}(s_{3}) & =R(s_{3},a,s_{3})+\gamma\max(0_{\{a=L\}},0_{\{a=R\}},0_{\{a=N\}})=0\\
U^{(1)}(s_{4}) & =R(s_{4},a,s_{4})+\gamma\max(0_{\{a=N\}},0_{\{a=R\}})=36
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The values only hold for 
\begin_inset Formula $a=N$
\end_inset

.
 Other actions will lead to zero utility.
\end_layout

\begin_layout Standard
So 
\begin_inset Formula $V^{(1)}$
\end_inset

 is namely
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
U^{(1)}=\begin{bmatrix}4 & 0 & 0 & 36\end{bmatrix}
\]

\end_inset


\end_layout

\begin_layout Subsection
value iteration step 2
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
U^{(2)}(s_{1}) & =R(s_{1},a,s_{1})+\gamma\max(4_{\{a=N\}},0_{\{a=R\}})=4+0.5\times4=6\\
U^{(2)}(s_{2}) & =R(s_{2},a,s_{2})+\gamma\max(0_{\{a=L\}},0_{\{a=R\}},0_{\{a=N\}})=0\\
U^{(2)}(s_{3}) & =R(s_{3},a,s_{3})+\gamma\max(0_{\{a=L\}},0_{\{a=R\}},0_{\{a=N\}})=0\\
U^{(2)}(s_{4}) & =R(s_{4},a,s_{4})+\gamma\max(36_{\{a=N\}},0_{\{a=L\}})=36+0.5\times36=54
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So 
\begin_inset Formula $V^{(2)}$
\end_inset

 is namely
\begin_inset Formula 
\[
U^{(2)}=\begin{bmatrix}6 & 0 & 0 & 54\end{bmatrix}
\]

\end_inset


\end_layout

\begin_layout Subsection
utility
\end_layout

\begin_layout Standard
\begin_inset Formula $V^{*}$
\end_inset

 indicates convergence.
 Thus we have at the 
\begin_inset Formula $z$
\end_inset

-th step:
\begin_inset Formula 
\begin{align*}
U^{(z)}(s_{1}) & =U^{(z-1)}(s_{1})=4+\gamma U^{(z-1)}(s_{1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Solving the equation leads to 
\begin_inset Formula $U^{(z)}(s_{1})=8$
\end_inset

.
 Similarly we will have 
\begin_inset Formula $U^{(z)}(s_{2})=0$
\end_inset

, 
\begin_inset Formula $U^{(z)}(s_{3})=0$
\end_inset

, and 
\begin_inset Formula $U^{(z)}(s_{4})=72.$
\end_inset


\end_layout

\begin_layout Standard
Namely 
\begin_inset Formula $V^{*}$
\end_inset

 is
\begin_inset Formula 
\[
U^{*}=\begin{bmatrix}8 & 0 & 0 & 72\end{bmatrix}
\]

\end_inset


\end_layout

\begin_layout Section
Q2
\end_layout

\begin_layout Subsection
(a)
\end_layout

\begin_layout Standard
Assume input 
\begin_inset Formula $x$
\end_inset

 (vector), weight 
\begin_inset Formula $W_{l}$
\end_inset

 (matrix) and bias 
\begin_inset Formula $b_{l}$
\end_inset

 (vector) for the 
\begin_inset Formula $l$
\end_inset

-th layer, and activation function 
\begin_inset Formula $\sigma(\cdot)$
\end_inset

.
 We denote the pre-activation layer output as 
\begin_inset Formula $y_{l}$
\end_inset

 (vector), and the post-activation layer output as 
\begin_inset Formula $z_{l}$
\end_inset

, namely 
\begin_inset Formula $z_{l}=\sigma(y_{l})$
\end_inset

.
 There are in total 
\begin_inset Formula $L$
\end_inset

 layers, and index 
\begin_inset Formula $l\in\{1,\ldots,L\}$
\end_inset

.
\end_layout

\begin_layout Standard
Then, the forward pass of the network can be described asz
\begin_inset Formula 
\begin{align*}
y_{1} & =W_{1}x+b_{1}\\
z_{1} & =\sigma(y_{1})\\
y_{2} & =W_{2}z_{1}+b_{2}\\
z_{2} & =\sigma(y_{2})\\
 & \ldots\\
y_{l} & =W_{l}z_{l-1}+b_{l}\\
z_{l} & =\sigma(y_{l})\\
 & \ldots\\
y_{L} & =W_{L}z_{L-1}+b_{L}\\
z_{L} & =\sigma(y_{L})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now 
\begin_inset Formula $z_{L}$
\end_inset

 is the network output.
 If it is trained using cross-entropy loss as a classifier, then the maximum
 element in vector 
\begin_inset Formula $z_{L}$
\end_inset

 after softmax normalization corresponds to the predicted class.
\end_layout

\begin_layout Subsection
(b)
\end_layout

\begin_layout Standard
Assume batch size 1.
 Then layer 1 has matrix-vector product 
\begin_inset Formula $W_{1}x$
\end_inset

 with complexity 
\begin_inset Formula $O(dd_{1})$
\end_inset

, which involves 
\begin_inset Formula $d\times d_{1}$
\end_inset

 multiplications, and 
\begin_inset Formula $d_{1}$
\end_inset

 additions.
 The bias term involves 
\begin_inset Formula $d_{1}$
\end_inset

 additions.
 The activation step has complexity 
\begin_inset Formula $O(d_{1})$
\end_inset

 as well since it is element wise.
 So in total there will be 
\begin_inset Formula $dd_{1}+d_{1}d_{2}+\ldots+d_{l-1}d_{l}$
\end_inset

 multiplications, and matrix-matrix (in larger batch size) or matrix-vector
 (when batch size 1) multiplication is the dominating computation operation.
 
\end_layout

\begin_layout Subsection
(c)
\end_layout

\begin_layout Standard
We apply chain rule for the formulation.
 Assume cost function 
\begin_inset Formula $J$
\end_inset

.
 We propagate the gradient with chain rule in reversed order compared to
 the forward process.
 Assume 
\begin_inset Formula $\partial J/\partial z_{L}$
\end_inset

 is known, then
\begin_inset Formula 
\begin{align*}
\frac{\partial J}{\partial y_{L}} & =\frac{\partial J}{\partial z_{L}}\cdot\frac{\partial z_{L}}{\partial y_{L}}=\frac{\partial J}{\partial z_{L}}\cdot\sigma'(y_{L})\\
\frac{\partial J}{\partial W_{L}} & =\frac{\partial J}{\partial y_{L}}\cdot\frac{\partial y_{L}}{\partial W_{L}}=\frac{\partial J}{\partial y_{L}}\cdot z_{L-1}^{T}\\
\frac{\partial J}{\partial b_{L}} & =\frac{\partial J}{\partial y_{L}}\\
\frac{\partial J}{\partial z_{L-1}} & =\frac{\partial J}{\partial y_{L}}\cdot\frac{\partial y_{L}}{\partial z_{L-1}}=W_{L}^{T}\cdot\frac{\partial J}{\partial y_{L}}\\
\frac{\partial J}{\partial y_{L-1}} & =\frac{\partial J}{\partial z_{L-1}}\cdot\sigma'(y_{L-1})\\
 & \ldots\\
\frac{\partial J}{\partial W_{l}} & =\frac{\partial J}{\partial y_{l}}\cdot\frac{\partial y_{l}}{\partial W_{l}}=\frac{\partial J}{\partial y_{l}}\cdot z_{l-1}^{T}\\
\frac{\partial J}{\partial b_{l}} & =\frac{\partial J}{\partial y_{l}}\\
\frac{\partial J}{\partial z_{l-1}} & =\frac{\partial J}{\partial y_{l}}\cdot\frac{\partial y_{l}}{\partial z_{l-1}}=W_{l}^{T}\cdot\frac{\partial J}{\partial y_{l}}\\
 & \ldots\\
\frac{\partial J}{\partial y_{1}} & =\frac{\partial J}{\partial z_{1}}\frac{\partial z_{1}}{\partial y_{1}}=\frac{\partial J}{\partial z_{1}}\cdot\sigma'(y_{1})\\
\frac{\partial J}{\partial b_{1}} & =\frac{\partial J}{\partial y_{1}}\\
\frac{\partial J}{\partial W_{1}} & =\frac{\partial J}{\partial y_{1}}\cdot\frac{\partial y_{1}}{\partial W_{1}}=\frac{\partial J}{\partial y_{1}}\cdot x^{T}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
With the chain rule all the formulations in all layers are more or less
 alike.
 In the equation 
\begin_inset Formula $\sigma'(x)$
\end_inset

 is the derivative of activation function 
\begin_inset Formula $\sigma(x)$
\end_inset

.
 In the ReLU case, it is 
\begin_inset Formula $\sigma'(x)=x$
\end_inset

 when 
\begin_inset Formula $x>=0$
\end_inset

, or 
\begin_inset Formula $\sigma'(x)=0$
\end_inset

 when 
\begin_inset Formula $x<0$
\end_inset

.
\end_layout

\begin_layout Subsection
(d)
\end_layout

\begin_layout Standard
Generally backward computation is more expensive than forward pass.
 Because in this case we compute twice as many as matrix multiplications,
 one for the gradient with respect to the weights 
\begin_inset Formula $W_{l}$
\end_inset

, and one for the gradient with respect to 
\begin_inset Formula $z_{l}$
\end_inset

 and 
\begin_inset Formula $y_{l}$
\end_inset

, which is to be propagated.
 With a similar conclusion in answer to question (b), matrix multiplication
 is still the dominating operation.
 Matrix multiplication is the performance bottleneck in practice as well.
 Element-wise operations do not really contribute much complexity.
\end_layout

\begin_layout Section
Q3
\end_layout

\begin_layout Subsection
(a)
\end_layout

\begin_layout Standard
True.
 Once i.i.d, the mean gradient over a batch as an estimation is closer to
 the mean gradient over the data distribution.
\end_layout

\begin_layout Subsection
(b)
\end_layout

\begin_layout Standard
Failure of the model to learn indicates failure of generalization.
 This will happen when the data cluster of the positive examples and the
 cluster of negative examples are not separateble.
 It could happen when the data is too noisy, or the data is simply too hard
 to learn and the extracted features or learned representations failed to
 catch their differences.
\end_layout

\begin_layout Subsection
(c)
\end_layout

\begin_layout Standard
In principal, convolution is linear operation, and it is equivalent to a
 sparse, and tiled matrix multiplication.
 However, the computational complexity of fully-connected layer is lower
 than fully-connected, and convolution kernels are smaller than fully-connected
 weights.
 Hence, convolution is computaionally efficient, and requires less storage.
 Besides, convolution also has some good properties like translation invariance
 (see deep learning book).
\end_layout

\begin_layout Subsection
(d)
\end_layout

\begin_layout Standard
The question means the network output is 
\begin_inset Formula 
\[
\text{output}=sigmoid(relu(...))
\]

\end_inset


\end_layout

\begin_layout Standard
ReLU activation does not propagate gradient with input less than 0.
 And sigmoid also has two saturation area which lead to very small gradient.
 Only when the input to ReLU precisely falls into the range from 0 to a
 small positive number, there will be a gradient.
 Otherwise, the gradient will just vanish and the network will not learning
 everything since everywhere is zero (or near-zero) gradient.
\end_layout

\begin_layout Subsection
(e)
\end_layout

\begin_layout Standard
If I remember correctly, in the deep learning book there is some suggestion
 on learning rate search.
 The strategy suggested in the question is not efficient.
 Usually we do binary search in log scale.
 For example, we plan with 0.01, 0.1, and 1 at the beginning.
 Then we use binary search to continue to find an appropriate learning rate
 that is not leading to diverging loss function, while not being too small.
\end_layout

\begin_layout Standard
The suggested learning rate search method is sequential search, which is
 not efficient compared to binary search.
\end_layout

\begin_layout Subsection
(f)
\end_layout

\begin_layout Enumerate
Mini-batch gradient descent is feasible in practice.
 You don't have the kind of hardware that can do gradient update on the
 whole ImageNet.
\end_layout

\begin_layout Enumerate
Mini-batch gradient descent provides statistically more stable gradients
 than batch-1 stochastic gradient descent, and helps the model to converge
 faster.
\end_layout

\begin_layout Enumerate
Adam optimizer leverages the historical gradients.
 It can help the model learn faster (with a kind of momemtum effect) and
 sometimes help the model to escape from local optimum.
\end_layout

\begin_layout Section
Q4
\end_layout

\begin_layout Description
Mode-Collapse.
 Mode collapse is the most severe form of non-convergence issue in GANs.
 It means
\begin_inset Formula 
\[
\min_{G}\max_{D}V(G,D)\neq\max_{D}\min_{G}V(G,D),
\]

\end_inset

where GAN converges to correct distribution when 
\begin_inset Formula $D$
\end_inset

 is in inner loop; while GAN places all mass on most likely point when 
\begin_inset Formula $G$
\end_inset

 is in inner loop.
 Besides, other GAN losses also yield mode collapse, and Reverse KL loss
 perfers to fit as many modes as the model can represent and no more â€“ it
 does not prefer fewer modes in general.
 In practice, GANs often seem to collapse to far fewer modes than the model
 can represent.
 As a result, mode collpase causes low output diversity.
\end_layout

\begin_layout Description
Solution.
 To mitigate mode collapse, we need to prevent the generator from broadening
 its scope by preventing it from optimizing for a single fixed discriminator.
 Possible solutions include:
\end_layout

\begin_deeper
\begin_layout Description
(1) Wasserstein loss.
 It alleviates mode collapse training the discriminator to optimality without
 worrying about vanishing gradients.
 If the discriminator does not get stuck in local minima, it learns to reject
 the outputs that the generator stabilizes on.
 So the generator has to output differently.
\end_layout

\begin_layout Description
(2) Unrolled GANs.
 We back-propagate through k updates of the discriminator to prevent mode
 collapse.
 Namely, we use a generator loss function that incorporates not only the
 current discriminator's classifications, but also the outputs of future
 discriminator versions.
 So the generator can't over-optimize for a single discriminator.
\end_layout

\end_deeper
\begin_layout Section
Q5
\end_layout

\begin_layout Subsection
(a) True / false about attack
\end_layout

\begin_layout Itemize
(i) is true.
 Adversarial examples has transferrability.
\end_layout

\begin_layout Itemize
(ii) is false.
 FGSM is called 
\begin_inset Quotes eld
\end_inset

fast
\begin_inset Quotes erd
\end_inset

 because it's single-step.
\end_layout

\begin_layout Itemize
(iii) is false.
 Dropout is effective regularization, but not effective defense.
 Stronger attacks such as adaptive attack will be able to penetrate such
 countermeasure.
\end_layout

\begin_layout Itemize
(iv) is true.
 Most of the discussed attacks are white-box attacks.
 However, black box attacks are also possible, such as transferrability-based
 attacks (TI-FGSM and DI-FGSM), score-based black box attacks (e.g.
 Natural Evolution Strategy), and query-based attacks.
 These black-box attacks do not require any access to the network parameter,
 architecture, or gradient.
\end_layout

\begin_layout Subsection
(b) FGSM calculation
\end_layout

\begin_layout Standard
FGSM is a single step attack.
 Given
\begin_inset Formula 
\begin{align*}
x & =[1,2,3]^{T}\\
\partial J\partial x & =[0.5,-0.5,1]^{T}\\
\epsilon & =0.01
\end{align*}

\end_inset

we have a single step projected gradient ascent as
\begin_inset Formula 
\begin{align*}
x^{*} & =x+\epsilon\cdot\text{sign}(\partial J/\partial x)\\
 & =x+0.01[1,-1,1]^{T}\\
 & =[1,2,3]^{T}+[0.01,-0.01,0.01]^{T}\\
 & =[1.01,1.99,3.01]^{T}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
(c) FGSM statement
\end_layout

\begin_layout Standard
The statement is false.
 According to Ian Goodfellow in FGSM paper, actually when the dimension
 of 
\begin_inset Formula $x$
\end_inset

 is higher, the required 
\begin_inset Formula $\epsilon$
\end_inset

 is lower.
 Assume mean value 
\begin_inset Formula $\mu$
\end_inset

 for a layer input, mean weight 
\begin_inset Formula $\sigma$
\end_inset

 for the layer, and dimensionality 
\begin_inset Formula $d$
\end_inset

.
 The expected activation is 
\begin_inset Formula $\mu\sigma d$
\end_inset

.
 When a perturbation is added to the linear layer, the activation has been
 bumped by 
\begin_inset Formula $\epsilon\mu\sigma d$
\end_inset

.
 When 
\begin_inset Formula $d$
\end_inset

 is large enough, 
\begin_inset Formula $\epsilon$
\end_inset

 does not have to be large to create a huge activation bump.
\end_layout

\begin_layout Subsection
(c) GAN (there is a typo in question numbering)
\end_layout

\begin_layout Standard
We should use (B) non-saturating cost, in order to avoid making discriminator
 
\begin_inset Formula $D$
\end_inset

 
\begin_inset Quotes eld
\end_inset

too smart
\begin_inset Quotes erd
\end_inset

, and thus maintain a relatively good balance between generator 
\begin_inset Formula $G$
\end_inset

 and discriminator 
\begin_inset Formula $D$
\end_inset

.
 In this case, generator 
\begin_inset Formula $G$
\end_inset

 can still learn even when distriminator successfully rejects all generator
 samples.
\end_layout

\begin_layout Subsection
(d) GAN loss
\end_layout

\begin_layout Standard
For GAN, the equilibrium is a saddle point of the discriminator loss.
 This is reflected in the training process as both discriminator and generator
 are simultaneously learning, and still maintains a similar loss.
\end_layout

\begin_layout Section
Q6
\end_layout

\begin_layout Subsection
(a) AI bias
\end_layout

\begin_layout Standard
For example, for face recognition model, if its training datasets contains
 more training examples for a specific human race, then it may perform specifica
lly good for this race, and perform relatively worse for the others.
\end_layout

\begin_layout Standard
Adding more data to balance the training set is an intuitive solution, but
 it may be difficult to take into practice.
\end_layout

\begin_layout Subsection
(b) interpretable AI
\end_layout

\begin_layout Standard
Take linear support vector machine with 2d input feature as example.
 We can clearly draw the classification hyperplane, and figure out exactly
 the data that formed support vectors.
\end_layout

\begin_layout Standard
Take decision tree as example.
 We can clearly follow the tree and describe what feature is the tree using
 at the current layer, and to what branch does the decision tree go based
 on what decision rule.
\end_layout

\begin_layout Standard
Traditional models are intuitive to interpret, but deep models are not.
\end_layout

\begin_layout Subsection
(c) GradCAM is generalization of CAM
\end_layout

\begin_layout Standard

\bar under
This question corresponds to the section 3.1 in paper 
\begin_inset Quotes eld
\end_inset

Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
Grad-CAM generalizes CAM for a wide variety of CNN-based architectures.
 Recall that CAM produces a localization map for an image classification
 CNN with a specific kind of architecture where global average pooled convolutio
nal feature maps are fed directly into softmax.
 Specifically, let the penultimate layer produce 
\begin_inset Formula $K$
\end_inset

 feature maps, 
\begin_inset Formula $A^{k}\in\mathbb{R}^{u\times v}$
\end_inset

, with each element indexed by 
\begin_inset Formula $i,j$
\end_inset

.
 So 
\begin_inset Formula $A_{ij}^{k}$
\end_inset

 refers to the activation at location 
\begin_inset Formula $(i,j)$
\end_inset

 of the feature map 
\begin_inset Formula $A^{k}$
\end_inset

.
 These feature maps are then spatially pooled using Global Average Pooling
 (GAP) and linearly transformed to produce a score 
\begin_inset Formula $Y^{c}$
\end_inset

 for each class 
\begin_inset Formula $c$
\end_inset

,
\begin_inset Formula 
\[
Y^{c}=\sum_{k}w_{k}^{c}\frac{1}{Z}\sum_{i}\sum_{j}A_{ij}^{k}\qquad(3)
\]

\end_inset

where 
\begin_inset Formula $w_{k}^{c}$
\end_inset

 class feature weights.
 Let us define 
\begin_inset Formula $F^{k}$
\end_inset

 to be the global average pooled output,
\begin_inset Formula 
\[
F^{k}=\frac{1}{Z}\sum_{i}\sum_{j}A_{ij}^{k}.\qquad(4)
\]

\end_inset

CAM computes the final score by
\begin_inset Formula 
\[
Y^{c}=\sum_{k}w_{k}^{c}\cdot F^{k},\qquad(5)
\]

\end_inset

where 
\begin_inset Formula $w_{k}^{c}$
\end_inset

 is the weight connecting the 
\begin_inset Formula $k^{th}$
\end_inset

 feature map with the 
\begin_inset Formula $c^{th}$
\end_inset

 class.
 Taking the gradient of the score for class 
\begin_inset Formula $c(Y^{c})$
\end_inset

 with respect to the feature map 
\begin_inset Formula $F^{k}$
\end_inset

, we will get
\begin_inset Formula 
\[
\frac{\partial Y^{c}}{\partial F^{k}}=\big(\frac{\partial Y^{c}}{\partial A_{ij}^{k}}\big)/\big(\frac{\partial F^{k}}{\partial A_{ij}^{k}}).\qquad(6)
\]

\end_inset

Taking partial derivative of Eq.
 (4) w.r.t.
 
\begin_inset Formula $A_{ij}^{k}$
\end_inset

, we can see that 
\begin_inset Formula $\frac{\partial F^{k}}{\partial A_{ij}^{k}}=\frac{1}{Z}$
\end_inset

.
 Substituting this in Eq.
 (6), we get
\begin_inset Formula 
\[
\frac{\partial Y^{c}}{\partial F^{k}}=\frac{\partial Y^{c}}{\partial A_{ij}^{k}}\cdot Z
\]

\end_inset

From Eq.
 (5) we get that 
\begin_inset Formula $\frac{\partial Y^{c}}{\partial F^{k}}=w_{k}^{c}$
\end_inset

.
 Hence,
\begin_inset Formula 
\[
w_{k}^{c}=Z\cdot\frac{\partial Y^{c}}{\partial A_{ij}^{k}}
\]

\end_inset

Summing both sides of Eq.
 (8) over all pixels 
\begin_inset Formula $(i,j)$
\end_inset

, we get
\begin_inset Formula 
\[
\sum_{i}\sum_{j}w_{k}^{c}=\sum_{i}\sum_{j}Z\cdot\frac{\partial Y^{c}}{\partial A_{ij}^{k}}
\]

\end_inset

Since 
\begin_inset Formula $Z$
\end_inset

 and 
\begin_inset Formula $w_{k}^{c}$
\end_inset

 do not depend on 
\begin_inset Formula $(i,j)$
\end_inset

, rewriting this as
\begin_inset Formula 
\[
Zw_{k}^{c}=Z\sum_{i}\sum_{j}\frac{\partial Y^{c}}{\partial A_{ij}^{k}}
\]

\end_inset

Note that 
\begin_inset Formula $Z$
\end_inset

 is the number of pixels in the feature map (or 
\begin_inset Formula $Z=\sum_{i}\sum_{j}\bm{1}$
\end_inset

).
 Thus, we can re-order terms and see that
\begin_inset Formula 
\[
w_{k}^{c}=\sum_{i}\sum_{j}\frac{\partial Y^{c}}{\partial A_{ij}^{k}}
\]

\end_inset

Up to a proportionality constant 
\begin_inset Formula $(1/Z)$
\end_inset

 that gets normliazed-out during visualization, the expression for 
\begin_inset Formula $w_{k}^{c}$
\end_inset

 s identical to 
\begin_inset Formula $\alpha_{k}^{c}$
\end_inset

 used by Grad-CAM.
 Thus, Grad-CAM is a strict generalization of CAM.
\end_layout

\end_body
\end_document
