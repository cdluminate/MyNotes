#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{microtype}
\usepackage[margin=0.7in]{geometry}
%\usepackage{gentium}
\usepackage{times}
\usepackage{indentfirst}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Rama | Machine Intelligence 2022 Spring Course Notes
\end_layout

\begin_layout Author
M Zhou
\end_layout

\begin_layout Section
History of AI
\end_layout

\begin_layout Standard
Rational Decision: maximizing expected utility.
\end_layout

\begin_layout Standard
From the brain: memory and simulation are key to decision making.
\end_layout

\begin_layout Standard
Directions in AI: Search, Language, Vision, Expertise (expert system / recommend
er).
\end_layout

\begin_layout Standard
Definition of AI: Narrow AI v.s.
 General AI.
\end_layout

\begin_layout Standard
Issues with current AI: data hungry, black box, generalizability (domain
 shift), vulnerability, bias, fairness, privacy.
 Explainability.
 Going Big?
\end_layout

\begin_layout Section
Intelligent Agents & Environment
\end_layout

\begin_layout Standard
An agent is a computer system that is capable of independent action on behalf
 of its user or owner.
\end_layout

\begin_layout Standard
A multiagent system is one that consists of a number of agents, which interact
 with one-another.
 
\end_layout

\begin_layout Standard
Two key problems: agent design, and society design.
\end_layout

\begin_layout Standard
Performance measure: objective criterion for success of an agent's behavior.
\end_layout

\begin_layout Standard
Rational agent maximizes its expected performance measure for each possible
 percept sequence.
 
\end_layout

\begin_layout Standard
PEAS: Performance measure, Environment, Actuators, Sensors.
\end_layout

\begin_layout Standard
Environment: fully observable or partially observable, deterministic or
 stochastic, episodic or sequential, static or dynamic (does it change while
 the agent is thinking), discrete or continuous
\end_layout

\begin_layout Subsection
Task environments
\end_layout

\begin_layout Standard
single agent or multi-agent
\end_layout

\begin_layout Subsection
Agent Types
\end_layout

\begin_layout Description
table-driven-agents use a percept sequence/action table in memory to find
 the enxt action.
 implemented by a large lookup table
\end_layout

\begin_layout Description
simple-refelx-agents based on condition-action rules, implemeneted with
 an appropriate production system.
 they are steateless devices which do not have memory of past world states.
\end_layout

\begin_layout Description
agents-with-memory model-based reflex agents.
 they have internal state, which is used to keep track of past states of
 the world
\end_layout

\begin_layout Description
agents-with-goals are agents that, in addition to state information, have
 goal information that describes desirable situations.
 agents of this kind take future events into consideration
\end_layout

\begin_layout Description
utility-based-agents base their decisions on classis axiomatic utility theory
 in order to act rationally
\end_layout

\begin_layout Description
learning-agents they have the ability to improve performance through learning
\end_layout

\begin_layout Section
Problem Solving by Searching
\end_layout

\begin_layout Subsection
running time of an algorithm
\end_layout

\begin_layout Standard
The big O notation
\end_layout

\begin_layout Subsection
search problem
\end_layout

\begin_layout Standard
A search problem consists of (1) a state space; (2) a successor function;
 (3) a start state and a goal test;
\end_layout

\begin_layout Standard
A solution is a sequence of actions (a plan) which transforms the start
 state to a goal state.
\end_layout

\begin_layout Standard
example: the 8-puzzle 
\begin_inset Quotes eld
\end_inset

sliding tile puzzle
\begin_inset Quotes erd
\end_inset

, TSP, VLSI layout, robot navigation, protein design, etc.
\end_layout

\begin_layout Subsection
state space graph and search tree
\end_layout

\begin_layout Standard
each state only occurs once in graph.
\end_layout

\begin_layout Standard
general tree search algorithm.
 imoprtant aspects: fringe, expansion, exploration strategy.
\end_layout

\begin_layout Standard

\series bold
depth-first search.
 DFS
\series default
.
 strategy: expand a deepest node first.
 implementation: fringe is a LIFO stack.
 branching factor 
\begin_inset Formula $b$
\end_inset

, maximum depth 
\begin_inset Formula $m$
\end_inset

, the number of nodes in the entire tree is 
\begin_inset Formula $O(b^{m})$
\end_inset

.
 It takes time 
\begin_inset Formula $O(b^{m})$
\end_inset

, space of fringe 
\begin_inset Formula $O(bm)$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
breadth-first search.
 BFS.
 
\series default
strategy: expand a shallowest node frist.
 implementation: fringe is a FIFO queue.
 shallowest solution depth 
\begin_inset Formula $s$
\end_inset

, it takes time 
\begin_inset Formula $O(b^{s})$
\end_inset

, fringe takes space 
\begin_inset Formula $O(b^{s})$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
iterative deepening search.
 (IDS)
\series default
 is the perferred uniformed search method when there is a large search space
 and the depth of the solution is not known.
 get DFS's space advantage with BFS's time/shallow-solution advantages.
 Run DFS with depth limit 1, if no solution run DFS w/ depth limit 2, and
 so on.
 time 
\begin_inset Formula $O(b^{d})$
\end_inset

, space 
\begin_inset Formula $O(bd)$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
uniform cost search (UCS)
\series default
.
 strategy expand a cheapest node first.
 implementation: fringe is a priority queue (priority: cumulative cost).
 This is optimal according to A*.
\end_layout

\begin_layout Standard

\series bold
search heuristic
\series default
: a function that estimates how close a state is to a goal.
 specific to particular search problem.
\end_layout

\begin_layout Standard

\series bold
Greedy best-first search:
\series default
 expand a node that you think is closest to a goal state.
 best-first may take you straght to the wrong goal.
 May easily fall into local optimum.
 evaluates heuristic function at node 
\begin_inset Formula $n$
\end_inset

.
 GBF search expands the node that appears to have shortest path to goal,
 with a hope that these nodes may lead to solution quickly.
 This is similar to DFS, which prefers to follow a single path to goal (guided
 by the heuristic).
 It is not complete (may fall in loops).
 Time 
\begin_inset Formula $O(b^{m})$
\end_inset

, Space 
\begin_inset Formula $O(b^{m})$
\end_inset

.
 not optimal
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

fun tree-search(problem, strategy) returns solution, or failure
\end_layout

\begin_layout Plain Layout

	init search tree using initial state of $problem
\end_layout

\begin_layout Plain Layout

	loop
\end_layout

\begin_layout Plain Layout

		if there are no candidates for expansion; then
\end_layout

\begin_layout Plain Layout

			return failure
\end_layout

\begin_layout Plain Layout

		endif
\end_layout

\begin_layout Plain Layout

		choose a leaf node for expansion according to $strategy
\end_layout

\begin_layout Plain Layout

		if the node contains a goal state; then
\end_layout

\begin_layout Plain Layout

			return corresponding solution
\end_layout

\begin_layout Plain Layout

		else
\end_layout

\begin_layout Plain Layout

			expand node and add resulting nodes to search tree
\end_layout

\begin_layout Plain Layout

		endif
\end_layout

\begin_layout Plain Layout

	end
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
general tree search
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
A* (a star) search
\end_layout

\begin_layout Standard
idea: avoid expanding paths that are already expensive.
 Specifically, evluate function 
\begin_inset Formula $f(n)=g(n)+h(n)$
\end_inset

 at node 
\begin_inset Formula $n$
\end_inset

, where 
\begin_inset Formula $g(n)$
\end_inset

 is the cumulative cost to reach 
\begin_inset Formula $n$
\end_inset

, 
\begin_inset Formula $h(n)$
\end_inset

 is the heuristic (estimated cost) from 
\begin_inset Formula $n$
\end_inset

 to goal, 
\begin_inset Formula $f(\cdot)$
\end_inset

 is the total cost.
\end_layout

\begin_layout Standard
It is combination of UCS (backward cost 
\begin_inset Formula $g(n)$
\end_inset

) and Greedy (forward cost 
\begin_inset Formula $h(n)$
\end_inset

).
 A star combines both.
\end_layout

\begin_layout Standard
Under some reasonable conditions for the heuristics, A* is complete and
 optimal.
\end_layout

\begin_layout Standard
Widely used in e.g.
 google maps.
\end_layout

\begin_layout Standard
heuristics admissibility: 
\begin_inset Formula $h(n)\leq h^{*}(n)$
\end_inset

, the heuristics is always less or equal to the true cost.
\end_layout

\begin_layout Standard
heuristic consistency: 
\begin_inset Formula $f(n)$
\end_inset

 non-decreasing along any path.
 this is a stronger condition than admissibility.
 A consistent heuristic is also admissible.
\end_layout

\begin_layout Standard
We can use weighted A* search with 
\begin_inset Formula $f(n)=g(n)+wh(n)$
\end_inset

 where 
\begin_inset Formula $1<w<\infty$
\end_inset

.
 A* degenerates into uniform cost with 
\begin_inset Formula $w=0$
\end_inset

, or greedy best-first with 
\begin_inset Formula $w\rightarrow\infty$
\end_inset

.
\end_layout

\begin_layout Standard
other variations of A*: (1) beam search.
 keeps only the k nodes with the best f-scores discarding any other expanded
 nodes.
 (2) iterative deepening A* search similar to iterative deepening search
 to DFS.
 (3) recursive best-first search.
 (4) branch and bound.
\end_layout

\begin_layout Standard
most of the work in solving hard search problems optimally is in comuing
 up with admissible heuristics.
\end_layout

\begin_layout Standard

\series bold
Summary:
\series default
 A* uses both backward costs and (esimates of) forward costs.
 A* is optimal with admissible or consistent heuristics.
 Heuristic design is the key: ofen use relaxed problems
\end_layout

\begin_layout Section
Adversarial search and games
\end_layout

\begin_layout Section
Constraint satisfaction problems
\end_layout

\begin_layout Section
Probablistic reasoning
\end_layout

\begin_layout Section
Dynamic bayesian networks and associated inference algorithms
\end_layout

\begin_layout Section
Optimal sequential decisions
\end_layout

\begin_layout Section
Markov decision processes
\end_layout

\begin_layout Section
Partially observed Markov decision processes
\end_layout

\begin_layout Section
Deep learning
\end_layout

\begin_layout Section
GANs
\end_layout

\begin_layout Section
Robustness to adversarial attacks
\end_layout

\begin_layout Section
Deep fakes
\end_layout

\begin_layout Section
Fair and ethical AI
\end_layout

\begin_layout Section
Safety of AI systems and applications in engineering and medicine
\end_layout

\end_body
\end_document
