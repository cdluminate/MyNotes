#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{microtype}
\usepackage{times}
\usepackage[margin=1in]{geometry}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
HW #1
\end_layout

\begin_layout Author
Mo Zhou <mzhou32@jhu.edu>
\end_layout

\begin_layout Section
Lecture 2
\end_layout

\begin_layout Subsection
Q1
\end_layout

\begin_layout Standard

\bar under
What are orthogonal basis functions? How can an input image patch be expressed
 as a combination of orthogonal basis functions?
\end_layout

\begin_layout Standard
An orthogonal set of basis function is
\begin_inset Formula 
\[
\{b_{i}(x):i=1,\ldots,N\}
\]

\end_inset

where 
\begin_inset Formula $\sum_{x}\{b_{i}(x)\}^{2}=1$
\end_inset

, and 
\begin_inset Formula $\sum_{x}b_{i}(x)b_{j}(x)=0$
\end_inset

 if 
\begin_inset Formula $i\neq j$
\end_inset

.
 For example, sinusoids can be used as orthogonal basis function.
\end_layout

\begin_layout Standard
An input image patch 
\begin_inset Formula $I(x)$
\end_inset

 can be expressed by
\begin_inset Formula 
\[
I(x)=\sum_{i}a_{i}b_{i}(x)
\]

\end_inset

where the coefficient 
\begin_inset Formula $a_{i}=\sum_{x}I(x)b_{i}(x)$
\end_inset

 because the bases are orthogonal.
 Hence, the image patch 
\begin_inset Formula $I(x)$
\end_inset

 can be expressed by the coefficients 
\begin_inset Formula $\{a_{i}\}$
\end_inset

.
\end_layout

\begin_layout Subsection
Q2
\end_layout

\begin_layout Standard

\bar under
Give two examples of orthogonal basis functions.
\end_layout

\begin_layout Standard
(1) Sinusoids 
\begin_inset Formula $f(x)$
\end_inset


\begin_inset Formula 
\[
f(x)=a\sin(\omega x+c)
\]

\end_inset


\end_layout

\begin_layout Standard
(2) Haar Bases 
\begin_inset Formula $\psi_{n,k}$
\end_inset


\begin_inset Formula 
\[
\psi_{n,k}(t)=2^{\frac{n}{2}}\psi(2^{n}t-k),\qquad t\in R
\]

\end_inset

where the Haar wavelet's mother wavelet function 
\begin_inset Formula $\psi(t)$
\end_inset

 is defined as
\begin_inset Formula 
\[
\psi(t)=\begin{cases}
1 & 0\leq t\leq\frac{1}{2}\\
-1 & \frac{1}{2}\leq t<1\\
0 & o.w.
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Subsection
Q3
\end_layout

\begin_layout Standard

\bar under
Give a method for estimating a set of basis vectors given a training set
 of images.
 What form do these basis functions take if the image is shift-invariant?
\end_layout

\begin_layout Standard
Given the correlation matrix 
\begin_inset Formula $K(x,y)$
\end_inset

, we have 
\begin_inset Formula 
\[
\sum_{y}K(x,y)e_{i}(y)=\lambda_{i}e_{i}(x).
\]

\end_inset

Since Images are shift-invariant, namely 
\begin_inset Formula $K(x,y)=F(x-y)$
\end_inset

, we have
\begin_inset Formula 
\[
\sum_{y}F(x-y)e_{i}(y)=\lambda_{i}e_{i}(x).
\]

\end_inset


\end_layout

\begin_layout Subsection
Q4
\end_layout

\begin_layout Standard

\bar under
How can we represent images in terms of a linear combination of over-complete
 basis functions by imposing a sparsity constraint?
\end_layout

\begin_layout Standard
We impose L-1 sparsity on the optimization problem for finding the coefficients:
\begin_inset Formula 
\[
E[\bm{a}]=\sum_{x}\Big\{ I(x)-\sum_{i}a_{i}b_{i}(x)\Big\}^{2}+\lambda\sum_{i}\big|a_{i}\big|
\]

\end_inset

Then the solution is 
\begin_inset Formula $\hat{\bm{a}}=\arg\min E[\bm{a}]$
\end_inset

.
\end_layout

\begin_layout Subsection
Q5
\end_layout

\begin_layout Standard

\bar under
What is the miracle of sparsity? Describe L1 sparsity and show, for a simple
 example, how it results in a sparse representation.
\end_layout

\begin_layout Standard
Consider encoding an input 
\begin_inset Formula $y$
\end_inset

 given 
\begin_inset Formula $2N$
\end_inset

 bases functions 
\begin_inset Formula $\{\bar{b}_{i}\}$
\end_inset

 with minimum 
\begin_inset Formula $a=\sum_{i}\bar{a}_{i}$
\end_inset

, the set
\begin_inset Formula 
\[
\{y:\|y-\sum_{i}\bar{a}_{i}\bar{b}_{i}\|\quad s.t.\ \sum_{i}\bar{a}_{i}=a\}
\]

\end_inset

specifies the convex hull of the bases with radius 
\begin_inset Formula $a$
\end_inset

.
 Then, for an input data 
\begin_inset Formula $y$
\end_inset

 where 
\begin_inset Formula $|y|=1$
\end_inset

, solving for 
\begin_inset Formula $\bar{a}_{i}$
\end_inset

 corresponds to finding the closest point 
\begin_inset Formula $y_{p}$
\end_inset

 on the convex hull.
 When sparsity is enforced, the radius 
\begin_inset Formula $a$
\end_inset

 of the convex hull will also be penalized.
 Hence, 
\begin_inset Formula $y$
\end_inset

 is projected to a point 
\begin_inset Formula $y_{p}$
\end_inset

 on the boundary of the convex hull.
\end_layout

\begin_layout Standard
With an increasing 
\begin_inset Formula $\lambda$
\end_inset

, the penalty for the radius of the convex hull also increases, and hence
 causing the radius to get smaller.
 In this case, more bases will have zero coefficients.
\end_layout

\begin_layout Subsection
Q6
\end_layout

\begin_layout Standard

\bar under
Discuss the relative advantages of Principal Component Analysis and Sparse
 Coding for face recognition.
\end_layout

\begin_layout Standard
In case of face recognition, faces can be aligned to remove shift-invariance,
 and the PCA bases will not be sinusoids.
 PCA is also fast and accurate.
\end_layout

\begin_layout Standard
Sparse Coding requires less space to store the representation of images.
\end_layout

\begin_layout Section
Lecture 3
\end_layout

\begin_layout Subsection
Q1
\end_layout

\begin_layout Standard

\bar under
What is the k-means algorithm? What are the means, the assignment variable,
 and k? What are its convergence properties? What are the advantages of
 k-means++?
\end_layout

\begin_layout Standard
K-means algorithm represents each image by one basis function only.
 In other words, K-means algorithm finds the centers of clusters in the
 given image dataset.
\end_layout

\begin_layout Standard
The means are the centers of clusters.
 The assignment variable is the cluster index assignments for the data.
 The 
\begin_inset Formula $k$
\end_inset

 is a hyper-parameter specifying the number of clusters.
\end_layout

\begin_layout Standard
According to 
\begin_inset Quotes eld
\end_inset

Convergence Properties of the K-Means Algorithms
\begin_inset Quotes erd
\end_inset

 of Yoshua Bengio, K-means algorithm can be described either as a gradient
 descent algorithm or by slightly extending the mathematics of the EM algorithm
 to this hard threshold case.
 K-means algorithm actually minimizes the quantization error using the very
 fast newton algorithm.
\end_layout

\begin_layout Standard
K-means++ can avoid some poor clusterings found by the standard K-means
 algorithm.
 Meanwhile, it achieves both higher speed and accuracy compared to standard
 K-means.
\end_layout

\begin_layout Subsection
Q2
\end_layout

\begin_layout Standard

\bar under
How can k-means be used to learn a set of dictionary elements for image
 patches?
\end_layout

\begin_layout Standard
Mini-Epitomes, as an extended K-means algorithm can be used to learn dictionary
 for image patches.
 The steps are as follows:
\end_layout

\begin_layout Enumerate
Select mini-epitome 
\begin_inset Formula $k$
\end_inset

 with probability 
\begin_inset Formula $P(l_{i}=k)=\pi_{k}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Select position 
\begin_inset Formula $p$
\end_inset

 within epitome uniformly.
\end_layout

\begin_layout Enumerate
Generate the patch 
\begin_inset Formula $x_{i}$
\end_inset

 as 
\begin_inset Formula $P(x_{i}|l_{i},p_{i})=\mathcal{N}(x_{i};\alpha_{i}T_{p_{i}}\mu_{l_{i}},\sigma^{2}I)$
\end_inset

.
\end_layout

\begin_layout Subsection
Q3
\end_layout

\begin_layout Standard

\bar under
What is a mixture of Gaussian distribution? And how does k-means relate
 to a mixture of Gaussian distributions?
\end_layout

\begin_layout Standard
Natural data is hard to represent with a single Gaussian distribution.
 A mixture of Gaussian is the weighted sum of a series of Gaussians with
 different mean and variance.
\end_layout

\begin_layout Standard
K-means can be interpreted as a mixture of Gaussian with zero variance.
 Namely, mixture of Gaussian is a softer version of K-means, where the parameter
s of Gaussians can be found through the EM algorithm.
\end_layout

\begin_layout Subsection
Q4
\end_layout

\begin_layout Standard

\bar under
What are mini-epitones? How do they deal with shift-invariance? What algorithm
 is used to learn them? How well can they represent images?
\end_layout

\begin_layout Standard
Mini-epitomes is a generative model for the raw intensity of image patches.
\end_layout

\begin_layout Standard
Shift-invariance is achieved by sampling patches from mini-epitomes that
 minimizes reconstruction error.
 Hence, the epitomes can be invariant to, e.g., patches with the same pattern
 but different position, and are less redundant.
\end_layout

\begin_layout Standard
The algorithms used to learn them are Expectation-Maximization (EM) for
 parameter refinement, and epitomic K-means++ for diverse dictionary initializat
ion.
\end_layout

\begin_layout Standard
Images can be represented by the histogram-based encoding tailored to the
 epitomic representation.
 Based on the evaluation results on PASCAL VOC 2007 datasets, the mini-epitome
 method can achieve the same level of image classification accuracy with
 significantly smaller dictionary size compared to SIFT bag-of-words method.
\end_layout

\begin_layout Section
Lecture 4
\end_layout

\begin_layout Subsection
Q1
\end_layout

\begin_layout Standard

\bar under
What is the Expectation-Maximization (EM) algorithm? How can EM be applied
 to learning a mixture of Gaussian distributions? Describe why the EM algorithm
 converges.
\end_layout

\begin_layout Standard
EM algorithm is a way to estimate parameters 
\begin_inset Formula $\theta$
\end_inset

 of a model 
\begin_inset Formula $P(x|h,\theta)$
\end_inset

 if some variables 
\begin_inset Formula $x$
\end_inset

 can be observed, but the others 
\begin_inset Formula $h$
\end_inset

 are hidden.
\end_layout

\begin_layout Standard
To apply the EM to learn a mixture of Gaussian, we first introduce a new
 variable 
\begin_inset Formula $q(h)$
\end_inset

 which is a distribution over the hidden variables.
 Then we define the free energy function
\begin_inset Formula 
\[
F(\theta,q)=-\log p(x|\theta)+\sum hq(h)\log\frac{q(h)}{p(h|x,\theta)}.
\]

\end_inset

And EM algorithm consists of minimizing 
\begin_inset Formula $F(\theta,q)$
\end_inset

 with respect to 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $q(\cdot)$
\end_inset

 alternatively.
\end_layout

\begin_layout Standard
EM algorithm converges to a local optimum (with zero gradient) because every
 step of the updates is increasing the lower bound.
\end_layout

\begin_layout Subsection
Q2
\end_layout

\begin_layout Standard

\bar under
What are super-pixels? Briefly describe the SLIC algorithm.
 What are the advantages of representing an image in terms of super-pixels?
\end_layout

\begin_layout Standard
Super-pixels are image decomposition as non-overlapping subregions, hwere
 the intensity/texture properties are roughly homogeneous within each subreagion.
\end_layout

\begin_layout Standard
The procedure of SLIC algorithm is as follows:
\end_layout

\begin_layout Enumerate
Initialize K clusters in grid positions
\end_layout

\begin_layout Enumerate
Move K clusters to lowest gradient positions
\end_layout

\begin_layout Enumerate
Assign each pixel to a cluster center
\end_layout

\begin_layout Enumerate
Recalculate the centers as the average labxy vector of all the pixels belonging
 to each cluster
\end_layout

\begin_layout Enumerate
Iterate untill convergence
\end_layout

\begin_layout Enumerate
Fix disconnected segments.
\end_layout

\begin_layout Standard
Super-pixels are important for representing images because they can be used
 to specify the location and sizes of objects in images for initializing
 object classification of deep neural networks.
 Besides, superpixels are unsupervised, which is suitable for cases where
 data annotation is hard to obtain.
 Lastly, there are neuroscience theories that the goal of every vision is
 to break images up into pseudo-objects which is in the spirit of super-pixels.
\end_layout

\begin_layout Section
Lecture 5
\end_layout

\begin_layout Subsection
Q1
\end_layout

\begin_layout Standard

\bar under
What is the Mumford and Shah model for image segmentation?
\end_layout

\begin_layout Standard
Mumford and Shah formulated the image segmentation of a domain 
\begin_inset Formula $D$
\end_inset

 as the minimization of a functional 
\begin_inset Formula $E[J,B]$
\end_inset

.
 The input 
\begin_inset Formula $I$
\end_inset

 is an image.
 The output 
\begin_inset Formula $(\hat{J},\hat{B})=\arg\min E[J,B]$
\end_inset

 is a smoothed image 
\begin_inset Formula $\hat{J}$
\end_inset

 and the position 
\begin_inset Formula $\hat{B}$
\end_inset

 of the boundaries that separates 
\begin_inset Formula $D$
\end_inset

 into subdomains 
\begin_inset Formula $D=\cup D_{i}$
\end_inset

, with 
\begin_inset Formula $D_{i}\cap D_{j}=0$
\end_inset

 for 
\begin_inset Formula $i\neq j$
\end_inset

.
 Specifically,
\begin_inset Formula 
\begin{align*}
E[J,B] & =C\int d\vec{x}(I(\vec{x})-J(\vec{x}))^{2}\\
 & +A\int_{D/B}\vec{\nabla}J(\vec{x})\cdot\vec{\nabla}J(\vec{x})d\vec{x}+B\int_{B}ds
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Q2
\end_layout

\begin_layout Standard

\bar under
What is convexity? What is the steepest descent algorithm? Why is convexity
 important for steepest descent?
\end_layout

\begin_layout Standard
An energy functional (or function) 
\begin_inset Formula $E[J;I]$
\end_inset

 is convex if for all 
\begin_inset Formula $0\leq\alpha\leq1$
\end_inset

 and any 
\begin_inset Formula $J_{1}$
\end_inset

, 
\begin_inset Formula $J_{2}$
\end_inset

, we have
\begin_inset Formula 
\[
\alpha E[J_{1};I]+(1-\alpha)E[J_{2};I]\geq E[\alpha_{1}J_{1}+(1-\alpha_{1})J_{2}].
\]

\end_inset


\end_layout

\begin_layout Standard
Steepest descent algorithm updates 
\begin_inset Formula $J$
\end_inset

 in the direction of the gradient 
\begin_inset Formula $-\frac{\partial E}{\partial J}$
\end_inset

, which is guaranteed to reduce the energy.
\end_layout

\begin_layout Standard
Convexity is important because in this case 
\begin_inset Formula $E[J]$
\end_inset

 has a unique minimum (which is global) and steepest descent is guaranteed
 to find it.
\end_layout

\begin_layout Subsection
Q3
\end_layout

\begin_layout Standard

\bar under
What is the Rudin-Osher-Fatemi, or total variation, model? Why is it more
 practically useful than the weak membrane model? Why is it less effective
 than dictionary methods for denoising images?
\end_layout

\begin_layout Standard
The Rudin-Osher-Fatemi model takes the form:
\begin_inset Formula 
\[
E[J;I]=\int_{D}|\vec{\nabla}J|d\vec{x}+\frac{\lambda}{2}\int_{D}(J(\vec{x})-I(\vec{x}))^{2}d\vec{x}.
\]

\end_inset


\end_layout

\begin_layout Standard
This is more practical because it is convex.
\end_layout

\begin_layout Standard
It is less effective than dictionary methods for denoising images because
 the later method is able to capture longer-range interactions.
\end_layout

\begin_layout Subsection
Q4
\end_layout

\begin_layout Standard

\bar under
What is variational bounding and CCCP? How do they compare to steepest descent?
 How do they guarantee that each iteration decreases the cost?
\end_layout

\begin_layout Standard
Steepest descent needs to be discretized in time to be implemented by computers.
 The update equation has to be converted into a discrete update rule: 
\begin_inset Formula $x_{t+1}=x_{t}-\eta\nabla f(x(t))$
\end_inset

.
\end_layout

\begin_layout Standard
Based on this, variational bounding proceeds by obtaining a sequence of
 bounding functions 
\begin_inset Formula $E_{B}(x,x_{n})$
\end_inset

 where 
\begin_inset Formula $E_{B}(x,x_{n})\geq E(x)$
\end_inset

 for 
\begin_inset Formula $\forall x,x_{n}$
\end_inset

 and 
\begin_inset Formula $E_{B}(x_{n},x_{n})=E(x_{n})$
\end_inset

.
\end_layout

\begin_layout Standard
A special case of this is CCCP.
 The function 
\begin_inset Formula $E(x)$
\end_inset

 is decomposed into a concave 
\begin_inset Formula $E_{c}(x)$
\end_inset

 and a convex part 
\begin_inset Formula $E_{v}(x)$
\end_inset

 so that 
\begin_inset Formula $E(x)=E_{c}(x)+E_{v}(x)$
\end_inset

.
\end_layout

\begin_layout Standard
The steepest descent can be derived as a special case of CCCP.
 Let 
\begin_inset Formula 
\[
E(x)=E(x)+\frac{\lambda}{2}|x|^{2}-\frac{\lambda}{2}|x|^{2},
\]

\end_inset

and 
\begin_inset Formula $E(x)+\frac{\lambda}{2}|x|^{2}$
\end_inset

 is convex, while 
\begin_inset Formula $-\frac{\lambda}{2}|x|^{2}$
\end_inset

 is concave.
\end_layout

\begin_layout Standard
CCCP is guaranteed to decrease the energy with the update rule
\begin_inset Formula 
\[
\nabla E_{v}(x_{n+1})=-\nabla E_{c}(x_{n}).
\]

\end_inset


\end_layout

\begin_layout Subsection
Q5
\end_layout

\begin_layout Standard

\bar under
What forms do the histograms of derivative operators of images normally
 take?
\end_layout

\begin_layout Standard
The histogram of derivative has a Laplacian distribution form
\begin_inset Formula 
\[
p(x)=\frac{1}{Z(k)}\exp\{-k|x|\}
\]

\end_inset

where 
\begin_inset Formula $k$
\end_inset

 is a positive constant and 
\begin_inset Formula $Z(k)$
\end_inset

 normalizes the distribution.
\end_layout

\begin_layout Section
Lecture 6
\end_layout

\begin_layout Subsection
Q1
\end_layout

\begin_layout Standard

\bar under
Briefly describe statistical edge detection.
 What cues are used for detecting edges?
\end_layout

\begin_layout Standard
Consider a statistical approach where we have an annotated dataset where
 pixels 
\begin_inset Formula $x$
\end_inset

 are labelled as edge or non-edge.
 For any filter 
\begin_inset Formula $\phi(\cdot)$
\end_inset

 we can learn probability distributions 
\begin_inset Formula $P(\phi\cdot I(x)|x_{on-edge})$
\end_inset

 and 
\begin_inset Formula $P(\phi\cdot I(X)|x_{off-edge})$
\end_inset

.
 Then edge detection can be formulated as log-likelihood ratio test.
\end_layout

\begin_layout Standard
Cues including filters are used for edge detection.
\end_layout

\begin_layout Subsection
Q2
\end_layout

\begin_layout Standard

\bar under
How is this formulated as a classification learning task using groundtruth
 data? What image features can be used?
\end_layout

\begin_layout Standard
For any filter 
\begin_inset Formula $\phi(\cdot)$
\end_inset

 we can learn probability distributions 
\begin_inset Formula $P(\phi\cdot I(x)|x_{on-edge})$
\end_inset

 and 
\begin_inset Formula $P(\phi\cdot I(X)|x_{off-edge})$
\end_inset

.
 The log-likelihood ratio test based on the two probabilities is a binary
 classification rule.
\end_layout

\begin_layout Standard
Features like simple derivative filter (i.e., 
\begin_inset Formula $\nabla I(x)$
\end_inset

) can be used.
\end_layout

\begin_layout Subsection
Q3
\end_layout

\begin_layout Standard

\bar under
What is the log-likelihood tests? What happens if the image feature is a
 single cue like the derivative of the image intensity?
\end_layout

\begin_layout Standard
A point 
\begin_inset Formula $x$
\end_inset

 is labeled as edge if 
\begin_inset Formula 
\[
\log\frac{P(\phi\cdot I(x)|x_{\text{on-edge}})}{P(\phi\cdot I(X)|x_{\text{off-edge}})}>T.
\]

\end_inset


\end_layout

\begin_layout Standard
When image feature is a single cue (the derivative of the image intensity),
 the log-likelihood is equivalent to simply thresholding the gradient.
\end_layout

\begin_layout Subsection
Q4
\end_layout

\begin_layout Standard

\bar under
Why is a statistical approach useful if edge detection requires using multiple
 cues?
\end_layout

\begin_layout Standard
The statistical approach gives a natural way to combine different edge detectors.
 The result of the combination is superior to simply putting thresholds
 on the individual edge detectors.
\end_layout

\begin_layout Subsection
Q5
\end_layout

\begin_layout Standard

\bar under
How does this relate to Bayes Decision Theory? Which is worse for edge detection
, false positives or false negatives? How do the prior and loss function
 contribute to the threshold?
\end_layout

\begin_layout Standard
The log-likelihood ratio test is a part of Bayes Decision Theory.
 Bayes decision theory can specify the optimal way to estimate 
\begin_inset Formula $y$
\end_inset

 from input 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Standard
Whehter false positive or false negatives are worse depends on context and
 higher level information, and there is no hard decisions on this problem.
\end_layout

\begin_layout Standard
Loss function are used to learn the likelihoods in the ratio test.
 When the two cases have the equal prior, the ratio test can be converted
 to use posterior instead.
\end_layout

\begin_layout Subsection
Q6
\end_layout

\begin_layout Standard

\bar under
Give an example of another visual task that can the same approach be applied
 to?
\end_layout

\begin_layout Standard
Semantic segmentation.
 But this only worked for homogeneous segmentation classes like sky and
 water, but not for inhomogeneous classes like cars and airplanes.
\end_layout

\begin_layout Section
Lecture 7
\end_layout

\begin_layout Subsection
Q1
\end_layout

\begin_layout Standard

\bar under
How does regression relate to decision theory?
\end_layout

\begin_layout Standard
Regression is to learn the distribution 
\begin_inset Formula $P(y|x)$
\end_inset

 directly.
\end_layout

\begin_layout Subsection
Q2
\end_layout

\begin_layout Standard

\bar under
What is binary, or logistic, regression? How can this be be learnt from
 data? Does this require solving a convex or non-convex optimization problem?
 What algorithms can be used to solve it?
\end_layout

\begin_layout Standard
Logistic regression specifies a conditional probability distribution
\begin_inset Formula 
\[
P(y|x)=\frac{\exp\{y(w^{T}x+w_{0})\}}{\exp\{w^{T}x+w_{0}\}+\exp\{-w^{T}x+w_{0}\}}
\]

\end_inset


\end_layout

\begin_layout Standard
The parameters can be estimated from the training dataset 
\begin_inset Formula $\{(x_{n},y_{n})|n=1,\ldots,n\}$
\end_inset

 by
\begin_inset Formula 
\[
(w^{*},w_{0}^{*})=\arg\min\Big\{-\sum_{n=1}^{N}\log P(y_{n}|x_{n})\Big\}
\]

\end_inset

which can be performed by gradient descent.
\end_layout

\begin_layout Standard
It does not require convexity for the problem to be solved since gradient
 descent is used as the optimization algorithm.
\end_layout

\begin_layout Subsection
Q3
\end_layout

\begin_layout Standard

\bar under
How does logistic regression relate to multi-level perceptrons and deep
 networks? What are the main similarities and the biggest differences?
\end_layout

\begin_layout Standard
Multi-layer perceptrons and deep networks can be adopted to solve the logistic
 regression problem.
\end_layout

\begin_layout Standard
The similarities are: (1) using the same loss function and the same optimization
 problem framework; (2) differentiable.
\end_layout

\begin_layout Standard
Differences: (1) deep neural networks may have a larger scale (in terms
 of number of parameters and number of layers) than multi-layer perceptron;
 (2) deep neural networks may involve other types of network layers such
 as convolution.
\end_layout

\begin_layout Section
Lecture 8
\end_layout

\begin_layout Subsection
Q1
\end_layout

\begin_layout Standard

\bar under
Explain how the output of a deep network can be expressed as a composition
 of operations at different layers.
\end_layout

\begin_layout Standard
For example, the output of a neural network is 
\begin_inset Formula $O=\text{ReLU(}W_{3}H_{2})$
\end_inset

, where 
\begin_inset Formula $H_{2}=\text{ReLU}(W_{2}H_{1})$
\end_inset

, and 
\begin_inset Formula $H_{1}=\text{ReLU}(W_{1}I)$
\end_inset

.
 This is a combination of three affine transformation layers with ReLU activatio
n.
\end_layout

\begin_layout Subsection
Q2
\end_layout

\begin_layout Standard

\bar under
What is the loss function? Is it usually a convex or concave function? Can
 the loss function contain terms at different levels of the hierarchy?
\end_layout

\begin_layout Standard
Loss function measures the discrepancy between the neural network output
 and the expected output.
 To train the deep network, we need to compute the derivatives of the loss
 funciton with respect to the model parameters.
\end_layout

\begin_layout Standard
The loss function is a non-convex function of model parameters.
\end_layout

\begin_layout Standard
The loss function can contain terms at different levels of the hierarchy
 as long as the function is differentiable.
\end_layout

\begin_layout Subsection
Q3
\end_layout

\begin_layout Standard

\bar under
Why is it important the outputs are differentiable functions of the weights.
 What is steepest descent? What is stochastic gradient descent? Explain
 how the derivatives with respect to the weights can be computed by backpropagat
ion.
\end_layout

\begin_layout Standard
Gradient can be computed for differentiable functions.
 Updating the model parameters for solving the loss function optimization
 problem requires gradient descent, which depends on gradient.
 Hence, the outputs (and the loss) should be differentiable functions of
 the model parameters.
\end_layout

\begin_layout Standard
Steepest descent is the gradient descent at the batch mode:
\begin_inset Formula 
\[
W_{t+1}=W_{t}-\eta_{t}\frac{1}{N}\sum_{n=1}^{N}L(O(W,I_{n}),T_{n}).
\]

\end_inset


\end_layout

\begin_layout Standard
Stochastic Gradient Descent (SGD) is a variant of steepest descent in the
 online learning manner.
 Specifically, at each time step, an example or a subset 
\begin_inset Formula $X$
\end_inset

 of samples (of size 
\begin_inset Formula $M,$
\end_inset

and 
\begin_inset Formula $M<N$
\end_inset

) is randomly selected, and
\begin_inset Formula 
\[
W_{t+1}=W_{t}-\eta_{t}\frac{1}{M}\sum_{I_{n}\in X}\frac{\partial}{\partial W}L(O(W,I_{n}),T_{n})
\]

\end_inset


\end_layout

\begin_layout Standard
The derivatives of the loss function with respect to the weights can be
 computed by backpropagation because of the chain rule for differentiation.
 Back-propagation is in fact the reverse mode automatic differentiation,
 which relys on the chain rule.
\end_layout

\begin_layout Subsection
Q4
\end_layout

\begin_layout Standard

\bar under
What are convolutional layers? What is pooling? What are the advantages
 of ReLU as compared to sigmoid functions for the non-linearities?
\end_layout

\begin_layout Standard
Convolution layers are linear layers, which apply a small convolution filter
 across the whole input.
\end_layout

\begin_layout Standard
Pooling (i.e., max pooling) is an operation to downsample the input feature
 map in a deep neural networks.
\end_layout

\begin_layout Standard
ReLU activation does not suffer from gradient saturation like sigmoid functions
 does.
 Besides, ReLU is simple and fast to compute, and the models can better
 generalize.
\end_layout

\begin_layout Subsection
Q5
\end_layout

\begin_layout Standard

\bar under
Give three examples of different types of deep networks.
\end_layout

\begin_layout Standard
AlexNet is the milestone work that triggered the revolution of deep neural
 networks in computer vision.
\end_layout

\begin_layout Standard
ResNet is the most prevelant backbone neural network for a wide range of
 vision tasks nowdays.
 It servers as a very important baseline.
\end_layout

\begin_layout Standard
Swin-Transforer is a new type of deep network based on the attention mechanism
 instead of traditional convolutional architectures.
\end_layout

\end_body
\end_document
